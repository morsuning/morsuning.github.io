[{"content":"面向构建、部署与优化智能代理的新一整套工具\n从今天起，我们推出 AgentKit，一套面向开发者和企业，用于构建、部署与优化智能代理（agents）的完整工具集。到目前为止，构建代理意味着你要处理零散的工具：复杂的编排（orchestration）没有版本控制、自定义连接器、手动评估流程、提示(prompt) 调优，以及上线前几周的前端工作。使用 AgentKit，开发者现在可以可视化设计工作流，并且使用新的构建模块更快地嵌入具“代理特性”的 UI，包括：\nAgent Builder：用于可视化创建和版本管理多 Agent 工作流的画布 Connector Registry：集中管理 OpenAI 产品间的数据与工具连接方式 ChatKit：一个用于在你的产品中嵌入可定制聊天型代理体验的工具包 我们还扩展了评估能力（Evals），新增功能如数据集、跟踪评分（trace grading）、自动提示优化、第三方模型支持，以便衡量与提升代理性能。\n自从 3 月发布 Responses API 和 Agents SDK 以来，我们看到很多开发者和企业构建了端到端的 agent 工作流，用于深入研究、客服支持等。Klarna 构建了一个可处理三分之二工单的客服代理，Clay 用一个销售代理把增长提升了 10 倍。AgentKit 构建在 Responses API 之上，帮助开发者更高效、更可靠地构建代理。 (OpenAI)\n使用 Agent Builder 设计工作流 随着代理工作流日益复杂，开发者需要更清晰地了解其内部运作。 Agent Builder 提供一个可视化画布，用于拖拽节点组成逻辑、连接工具、配置定制 Guardrails（安全界限）。它支持预览运行、内联评估配置以及完整版本控制，非常适合快速迭代。 (OpenAI)\n开发者可以从空白画布开始，也可以使用预构建模板。 在 Ramp 团队，他们在几小时内即可从空白画布构建出一个买家代理：\n“Agent Builder 将原本需要数月、涉及复杂编排、自定义代码和手动优化的工作，转变为只需几小时即可完成。这个可视化画布让产品、法律和工程团队保持在同一页面，迭代周期缩短 70%，能够在两个冲刺内上线，而不是两个季度。” — Ramp (OpenAI)\n类似地，日本领先的技术及互联网服务公司 LY Corporation 使用 Agent Builder，在不到两小时内构建了一个工作助理代理：\n“Agent Builder 让我们以全新的方式编排代理，在一个界面里让工程师与领域专家协作。我们在不到两小时内构建了第一个多 agent 工作流并运行，大幅加速了代理的创建与部署时间。” — LY Corporation (OpenAI)\n我们还推出了 Connector Registry，供企业治理和维护跨多个工作区与组织中的数据。Connector Registry 将数据源整合到一个管理面板，可跨 ChatGPT 与 API 使用。这个注册表包含所有预构建连接器（如 Dropbox、Google Drive、SharePoint、Microsoft Teams）和第三方 MCP（多渠道平台）连接器。 (OpenAI)\n开发者还可以在 Agent Builder 中启用 Guardrails——一种开源、模块化的安全层，用以防止代理发生意外或恶意行为。Guardrails 可以掩码或标记个人识别信息（PII）、检测越狱（jailbreak）行为，并应用其他保护措施，更便于构建和部署可靠、安全的代理。Guardrails 可以独立部署，也可以通过 Guardrails 库在 Python 和 JavaScript 中使用。 (OpenAI)\n用 ChatKit 嵌入具代理特性的聊天体验 部署代理聊天 UI（用户界面）往往比预期更复杂 —— 你要处理流式响应、线程管理、显示模型“思考”状态、设计交互流畅的聊天体验。ChatKit 使得在你的产品中嵌入聊天型代理更简单。它可以被嵌入到应用或网站中，并可定制外观以匹配你的主题或品牌。 (OpenAI)\n“我们用 ChatKit 为 Canva 开发者社区构建支持代理，节省了超过两周的开发时间，并在不到一小时内完成集成。这个支持代理将改变开发者与我们文档的交互方式，使其变为对话式体验，从而更容易在 Canva 上构建应用和集成。” — Canva (OpenAI)\nChatKit 已经服务于多个用例，从内部知识助理、入门引导、客服支持到研究代理。HubSpot 的客服代理是其中一个例子。 (OpenAI)\n用新的 Evals 能力衡量代理性能 要构建可靠、可投入生产环境的代理，就必须进行严格的性能评估。去年我们推出 Evals 平台，帮助开发者测试 prompts 和衡量模型行为。如今我们为 Evals 添加了四个新功能，使得创建评估（evals）更容易：\nDatasets — 从零快速构建 agent 评估，并通过自动评分器与人工批注扩展 Trace grading — 对 agent 工作流做端到端评估并自动打分，以找出缺陷 自动提示优化（Automated prompt optimization）— 基于人工批注和评分器输出生成更好的 prompts 第三方模型支持 — 在 OpenAI Evals 平台内部评估其他厂商的模型 (OpenAI) 我们已经看到客户通过使用这些功能获得了重大性能提升。\n“这个评估平台使我们多 agent 尽职调查框架的开发时间缩短超过 50%，同时使代理准确率提升了 30%。” — Carlyle (OpenAI)\n（在原文中有一个界面截图，展示 dataset 表格，一些评分、语气、反馈、准确度列） (OpenAI)\n用强化微调推动代理性能 强化微调（Reinforcement fine-tuning, RFT）使得开发者可以定制我们的推理模型。RFT 在 OpenAI o4-mini 上已广泛可用，并且在 GPT-5 上处于私有 beta 阶段。我们正与多家客户紧密合作，在更广泛发布前优化 GPT-5 的 RFT。 (OpenAI)\n今天，我们在该 RFT beta 中引入了两项新特性，以进一步提升代理性能：\n定制工具调用（Custom tool calls）— 让模型学会在正确的时机调用正确工具，以改善推理能力 定制评分器（Custom graders）— 为你的用例设定专属评估标准，聚焦最关键的性能指标 (OpenAI) 定价与可用性 从今天起，ChatKit 和新的 Evals 能力 向所有开发者广泛开放。Agent Builder 处于 Beta 阶段，而 Connector Registry 正在向部分 API、ChatGPT Enterprise 与教育用户推出 Beta。要启用 Connector Registry，需要 Global Admin 控制台（Global Admin Console）\u0026ndash; 只有具有全局所有者身份的用户才能管理域、单点登录 (SSO)、多个 API 组织。 (OpenAI)\n所有这些工具都包含在标准 API 模型定价中。我们计划很快推出独立的 Workflows API 和代理部署选项（用于 ChatGPT）。 (OpenAI)\n我们迫不及待地想看看你们会构建出什么。 (OpenAI)\n","date":"2025-10-09T00:00:00Z","permalink":"https://morsuning.github.io/p/%E7%BF%BB%E8%AF%91openai-%E6%8E%A8%E5%87%BA-agentkit/","title":"【翻译】OpenAI - 推出 AgentKit"},{"content":"发布于 2025年4月18日，原文链接\nClaude Code 是一款用于代理式编码（agentic coding）的命令行工具。本文将介绍一些在使用 Claude Code 过程中，跨越不同代码库、语言和环境都已证明行之有效的技巧和窍门。\n我们最近发布了 Claude Code，这是一款为代理式编码设计的命令行工具。作为一项研究项目，Claude Code 为 Anthropic 的工程师和研究人员提供了一种更原生的方式，将 Claude 集成到他们的编码工作流中。\nClaude Code 的设计理念是刻意保持底层和无固定模式（low-level and unopinionated），提供近乎原始的模型访问能力，而不强制用户遵循特定的工作流程。这种设计哲学创造了一个灵活、可定制、可编写脚本且功能强大的安全工具。然而，尽管功能强大，这种灵活性也给初次接触代理式编码工具的工程师带来了一定的学习曲线——至少在他们形成自己的一套最佳实践之前是如此。\n本文旨在概述一些已在 Anthropic 内部团队以及在各种代码库、语言和环境中使用的外部工程师中被证明是行之有效的通用模式。此列表中的任何内容都不是一成不变或普遍适用的；请将这些建议视为起点。我们鼓励您进行实验，找到最适合您的方式！\n想要了解更详细的信息吗？我们在 claude.ai/code 上的综合文档涵盖了本文提到的所有功能，并提供了额外的示例、实现细节和高级技术。\n1. 自定义您的设置 Claude Code 是一个代理式编码助手，它会自动将上下文信息提取到提示中。这种上下文收集过程会消耗时间和 tokens，但您可以通过调整环境来优化它。\na. 创建 CLAUDE.md 文件 CLAUDE.md 是一个特殊文件，Claude 在开始对话时会自动将其内容提取到上下文中。这使得它成为记录以下内容的理想场所：\n常用的 bash 命令 核心文件和实用函数 代码风格指南 测试说明 代码仓库的规范（例如，分支命名、使用 merge 还是 rebase 等） 开发者环境设置（例如，pyenv 的使用、哪些编译器可用） 项目中特有的任何意外行为或警告 您希望 Claude 记住的其他信息 CLAUDE.md 文件没有固定的格式要求。我们建议保持其内容简洁且易于人类阅读。例如：\n1 2 3 4 5 6 7 8 9 # Bash commands \\- npm run build: Build the project \\- npm run typecheck: Run the typechecker \\# Code style \\- Use ES modules (import/export) syntax, not CommonJS (require) \\- Destructure imports when possible (eg. import { foo } from \u0026#39;bar\u0026#39;) \\# Workflow \\- Be sure to typecheck when you’re done making a series of code changes \\- Prefer running single tests, and not the whole test suite, for performance 您可以将 CLAUDE.md 文件放置在多个位置：\n仓库的根目录，或您运行 claude 命令的任何位置（最常见的用法）。将其命名为 CLAUDE.md 并提交到 git 中，以便在不同会话和团队成员之间共享（推荐），或者命名为 CLAUDE.local.md 并将其添加到 .gitignore 中。 运行 claude 命令所在目录的任何父目录。这对于 monorepos（单一代码库）项目最有用，您可能在 root/foo 目录下运行 claude，同时在 root/CLAUDE.md 和 root/foo/CLAUDE.md 中都有 CLAUDE.md 文件。这两个文件的内容都会被自动提取到上下文中。 运行 claude 命令所在目录的任何子目录。这与上述情况相反，在这种情况下，当您处理子目录中的文件时，Claude 会按需提取 CLAUDE.md 文件的内容。 您的主文件夹 (~/.claude/CLAUDE.md)，其内容将应用于您所有的 claude 会话。 当您运行 /init 命令时，Claude 会自动为您生成一个 CLAUDE.md 文件。\nb. 调优您的 CLAUDE.md 文件 您的 CLAUDE.md 文件会成为 Claude 提示的一部分，因此应像对待任何频繁使用的提示一样对其进行优化。一个常见的错误是添加大量内容而没有迭代验证其有效性。花些时间进行实验，确定哪些内容能让模型最好地遵循指令。\n您可以手动向 CLAUDE.md 添加内容，或者按 # 键向 Claude 发出指令，它会自动将该指令整合到相关的 CLAUDE.md 文件中。许多工程师在编码时会频繁使用 # 来记录命令、文件和风格指南，然后将 CLAUDE.md 的更改包含在提交中，以便团队成员也能受益。\n在 Anthropic，我们偶尔会使用提示改进器 (prompt improver) 来优化 CLAUDE.md 文件，并经常调整指令（例如，使用 \u0026ldquo;IMPORTANT\u0026rdquo; 或 \u0026ldquo;YOU MUST\u0026rdquo; 来强调）以提高模型的遵循度。\nc. 管理 Claude 允许使用的工具列表 默认情况下，对于任何可能修改您系统的操作，Claude Code 都会请求许可：文件写入、许多 bash 命令、MCP 工具等。我们设计 Claude Code 时采用了这种刻意保守的方法，以将安全性放在首位。您可以自定义允许列表（allowlist），以允许您确信安全的其他工具，或允许那些易于撤销的潜在不安全工具（例如，文件编辑、git commit）。\n有四种方式来管理允许的工具：\n在会话中被提示时选择 \u0026ldquo;Always allow\u0026rdquo;（始终允许）。 启动 Claude Code 后使用 /permissions 命令来添加或移除允许列表中的工具。例如，您可以添加 Edit 来始终允许文件编辑，Bash(git commit:*) 来允许 git commit，或者 mcp__puppeteer__puppeteer_navigate 来允许使用 Puppeteer MCP 服务器进行导航。 手动编辑您的 .claude/settings.json 或 ~/.claude.json 文件（我们建议将前者检入源代码控制中以便与团队共享）。 使用 --allowedTools CLI 标志来设置特定于会话的权限。 d. 如果使用 GitHub，请安装 gh CLI Claude 知道如何使用 gh CLI 与 GitHub 交互，以创建 issue、开启 pull request、读取评论等。如果没有安装 gh，Claude 仍然可以使用 GitHub API 或 MCP 服务器（如果您已安装）。\n2. 为 Claude 提供更多工具 Claude 可以访问您的 shell 环境，您可以在其中为它构建一系列便利的脚本和函数，就像为自己构建一样。它还可以通过 MCP 和 REST API 利用更复杂的工具。\na. 将 Claude 与 bash 工具结合使用 Claude Code 继承了您的 bash 环境，使其可以访问您的所有工具。虽然 Claude 了解像 unix 工具和 gh 这样的常用工具，但如果没有指令，它不会知道您的自定义 bash 工具：\n通过使用示例告诉 Claude 工具的名称。 告诉 Claude 运行 --help 来查看工具文档。 在 CLAUDE.md 中记录常用的工具。 b. 将 Claude 与 MCP 结合使用 Claude Code 同时作为 MCP 服务器和客户端。作为客户端，它可以通过三种方式连接到任意数量的 MCP 服务器以访问它们的工具：\n在项目配置中（在相应目录中运行 Claude Code 时可用）。 在全局配置中（在所有项目中都可用）。 在检入代码库的 .mcp.json 文件中（对在您的代码库中工作的任何人均可用）。例如，您可以将 Puppeteer 和 Sentry 服务器添加到您的 .mcp.json 文件中，这样在您的仓库中工作的每位工程师都可以开箱即用地使用这些工具。 在使用 MCP 时，使用 --mcp-debug 标志启动 Claude 也有助于识别配置问题。\nc. 使用自定义斜杠命令 对于重复性的工作流——如调试循环、日志分析等——您可以将提示模板存储在 .claude/commands 文件夹中的 Markdown 文件里。当您键入 / 时，这些模板就会通过斜杠命令菜单可用。您可以将这些命令检入 git，使其对团队其他成员可用。\n自定义斜杠命令可以包含特殊关键字 $ARGUMENTS，以从命令调用中传递参数。\n例如，这是一个可用于自动获取并修复 GitHub issue 的斜杠命令：\n1 2 3 4 5 6 7 8 9 10 11 Please analyze and fix the GitHub issue: $ARGUMENTS. Follow these steps: 1\\. Use \\`gh issue view\\` to get the issue details 2\\. Understand the problem described in the issue 3\\. Search the codebase for relevant files 4\\. Implement the necessary changes to fix the issue 5\\. Write and run tests to verify the fix 6\\. Ensure code passes linting and type checking 7\\. Create a descriptive commit message 8\\. Push and create a PR Remember to use the GitHub CLI (\\`gh\\`) for all GitHub-related tasks. 将上述内容放入 .claude/commands/fix-github-issue.md 文件中，即可在 Claude Code 中通过 /project:fix-github-issue 命令使用它。然后，您可以使用 /project:fix-github-issue 1234 来让 Claude 修复编号为 1234 的 issue。同样，您可以将个人命令添加到 ~/.claude/commands 文件夹中，以便在所有会话中使用。\n3. 尝试常见工作流 Claude Code 不会强加特定的工作流，这让您可以灵活地按自己喜欢的方式使用它。在这种灵活性所提供的空间内，我们的用户社区中涌现出了几种成功有效使用 Claude Code 的模式：\na. 探索、规划、编码、提交 这个通用的工作流适用于许多问题：\n要求 Claude 阅读相关文件、图片或 URL，可以提供一般性指引（“阅读处理日志的文件”）或具体文件名（“阅读 logging.py”），但要明确告诉它暂时不要编写任何代码。 在这个工作流阶段，您应该考虑充分利用子代理（subagents），特别是对于复杂问题。让 Claude 使用子代理来验证细节或调查它可能有的特定问题，尤其是在对话或任务的早期，这往往能在不显著损失效率的情况下，更好地保留上下文的可用性。 要求 Claude 制定一个解决特定问题的计划。我们建议使用 \u0026ldquo;think\u0026rdquo; 这个词来触发扩展思考模式，这会给予 Claude 额外的计算时间来更彻底地评估备选方案。这些特定的短语直接映射到系统中不断增加的思考预算级别：\u0026ldquo;think\u0026rdquo; \u0026lt; \u0026ldquo;think hard\u0026rdquo; \u0026lt; \u0026ldquo;think harder\u0026rdquo; \u0026lt; \u0026ldquo;ultrathink\u0026rdquo;。每个级别都会为 Claude 分配更多的思考预算。 如果这一步的结果看起来合理，您可以让 Claude 创建一个文档或一个 GitHub issue 来记录它的计划，这样如果实现步骤（第3步）不符合您的期望，您可以回溯到这个节点。 要求 Claude 用代码实现其解决方案。这也是一个好时机，可以要求它在实现方案的各个部分时，明确验证其解决方案的合理性。 要求 Claude 提交结果并创建一个 pull request。如果相关，这也是让 Claude 更新任何 README 或变更日志，解释它刚刚做了什么的好时机。 步骤 #1-#2 至关重要——没有它们，Claude 往往会直接跳到编码解决方案。虽然有时这正是您想要的，但对于需要更深入前期思考的问题，要求 Claude 先进行研究和规划会显著提高其表现。\nb. 编写测试、提交；编码、迭代、提交 这是一个 Anthropic 内部最喜欢的工作流，适用于那些可以通过单元测试、集成测试或端到端测试轻松验证的变更。测试驱动开发（TDD）在代理式编码的加持下变得更加强大：\n要求 Claude 根据预期的输入/输出对编写测试。明确指出您正在进行测试驱动开发，这样它就会避免创建模拟实现，即使对于代码库中尚不存在的功能也是如此。 告诉 Claude 运行测试并确认它们失败。在此阶段明确告诉它不要编写任何实现代码通常很有帮助。 当您对测试满意时，要求 Claude 提交测试。 要求 Claude 编写能够通过测试的代码，并指示它不要修改测试。告诉 Claude 继续尝试，直到所有测试都通过。通常，Claude 需要几次迭代才能完成编写代码、运行测试、调整代码、再运行测试的循环。 在此阶段，要求它使用独立的子代理来验证实现是否对测试过拟合，这会很有帮助。 一旦您对更改满意，要求 Claude 提交代码。 当 Claude 有一个明确的目标可以迭代时——比如一个视觉模型、一个测试用例或其他类型的输出——它的表现最好。通过提供像测试这样的预期输出，Claude 可以进行更改、评估结果，并逐步改进直到成功。\nc. 编写代码、截图结果、迭代 与测试工作流类似，您可以为 Claude 提供视觉目标：\n为 Claude 提供一种截取浏览器屏幕截图的方法（例如，使用 Puppeteer MCP 服务器、(https://github.com/joshuayoes/ios-simulator-mcp)，或者手动复制/粘贴截图给 Claude）。 通过复制/粘贴或拖放图片，或者提供图片文件路径，给 Claude 一个视觉模型。 要求 Claude 用代码实现该设计，截取结果的屏幕截图，并进行迭代，直到其结果与模型匹配。 当您满意时，要求 Claude 提交。 像人类一样，Claude 的输出通过迭代往往会显著改善。虽然第一个版本可能不错，但经过2-3次迭代后，它通常会看起来好得多。为 Claude 提供查看其输出的工具，以获得最佳结果。\nd. 安全的 YOLO 模式 您可以不监督 Claude，而是使用 claude --dangerously-skip-permissions 来绕过所有权限检查，让 Claude 不间断地工作直到完成。这对于修复 lint 错误或生成样板代码等工作流非常有效。\n让 Claude 运行任意命令是有风险的，可能导致数据丢失、系统损坏或\u0026hellip; \\[译者注：原文此处句子不完整\\]4. 与 Claude 协作 最重要的实践是将 Claude 视为一个智能的协作者，而不仅仅是一个自动补全工具或搜索引擎。当您提供清晰、具体的指令并保持对话式的方法时，Claude 在处理复杂的多步骤任务时表现出色。\na. 具体明确 Claude 能够推断意图，但它无法读懂您的心思。具体性能够使其更好地与您的期望对齐。\n不好的指令 好的指令 为 foo.py 写测试 为 foo.py 写一个新的测试用例，覆盖用户未登录时的边缘情况。避免使用 mock。 为什么 ExecutionFactory 的 API 这么奇怪？ 查看 ExecutionFactory 的 git 历史，总结一下它的 API 是如何演变至今的。 添加一个日历小部件 查看主页上现有小部件的实现方式，以理解其模式，特别是代码和接口是如何分离的。HotDogWidget.php 是一个很好的入门示例。然后，遵循该模式实现一个新的日历小部件，允许用户选择月份并通过向前/向后翻页来选择年份。除了代码库中已使用的库之外，不要使用其他库，从头开始构建。 b. 给 Claude 提供图片 Claude 可以通过多种方式出色地处理图片和图表：\n粘贴截图（专业提示：在 macOS 中按 cmd+ctrl+shift+4 可以将截图复制到剪贴板，然后按 ctrl+v 粘贴。请注意，这与您通常在 Mac 上使用的 cmd+v 不同，并且在远程操作时无效。） 拖放图片到提示输入框中。 提供图片的文件路径。 这在进行 UI 开发时以设计模型为参考点，以及在分析和调试时使用可视化图表时特别有用。即使您不向上下文中添加视觉材料，明确告诉 Claude 最终结果在视觉上需要具有吸引力的重要性，仍然很有帮助。\nc. 提及您希望 Claude 查看或处理的文件 使用 Tab 键自动补全功能，可以快速引用您仓库中任何位置的文件或文件夹，帮助 Claude 找到或更新正确的资源。\nd. 给 Claude 提供 URL 将特定的 URL 与您的提示一起粘贴，Claude 会获取并阅读其内容。为避免对同一域名（例如 docs.foo.com）重复出现权限提示，请使用 /permissions 将域名添加到您的允许列表中。\ne. 尽早并频繁地进行路线修正 虽然自动接受模式（按 shift+tab 切换）可以让 Claude 自主工作，但通常情况下，通过作为一名积极的协作者并引导 Claude 的方法，您会得到更好的结果。在开始时向 Claude 彻底解释任务可以获得最佳结果，但您也可以随时对 Claude 进行路线修正。\n这四个工具有助于进行路线修正：\n在编码前要求 Claude 制定一个计划。明确告诉它在您确认其计划可行之前不要编码。 在任何阶段（思考、工具调用、文件编辑）按 Escape 键中断 Claude，同时保留上下文，以便您可以重新定向或扩展指令。 双击 Escape 键可以跳回历史记录，编辑之前的提示，并探索一个不同的方向。您可以编辑提示并重复，直到得到您想要的结果。 要求 Claude 撤销更改，通常与选项 #2 结合使用，以采取不同的方法。 尽管 Claude Code 偶尔会在第一次尝试时就完美解决问题，但使用这些修正工具通常能更快地产生更好的解决方案。\nf. 使用 /clear 保持上下文的专注 在长时间的会话中，Claude 的上下文窗口可能会被不相关的对话、文件内容和命令填满。这会降低性能，有时还会分散 Claude 的注意力。在任务之间频繁使用 /clear 命令来重置上下文窗口。\ng. 对复杂工作流使用清单和草稿板 对于包含多个步骤或需要详尽解决方案的大型任务——如代码迁移、修复大量 lint 错误或运行复杂的构建脚本——可以通过让 Claude 使用 Markdown 文件（甚至 GitHub issue！）作为清单和工作草稿板来提高性能。\n5. 脚本与自动化 批处理允许您自动执行重复性任务： 创建一个包含您的提示的 shell 脚本。 调用 claude 并传入您的脚本。例如：claude -p “migrate foo.py from React to Vue. When you are done, you MUST return the string OK if you succeeded, or FAIL if the task failed.” --allowedTools Edit Bash(git commit:*) 多次运行该脚本并优化您的提示以获得期望的结果。 管道操作 (Pipelining) 将 Claude 集成到现有的数据/处理管道中： 调用 claude -p “\u0026lt;your prompt\u0026gt;” --json | your_command，其中 your_command 是您处理管道的下一步。 就是这样！JSON 输出（可选）可以帮助提供结构，以便于自动化处理。 对于这两种用例，使用 --verbose 标志进行调试 Claude 调用可能会很有帮助。我们通常建议在生产环境中关闭详细模式以获得更清晰的输出。\n您在使用 Claude Code 方面有什么技巧和最佳实践吗？请标记 @AnthropicAI，让我们看看您正在构建什么！\n致谢 作者：Boris Cherny。这项工作借鉴了广大 Claude Code 用户社区的最佳实践，他们富有创造力的方法和工作流程持续激励着我们。特别感谢 Daisy Hollman、Ashwin Bhat、Cat Wu、Sid Bidasaria、Cal Rueb、Nodir Turakulov、Barry Zhang、Drew Hodun 以及许多其他 Anthropic 工程师，他们宝贵的见解和使用 Claude Code 的实践经验帮助塑造了这些建议。\n想了解更多？ 通过 Anthropic Academy 的课程，掌握 API 开发、模型上下文协议（Model Context Protocol）和 Claude Code。完成课程后可获得证书。\n探索课程\n© 2025 Anthropic PBC\n","date":"2025-09-28T00:00:00Z","permalink":"https://morsuning.github.io/p/%E7%BF%BB%E8%AF%91claude-code%E4%BB%A3%E7%90%86%E5%BC%8F%E7%BC%96%E7%A0%81%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","title":"【翻译】Claude Code：代理式编码的最佳实践"},{"content":"1.1 广告业务上下游介绍 广告的三要素：广告主、信息、受众\n广告分类\n效果广告/品牌广告，通过目的/内容/形式/效果区分 软广/硬广 广告售卖方式（计费方式），品牌/效果广告以及软广/硬广均有不同，可概括为以下类型（引用）：\n售卖方式品牌广告效果广告 硬广CPD-Cost Per DayCPM-Cost Per Mille 按轮卖CPD-Cost Per Download CPM-Cost Per MilleCPA-Cost Per Activation 软广按项目卖CPS-Cost Per Sale 活动赞助CPL-Cost Per Lead 广告从有投放需求到被投放给受众经过的相关利益方的过程：\n广告主 代理-DSP 流量贩子-SSP 媒体 用户 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt; \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;``\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;``\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;``\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;``\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;``\u0026lt;p\u0026gt;900w日活 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;3000w月活 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;具体到每一个用户 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt; 花钱推广-金主 拿钱干活-中间商 拿钱干活-中间商 售卖流量-我们 无辜的用户 \u0026lt;p\u0026gt;每年要花上亿推广费用 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;1. 不同地区：北美、南美、亚太、非洲的市场目标 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;2. 目的不同：推广新品、品牌升级 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;服务广告主 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;把广告主的要求变成一个个具体投放计划 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;1. 在北美市场花5000w，投放覆盖9000w目标人群 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;2. 在100个媒体上进行投放，包括主流媒体-Facebook、Ins、Tiktok等 \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;帮助媒体变现 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;来我的平台投放吧，我这里什么媒体都有！\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;1. 对接海量媒体 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;2. 进行流量交易，满足不同的交易方式 \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;1. 用户转化\u0026ndash;\u0026gt;流量 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;- 开广告场景 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;- 管理广告频次 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;2. 流量进行交易\u0026ndash;\u0026gt;钱 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;- 对接不同渠道 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;- 进行程序化交易 \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;合着就我一个冤大头？\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;平白无故看两个广告 \u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;贡献商业化流量，享受免费、更好、可持续的服务 \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;``\u0026lt;/p\u0026gt; 广告主：有广告投放需求的一方，即广告主 -\u0026gt; 需求方平台：也被称为DSP，负责将广告主的广告需求变成具体的广告物料——包括文字图片视频等以及制作投放计划，同时也会根据投放效果进行数据分析，帮助广告主调整广告策略\n-\u0026gt; 供应方平台：也被称为SSP，是代理和媒体的撮合交易商，掌握大量媒体资源，帮助代理将广告投放至媒体，帮助媒体流量变现\n-\u0026gt; 媒体：有广泛的用户流量，可通过广告位将广告投放给受众\n-\u0026gt; 用户：最终获取到广告信息的一方，即受众\n总结一下，代理的价值在于聚合了拥有广告投放需求的大量客户，流量贩子的价值在于聚合了具备广告投放能力的大量媒体，若广告主和媒体之间直接发生交易，交易效率极低\n1.2 效果广告业态 对我们的媒体——今日水印相机来说，通过广告实现流量变现的途径是：用户 -\u0026gt; 流量 -\u0026gt; 商业化流量 -\u0026gt; 变现，其中商业化流量指作为广告被投放给用户的流量，也就是用户与广告交互（曝光、点击、下载等）产生的流量\n商业化流量越多，媒体收益一般来说会更高，但商业化流量会显著影响用户体验，如微博有15-18%的商业化流量，小红书是10%，字节系13%，这些产品给人的体验均有所区别，所以平衡用户体验 - 平台收益 - 广告主ROI也是广告业务需要重点考虑的问题\n效果广告的获客链路：曝光 -\u0026gt; 点击 -\u0026gt; 下载 -\u0026gt; 注册 -\u0026gt; 激活付费\n在今日水印相机中，商业化流量指效果广告，是当前主要投放的广告类型，结合上述媒体在广告产业上下游扮演的角色，媒体需要做到广告资源管理、流量交易和渠道管理三方面的能力\n广告资源管理\n广告资源指客户端可以拿来交易的可投放的广告位，广告位由页面+容器+点位三个要素构成\n页面指广告所处的页面 其中容器指广告容器，它具备如下要素： 支持的广告类型：有开屏广告、插屏广告、信息流广告等，这些类型又可被分为阻断式广告（慎用，需要用户行为完成）、嵌入式广告、原生广告（渲染效果更匹配APP） 格式：文字、图片、音频、视频等 自适应填充：根据广告物料的特性填充相应内容 交互方式：点击、滑动、摇一摇等 转化能力：链接访问、注册、下载、唤起APP、小程序等 样式：广告物料的排列布局 点位指在信息流中出现的点位 广告资源管理指可以通过平台来灵活配置可用于出售的广告位\n广告资源管理 = 广告位 + 频次\n流量交易\n程序化交易：把流量以标准化的方式在市场内进行交易，就需要把流量发送到交易所（即渠道，扮演DSP角色） 出价与计算：是否支持竞价（bidding），一价结算还是二价结算 流量分发：如何定义询价/交易顺序 渠道（代码位）管理\n渠道管理指对接渠道和选择合适渠道获取更高的收益\n对接渠道的方式包括使用渠道提供的sdk、调用渠道的API等\n1.3 流量交易 流量交易是广告业务的核心，具体的流量交易过程如下\n在DSP和SSP之间，需要有一个广告位买方（DSP）和卖方（SSP）的中介拍卖平台，在此平台上买卖双方要出价竞争每一次广告曝光机会的花费，该平台被称为即被称为广告交易平台（Ad Exchange，ADX）\n当前端App触发广告流量机会时，会将本次流量下发给其对接的ADX，流量属性中通常会带有广告位和用户信息等相关属性； ADX在接收到流量请求时，首先会校验流量的合法性，最简单的就是参数校验，然后校验订单/DSP的预设值，最终将该流量下发给哪些DSP； DSP接收到本次流量时，根据流量中携带的相关属性决定是否参与竞价，如果流量合适，则返回参竞价格（或者dealId）及广告元素给ADX； ADX接收各家DSP竞价信息，在经过一系列的有效性判断之后根据价格竞价排序，价高者得之，将获胜的广告信息下发给媒体，同时通知DSP其广告获胜了（这一步非必需，但建议有）； 媒体在收到广告信息后，对广告进行渲染展示。 当ADX对接多个DSP时，就需要制定不同的策略来决定对这些DSP串行还是并行请求竞价，广告行业通常使用的策略如下：\n串行请求：一般被称为Waterfall（瀑布流），指的是“在无法实时评估每次流量的价值时，基于历史eCPM数据，从上到下请求DSP，分发流量”\n例：假设ADX对接了三个平台，三个平台的eCPM和填充率分别如下，假设有1000个广告请求\n我们期望总收益最高，即优先填充eCPM高的平台，且最终所有广告位尽可能被填充，因此可以采取如下策略：先把1000个广告请求全部请求 DSP3 ，把未填充的部分请求 DSP1，最后未填充的部分请求DSP2，具体流量分发流程图如下\n收益 = 1000 * 25 / 1000 * 20% + 800 * 20 / 1000 * 30%+560 *15/ 1000 *50% = 14，总填充率为72%\nWaterfall方案的问题是：\n如何确定一家DSP的历史eCPM数据和填充率？这个目前需要运营同学手动维护，无法做到自动化预测 历史数据没有及时更新的话，可能造成优先级低的DSP出价比优先级高的DSP高，无法收益最大化 多个DSP之间是串行请求的，会造成用户体验变差 另外一种可并行进行的竞价方案叫做Header Bidding（头部竞价），指“将流量发给头部买家，头部媒体进行竞价，然后将获胜的底价作为底价去请求其它不支持实时竞价的DSP”\n实现Header Bidding需要以下要求：\n头部买家需在返回广告物料时，同时返回出价，这样ADX才能完成竞价 若不支持实时返回出价（非头部买家），但需要支持传入广告位底价，这样如果有广告返回，那么价格一定高于底价，对ADX和媒体来说收益最高 上述Waterfall和Bidding是在DSP支持竞价的前提下进行的，除此之外，还可通过PD（Programmatic Direct，程序化直接交易）的方式进行广告交易，是广告主和媒体之间通过程序化平台进行的广告位直接购买交易，不经过实时竞价（RTB）过程\n1.3 名词解释 广告售卖方式\nCPM（Cost Per Mille）：按照每千次曝光计费 CPA（Cost Per Activation）：按照行为计费（比如注册等） CPT（Cost Per Time）：按时间计费，独占性包时段包位置 CPC（Cost Per Click）：按照点击计费 CPD（Cost Per Download）：按照下载计费 CPS（Cost Per Sales）：按照销售量计费 CPL（Cost Per Lead）：按照获客数量计费 广告上下游角色\nDSP（Demand Side Platform，需求方平台）：为广告主提供服务\nSSP（Supply Side Platform，供应方平台）：为可投放广告的媒体提供服务\n渠道：是对于媒体来说的概念，指获得广告投放的来源，具体有广告联盟、平台厂商、DSP/SSP、网服平台直售\n广告联盟：拥有自己的流量矩阵，即既拥有流量投放能力，也掌握广告投放需求，代表为穿山甲、优量汇、百青藤、快手联盟\n平台厂商：一般指手机厂商、拥有操作系统级别的流量，同样有流量投放能力和掌握广告投放需求\n网服平台直售：即广告主主动联系平台进行广告投放交易\n广告业务名词\n广告位：指媒体可拿来售卖（投放广告的）位置，包含页面+容器+点位三个要素，对广告资源的规划\n代码位：带有渠道和交易属性的位置，对双方来说共同的位置\n程序化广告：是一种通过自动化技术进行广告购买和投放的方式，前文所述就是程序化广告，参与方包括Advertiser，DSP，SSP，Ad Exchange，DMP（Data Management Platform，负责收集和分析用户数据，帮助广告主进行精准的广告投放）\n广告竞价名词\nRTB（Real-Time Bidding）：实时竞价，是程序化广告的一种核心机制，指广告展示位在页面加载时，通过实时竞价系统，在毫秒级别内让多个广告主同时出价竞购该广告位，出价最高的广告主获得广告展示机会\n竟胜：指广告主在广告竞价过程中赢得了广告展示机会的情况。当多个广告主为同一个广告展示位置竞价时，系统会根据出价（以及其他相关因素，如广告质量分、点击率预估等）选择一个最高的出价。这个出价的广告主被称为“竟胜”，他们的广告会被展示给用户\n竟败：指广告主在竞价过程中未能赢得广告展示机会的情况\nBidding一价：又称为一价竞价（First-Price Bidding），广告主支付的价格就是其竞价的金额。即广告主出价多少，赢得竞价后就支付多少\nBidding二价：又称为二价竞价（Second-Price Bidding），广告主支付的价格是第二高的出价金额，而不是自己出价的金额。即出价最高的广告主赢得广告展示位，但支付的价格是次高出价再加上一个最小的增量（如0.01元）\nPD（Programmatic Direct）：指程序化直接交易，是广告主和出版商之间通过程序化平台进行的广告位直接购买交易，不经过实时竞价（RTB）过程，程序化直接交易通常涉及广告主和出版商事先达成的协议，并且广告的展示位置、展示量、价格等都在交易前已经确定。广告主无需参与公开竞价，能够获得更加可控的广告投放资源\n广告运营名词\neCPM（ Effective Cost Per Mille）：每千次展示的有效成本\nDAU（Daily Active Users）：日活跃用户\nMAU（Monthly Active Users）：月活跃用户\nARPU（Average Revenue Per User）：每用户平均收入\n曝光Gap：广告的实际展示次数（曝光量）与预期展示次数之间的差距\n收入Gap：预期收入与实际收入之间的差距\nROI（Return on Investment）：即投资回报率，主要用于衡量投资的盈利能力。它通过比较投资所获得的收益与投资成本，帮助投资者评估一项投资的效益\n","date":"2024-10-15T00:00:00Z","permalink":"https://morsuning.github.io/p/%E7%A8%8B%E5%BA%8F%E5%8C%96%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","title":"程序化广告业务快速入门"},{"content":"常用软件 软件来源 macwk 学习版MacOS软件下载\nMac App Store 苹果官方应用商店，方便下载、卸载、更新和付费\nHomebrew MacOS软件包管理器，通常用来安装开源软件\n各软件官方网站\n必备软件 applite brew GUI 建议在此安装推荐的软件和任何brew安装的软件，方便管理\nappcleaner App卸载工具\nclash-verge-rev | hiddify-next 科学上网工具\nThe Unarchiver 压缩工具\nitem2 | wrap 终端模拟器\nedge | arc 浏览器\nmotrix 全功能下载管理器\nVSCode 全能代码编辑器\n欧陆词典 单词查询\u0026amp;翻译\nNotion 在线笔记 | Anytype 本地+在线笔记\nObsidian 离线可同步笔记\nMicrosoft Office 微软全家桶，办公专用\nSnippetsLab | Lepton 优秀的代码片段管理工具, 轻量, 可基于菜单栏操作\nreeder RSS订阅浏览器\niina or infuse 视频播放器\nkoodo Reader 电子书管理，可替代calibre，支持多设备同步及epub等多种电子书格式\ndash 开发文档查阅\nbuhontfs NTFS磁盘工具，可读写NTFS磁盘，我是免费期入的，可用其他软件替代\nstats iStats开源平替，菜单栏系统资源监视器\ntailscale 内网穿透工具\nraycast | utools 效率工具平台，可集成各类效率插件，补全系统级功能，raycast 插件推荐\nBarbee | Bartender 菜单栏项自定义隐藏，避免被刘海遮挡\nPDF Expert pdf编辑工具\nXnViewMP 图片查看格式转换压缩\nrustdesk 远程桌面工具\nwhisky 运行windows应用\nplaycover 运行未在Mac App Store上架的ios应用\nUTM | Parallels Desktop 虚拟机软件\nQuick Look 插件: 选中文件，按空格预览\nQuicklookStephen - 查看未知拓展名的纯文本文件 brew install \u0026ndash;cask qlstephen QLMarkdown - 空格键预览 Markdown 文本效果 - brew install \u0026ndash;cask qlmarkdown 可选软件 capslock 将CapsLock键改造为强力功能修饰键\nDownie 下载视频，也可以使用cobalt这个网站\nswitchhosts host切换\nKeyCastr 将mac按键显示在屏幕上，分享演示、录制视频或动图时超赞\npixpin 截图\u0026amp;OCR工具\nQSpace \u0026amp; TotalFinder 访达增强\nBetterMouse 全能鼠标驱动设置\npermute3 格式转换\nandroid file transfer 传输安卓系统文件\nEtcher 制作 U 盘镜像\nventoy 新一代多系统启动U盘解决方案\nCheatSheet 按command显示当前应用快捷键\nAlDente 用于MacBooks的ALL-IN-ONE充电限制器应用软件\n开发者工具\nDBeaver ｜ Naviat 数据库客户端\npostman API管理工具\nchsrc 全平台一件换源工具\n命令行工具简要推荐 wget 下载工具\ntmux 终端复用\ncloc 代码行数统计命令行工具\nproxychains-ng 终端命令行下代理神器，可以让指定的命令走设置好的代理，内网渗透、科学上网必备工具 brew install proxychains-ng 配置文件: /usr/local/etc/proxychains.conf\nproxychains4 curl https://www.google.com.hk 通过代理访问 proxychains4 -q /bin/zsh 开启zsh全局代理 配置文件最后一行配置示例: http 127.0.0.1 7897 建议配置alias pc=’proxychains4’ Shell 使用当前MacOS下体验最佳终端Warp，搭配MacOS自带的zsh及其配置框架oh-my-zsh\n先依次安装\noh-my-zsh: zsh配置框架 sh -c \u0026ldquo;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" brew: 包管理工具 配置oh-my-zsh 修改～/.zshrc\n主题\nZSH_THEME=”robbyrussell”默认\n推荐主题：简洁 - cloud, af-magic;详细 - ys, dst\nzsh插件\n自动跳转插件autojump 1 2 3 git clone https://github.com/wting/autojump.git $ZSH_CUSTOM/plugins/autojump; cd $ZSH_CUSTOM/plugins/autojump; python3 install.py; 只要访问过某个目录直接 j 目录 即可跳转到该目录\nextract (oh-my-zsh内置)一个命令解压所有文件 x \u0026lt;文件名\u0026gt; 即可解压该文件 zsh-syntax-highlighting 语法高亮插件 1 git clone https://github.com/zsh-users/zsh-syntax-highlighting $ZSH_CUSTOM/plugins/zsh-syntax-highlighting; zsh-autosuggestions 命令自动补全插件 1 git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions; 最终的参考.zshrc文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 # If you come from bash you might have to change your $PATH. export PATH=$HOME/env/bin:$HOME/.local/bin:/usr/local/bin:/opt/homebrew/bin:$PATH # Homebrew mirror export HOMEBREW_BREW_GIT_REMOTE=\u0026#34;https://mirrors.ustc.edu.cn/brew.git\u0026#34; export HOMEBREW_CORE_GIT_REMOTE=\u0026#34;https://mirrors.ustc.edu.cn/homebrew-core.git\u0026#34; export HOMEBREW_BOTTLE_DOMAIN=\u0026#34;https://mirrors.ustc.edu.cn/homebrew-bottles\u0026#34; export HOMEBREW_API_DOMAIN=\u0026#34;https://mirrors.ustc.edu.cn/homebrew-bottles/api\u0026#34; # Path to your oh-my-zsh installation. export ZSH=\u0026#34;$HOME/.oh-my-zsh\u0026#34; # Set name of the theme to load --- if set to \u0026#34;random\u0026#34;, it will # load a random theme each time oh-my-zsh is loaded, in which case, # to know which specific one was loaded, run: echo $RANDOM_THEME # See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes ZSH_THEME=\u0026#34;ys\u0026#34; # Set list of themes to pick from when loading at random # Setting this variable when ZSH_THEME=random will cause zsh to load # a theme from this variable instead of looking in $ZSH/themes/ # If set to an empty array, this variable will have no effect. # ZSH_THEME_RANDOM_CANDIDATES=( \u0026#34;robbyrussell\u0026#34; \u0026#34;agnoster\u0026#34; ) # Uncomment the following line to use case-sensitive completion. # CASE_SENSITIVE=\u0026#34;true\u0026#34; # Uncomment the following line to use hyphen-insensitive completion. # Case-sensitive completion must be off. _ and - will be interchangeable. # HYPHEN_INSENSITIVE=\u0026#34;true\u0026#34; # Uncomment one of the following lines to change the auto-update behavior # zstyle \u0026#39;:omz:update\u0026#39; mode disabled # disable automatic updates # zstyle \u0026#39;:omz:update\u0026#39; mode auto # update automatically without asking # zstyle \u0026#39;:omz:update\u0026#39; mode reminder # just remind me to update when it\u0026#39;s time # Uncomment the following line to change how often to auto-update (in days). # zstyle \u0026#39;:omz:update\u0026#39; frequency 13 # Uncomment the following line if pasting URLs and other text is messed up. # DISABLE_MAGIC_FUNCTIONS=\u0026#34;true\u0026#34; # Uncomment the following line to disable colors in ls. # DISABLE_LS_COLORS=\u0026#34;true\u0026#34; # Uncomment the following line to disable auto-setting terminal title. # DISABLE_AUTO_TITLE=\u0026#34;true\u0026#34; # Uncomment the following line to enable command auto-correction. # ENABLE_CORRECTION=\u0026#34;true\u0026#34; # Uncomment the following line to display red dots whilst waiting for completion. # You can also set it to another string to have that shown instead of the default red dots. # e.g. COMPLETION_WAITING_DOTS=\u0026#34;%F{yellow}waiting...%f\u0026#34; # Caution: this setting can cause issues with multiline prompts in zsh \u0026lt; 5.7.1 (see #5765) # COMPLETION_WAITING_DOTS=\u0026#34;true\u0026#34; # Uncomment the following line if you want to disable marking untracked files # under VCS as dirty. This makes repository status check for large repositories # much, much faster. # DISABLE_UNTRACKED_FILES_DIRTY=\u0026#34;true\u0026#34; # Uncomment the following line if you want to change the command execution time # stamp shown in the history command output. # You can set one of the optional three formats: # \u0026#34;mm/dd/yyyy\u0026#34;|\u0026#34;dd.mm.yyyy\u0026#34;|\u0026#34;yyyy-mm-dd\u0026#34; # or set a custom format using the strftime function format specifications, # see \u0026#39;man strftime\u0026#39; for details. # HIST_STAMPS=\u0026#34;mm/dd/yyyy\u0026#34; # Would you like to use another custom folder than $ZSH/custom? # ZSH_CUSTOM=/path/to/new-custom-folder # Which plugins would you like to load? # Standard plugins can be found in $ZSH/plugins/ # Custom plugins may be added to $ZSH_CUSTOM/plugins/ # Example format: plugins=(rails git textmate ruby lighthouse) # Add wisely, as too many plugins slow down shell startup. plugins=(git extract textmate ruby mvn gradle autojump zsh-syntax-highlighting zsh-autosuggestions) source $ZSH/oh-my-zsh.sh # User configuration autoload -U compinit # export MANPATH=\u0026#34;/usr/local/man:$MANPATH\u0026#34; # You may need to manually set your language environment # export LANG=en_US.UTF-8 # Preferred editor for local and remote sessions # if [[ -n $SSH_CONNECTION ]]; then # export EDITOR=\u0026#39;vim\u0026#39; # else # export EDITOR=\u0026#39;mvim\u0026#39; # fi # Compilation flags # export ARCHFLAGS=\u0026#34;-arch x86_64\u0026#34; # Set personal aliases, overriding those provided by oh-my-zsh libs, # plugins, and themes. Aliases can be placed here, though oh-my-zsh # users are encouraged to define aliases within the ZSH_CUSTOM folder. # For a full list of active aliases, run `alias`. # # Example aliases # alias zshconfig=\u0026#34;mate ~/.zshrc\u0026#34; # alias ohmyzsh=\u0026#34;mate ~/.oh-my-zsh\u0026#34; alias dk=\u0026#34;docker\u0026#34; alias python=\u0026#34;python3\u0026#34; alias cls=\u0026#39;clear\u0026#39; alias vi=\u0026#39;vim\u0026#39; alias pc=\u0026#39;proxychains4\u0026#39; alias javac=\u0026#34;javac -J-Dfile.encoding=utf8\u0026#34; alias grep=\u0026#34;grep --color=auto\u0026#34; alias -s html=vi # 在命令行直接输入后缀为 html 的文件名，会在 TextMate 中打开 alias -s rb=vi # 在命令行直接输入 ruby 文件，会在 TextMate 中打开 alias -s py=vi # 在命令行直接输入 python 文件，会用 vim 中打开，以下类似 alias -s js=vi alias -s c=vi alias -s java=vi alias -s txt=vi alias -s gz=\u0026#39;tar -xzvf\u0026#39; alias -s tgz=\u0026#39;tar -xzvf\u0026#39; alias -s zip=\u0026#39;unzip\u0026#39; alias -s bz2=\u0026#39;tar -xjvf\u0026#39; # Source global definitions s2c () { scp \u0026#34;$@\u0026#34; ${SSH_CLIENT%% *}:~/; } c2s () { scp ${SSH_CLIENT%% *}:\u0026#34;$@\u0026#34; .; } ","date":"2024-05-11T00:00:00Z","permalink":"https://morsuning.github.io/p/macos-%E5%BC%80%E5%8F%91%E8%BD%AF%E4%BB%B6%E5%8F%8A-shell-%E9%85%8D%E7%BD%AE%E6%8E%A8%E8%8D%90/","title":"MacOS 开发软件及 Shell 配置推荐"},{"content":"记录一次对象存储在曙光服务器（Hygon CPU）上CPU占用异常问题的定位过程，相关信息已脱敏\n环境说明 CPU规格：每个服务器2 * Hygon C86 7380 32-Core Processor，一共128个虚拟核，具体规格如下：\n通过lstopo \u0026ndash;of png \u0026gt; out.png 命令可以看到服务器CPU（numa架构）的及其外设（内存、硬盘、网卡）的拓扑结构图\n问题现象 3个节点的集群跑216并发的128M大对象，测试集群带宽，对象存储进程CPU占用上千，是正常节点CPU占用的数十倍，且CPU利用率高在三个节点中随机出现，最少1个节点出现，最多3个节点出现\n通过perf命令抓取性能数据，发现CPU利用率与IPC负相关，与L1-dcache-loads负相关，与dTLB-loads负相关\n下图最右边节点的CPU利用率最高\n定位结论 是Hygon CPU本身的问题，CPU占用高是CPU内部调度的问题\n定位过程 确定硬盘和网络都不是瓶颈 屏蔽对象存储服务进程的后台任务，不改变该现象 使用go pprof工具排除程序本身的问题 通过perf工具确定CPU利用率高的节点上CPU流水线的效率很低，各节点CPU效率有数倍差距 经过绑核验证，使用128核/64核/32核/16核/8核都能支持1.5G的对象带宽，无论绑多少核CPU都能用满 调优建议 建议在Hygon CPU上部署对象存储服务时使用16核的绑核方式（即numa中的一个node），例： 1 taskset -apc 32-39, 96-103 2638647 其中，32-29, 96-103是绑定的CPU核的变化，可以通过Iscpu获取，或者numactl-H获取；2638647 是需要绑核的进程ID\n当限制核数以后，会导致prometheus获取metrics效据变慢，具体表现在对象存储服务和node_exporter向prometheus回写数据非常慢。绑16核的场景下，回写metrics最多要花37秒，因此建议作出如下调整： ﻿﻿延长prometheus的指标拉取周期，由15秒拉取一次调整为1分钟拉取一次 延长prometheus的指标拉取超时时长，由10秒超时调整为55秒超时 ","date":"2023-12-21T00:00:00Z","permalink":"https://morsuning.github.io/p/%E8%AE%B0%E4%B8%80%E6%AC%A1cpu%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/","title":"记一次CPU占用过高问题定位"},{"content":"1 Kubernetes存储相关概念及实现原理 1.1 PV \u0026amp; PVC 概念\nKubernetes定义了PV（PersistentVolume）与PVC（PersistentVolumeClaim）这两个概念让用户使用持久化存储，是在用户与存储服务提供者之间添加的一个中间层。\n用户指Kubernetes应用的开发者，存储服务提供者一般是Kubernetes集群的运维人员，或者是第三方存储服务提供商的服务人员\n存储服务提供者事先根据PV支持的存储卷插件及适配的存储方案（目标存储系统）细节定义好可以支撑存储卷的底层存储空间\n然后由用户通过PVC声明要使用的存储特性来绑定符合条件的最佳PV定义存储卷，实现存储系统的使用与管理职能的解耦，大大简化了用户使用存储的方式\n为什么这么设计\n解决2个问题\n卷对象的生命周期无法独立于Pod而存在 用户必须足够熟悉存储的使用和配置才能在Pod上配置和使用卷 PV是由集群管理员于全局级别配置的预挂载存储空间，它通过支持的存储卷插件及给定的配置参数关联至某个存储系统上可用数据存储的一段空间，这段存储空间可能是Ceph存储系统上的一个存储映像、一个文件系统（CephFS）或其子目录，也可能是NFS存储系统上的一个导出目录等。\nPV将存储系统之上的存储空间抽象为Kubernetes系统全局级别的API资源，由集群管理员负责管理和维护。 将PV提供的存储空间用于Pod对象的存储卷时，用户需要事先使用PVC在名称空间级别声明所需要的存储空间大小及访问模式并提交给Kubernetes API Server，接下来由PV控制器负责查找与之匹配的PV资源并完成绑定。随后，用户在Pod资源中使用persistentVolumeClaim类型的存储卷插件指明要使用的PVC对象的名称即可使用其绑定到的PV所指向的存储空间，如图所示。\nPV和PVC是一对一的关系：一个PVC仅能绑定一个PV，而一个PV在某一时刻也仅可被一个PVC所绑定。\n为了能够让用户更精细地表达存储需求，PV资源对象的定义支持存储容量、存储类、卷模型和访问模式等属性维度的约束。相应地，PVC资源能够从访问模式、数据源、存储资源容量需求和限制、标签选择器、存储类名称、卷模型和卷名称等多个不同的维度向PV资源发起匹配请求并完成筛选。\nPV与PVC示例 \u0026amp; 用户使用示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 # PV apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs spec: # 存储类名称 storageClassName: manual # 存储资源 capacity: storage: 10Gi # 访问模式 accessModes: - ReadWriteMany # 数据源 nfs: path: /opt/nfs-volume server: 172.26.204.144 --- # PVC kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-nfs spec: storageClassName: manual accessModes: - ReadWriteMany resources: requests: storage: 10Gi --- # 用户使用 apiVersion: apps/v1 kind: Deployment metadata: name: test-nfs labels: app: test spec: replicas: 1 selector: matchLabels: app: test template: metadata: labels: app: test spec: containers: - name: busybox image: busybox # 使用卷 volumeMounts: - name: data mountPath: /data # 声明卷 volumes: - name: data persistentVolumeClaim: claimName: pvc-nfs PV和PVC的生命周期如下表所示\n操作 PV 状态 PVC 状态 创建 PV Available - 创建 PVC Available Pending Bound Bound 删除 PV -/Terminating Lost/Bound 重新创建 PV Bound Bound 删除 PVC Released - 后端存储不可用 Failed - 删除 PV 的 claimRef Available - PV生命周期\n创建后未能正确关联到存储设备的PV处于Pending状态，成功关联后转为Available 一个Available状态的PV与PVC关联后变为Bound状态 处于Bound状态的PV，其关联的PVC被删除后，变为Release状态 当PV的回收策略为recycle或手动删除PVC引用时，PV从Release状态变为Available状态 可选的回收策略：\nRetain（保留）：删除PVC后将保留其绑定的PV及存储的数据，但会把该PV置为Released状态，它不可再被其他PVC所绑定，且需要由管理员手动进行后续的回收操作：首先删除PV，接着手动清理其关联的外部存储组件上的数据，最后手动删除该存储组件或者基于该组件重新创建PV Delete（删除）：对于支持该回收策略的卷插件，删除一个PVC将同时删除其绑定的PV资源以及该PV关联的外部存储组件；动态的PV回收策略继承自StorageClass资源，默认为Delete。多数情况下，管理员都需要根据用户的期望修改此默认策略，以免导致数据非计划内的删除 Recycle（回收）：对于支持该回收策略的卷插件，删除PVC时，其绑定的PV所关联的外部存储组件上的数据会被清空，随后，该PV将转为Available状态，可再次接受其他PVC的绑定请求。不过，该策略已被废弃 recycle失败时，PV将从Released状态变为Failed状态 可通过手动删除PVC将PV状态变成Available PVC生命周期\n一个Pending状态PVC与PV绑定后变为Bound状态 处于Bound状态的PVC，与其关联的PV被删除后变为Lost状态 Lost状态的PVC再次与PV绑定后变成Bound状态 PV和PVC的生命周期可概括为存储制备（Provision）、存储绑定、存储使用、存储回收四个阶段\n这是使用Kubernetes存储最基本的模式，但会产生2个问题：\n存储服务提供者难以预测用户的真实需求，如果用户提交了一个PVC，但是PV控制器没有找到合适的PV与之绑定，容器创建就会失败 会造成资源浪费，如集群中创建的PV容量都是10G的，但是如果创建了一个声明使用5G的PVC，依然会绑定到10G的PV 因此Kubernetes提供了一种动态自动创建PV的机制，被称为动态制备（dynamic provision），刚刚说的手动创建PV的方式又被称为静态制备（static provision）\n1.2 StorageClass \u0026amp; Plugin Kubernetes使用一种API对象叫做存储类（StorageClass）提供动态预配、按需创建PV的机制。需要存储服务提供者事先借助存储类创建出一到多个“PV模板”，并在模板中定义好基于某个存储系统创建PV所依赖的存储组件（例如Ceph RBD存储映像或CephFS文件系统等）时需要用到的配置参数，包括PV的属性如存储类型、Volume大小等以及创建这种PV需要的存储插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # SC示例 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: nfs # 指定存储服务方（Provisioner，预配器），基于该字段判断使用的存储插件，内置插件以kubernetes.io/为前缀 provisioner: nfs.csi.k8s.io parameters: server: 10.0.0.11 share: /data # 默认回收策略 reclaimPolicy: Delete # 定义如何为PVC完成预配和绑定 volumeBindingMode: Immediate # 当前类动态创建的PV资源的默认挂载选项 mountOptions: - nfsvers=4.1 使用动态制备的方式创建PVC时，用户需要为其指定要使用PV模板（StorageClass资源），而后PV控制器会自动连接相应存储类上定义的 目标存储系统的管理接口 ，请求创建匹配该PVC需求的存储组件，并将该存储组件创建为Kubernetes集群上可由该PVC绑定的PV资源。\nKubernetes通过卷插件（Volume Plugins）的机制接入目标存储系统，Kubernetes定义了一系列管理接口，插件即是在一个存储系统的基础上实现了这些管理接口的代码\n卷插件分为In-Tree和Out-of-Tree两类\nIn-Tree的代码是放在Kubernetes内部的，和Kubernetes一起发布、管理与迭代，优点是使用方便，缺点是迭代速度慢、灵活性差，目前除了少数通用存储如nfs，hostpath，正在逐渐被废弃 Out-of-Tree是由存储厂商提供的，有FlexVolume和CSI两种实现机制，目前FlexVolume已被废弃，Kubernetes官方目前提供了生产可用的NFS，SMB，NVMF、host-path四种CSI插件 1.3 Kubernetes存储相关组件及架构 PV控制器（集群维度）：负责PV及PVC的整个生命周期管理，主要监听PV/PVC/SC三类资源，当发现这些资源的CRU操作时，PV控制器会判断是否需要创建、删除、绑定和回收卷；并根据需求进行存储卷的预配和删除操作 AD控制器（集群维度）：专用于存储设备的附加和拆除操作的组件，能够将存储设备关联（attach）至目标节点或从目标节点之上剥离（detach） AD控制器监听Pod/Node时间，如有必要，调用Volume Plugin执行AD操作 存储卷管理器也能触发AD操作，但它只监听调度到本节点的Pod 存储卷管理器（节点维度）：kubelet内置管理器组件之一，用于在当前节点上执行存储设备的挂载（mount）、卸载（unmount）和格式化（format）等操作；另外，存储卷管理器也可执行节点级别设备的附加（attach）及拆除（detach）操作 存储卷插件：Kubernetes存储卷功能的基础设施，是存储任务相关操作的执行方；它是存储相关的扩展接口，用于对接各类存储设备 PV控制器、AD控制器和存储卷管理器均构建于存储卷插件之上，以提供不同维度管理功能的接口，具体的实现逻辑均由存储卷插件完成\n最初，只有VolumeManager能够Attach/Detach，但是节点宕掉后，它已经挂载的卷需要在其它节点进行Detach，然后再Attach，这个必须依赖外部才能完成，AD控制器因此产生\n现在，到底在何处进行Attach/Detach，取决于Volume Plugin，如果实现了Attach相关接口，则在AttachDetach中执行，否则，在Volume Manager上执行\n1.4 Kubernetes存储实现原理 PV对象成为容器内的持久化存储过程，实际上就是将一个宿主机上的目录跟一个容器里的目录绑定挂载在了一起\n如果使用远程存储服务实现容器数据的持久化，Kubernetes所做的就是将这个远程存储服务挂载到宿主机上的一个目录，以供将来进行绑定挂载时使用，这个准备宿主机目录的过程可以称为“两阶段处理”\n1 第一阶段Attach，由AD控制器完成，类似于插入硬盘\n当一个Pod调度到一个节点上后，kubelet要负责为这个pod创建它的volume目录，默认情况下，kubelet为volume创建的目录是一个宿主机上的路径，如\n/var/lib/kubelet/pods/\u0026lt;Pod ID\u0026gt;/volumes/kubernetes.io-\u0026lt;volume type\u0026gt;/\u0026lt;vulume name\u0026gt;\n接下来进行的操作取决于Volume类型，如使用远程块存储，会调用相应的API，将其提供的持久化盘挂载到宿主机上，如果使用CSI，则会调用相应的CSI接口\n2 第二阶段mount，也由存储卷管理器完成，类似于格盘并挂载\n完成Attach阶段后，kubelet需要格式化这个磁盘设备并将它挂载到宿主机指定的挂载点上，即之前提到的宿主机目录\nmount完成后Volume的宿主机目录就是一个持久化目录了，容器写入的内容会被存储在存储服务中，如果Volume类型是远程文件存储服务（如NFS），kubelet会跳过attach阶段，因为使用NFS不需要经过“插盘”这个操作，直接mount即可\nKubernetes 通过在具体的插件实现接口上提供不同的参数列表，定义和区分这两个阶段\n第一阶段Kubernetes通过nodeName，即宿主机的名字区分 第二阶段通过dir，即Volume宿主机的目录区分 完成两阶段处理后，kubelet只需将这个volume目录通过CRI里的Mounts参数传递给Docker，就可以为Pod里的容器挂载这个持久化的Volume了\n1.5 CSI 介绍 Kubernetes从1.8版本开始已经停止接受in-tree卷插件，并建议所有供应商实现out-of-tree卷插件，而2种out-of-tree卷扩展机制之一的flexvolume已经被废弃，所以目前CSI目前已成为接入自定义存储的唯一途径\nCSI架构\nCSI，全称Container Storage Interface，是一种规范，在Kubernetes核心存储(即上文提到的PV控制器、AD控制器等)之外，CSI又引入了2组外部组件，方便存储提供者开发和使用CSI标准\n一组由Kubernetes官方提供，一系列external组件负责注册CSI Driver（即第三方提供的存储插件）或监听Kubernetes对象资源，从而发起csi Driver调用，都作为CSI Controller的sidecar容器\nnode-driver-register：一个sidecar容器，可从CSI driver获取驱动程序信息（使用NodeGetInfo），并使用kubelet插件注册机制在该节点上的kubelet中对其进行注册 External Provisioner：一个sidecar容器，用于监视Kubernetes PersistentVolumeClaim对象并针对驱动程序端点触发CSI CreateVolume和DeleteVolume操作。external-attacher还支持快照数据源。如果将快照CRD资源指定为PVC对象上的数据源，则此sidecar容器通过获取SnapshotContent对象获取有关快照的信息，并填充数据源字段，该字段向存储系统指示应使用指定的快照填充新卷 External Attacher：一个sidecar容器，用于监视Kubernetes VolumeAttachment对象并针对驱动程序端点触发CSI ControllerPublish和ControllerUnpublish操作 livenessprobe：一个sidecar容器，用于监视CSI驱动程序的运行状况，并通过Liveness Probe机制将其报告给Kubernetes。这使Kubernetes能够自动检测驱动程序问题并重新启动Pod以尝试解决问题 External Resizer：一个sidecar容器，监听PVC对象，如果用户在PVC对象请求更多存储，该组件会调用CSI Controller的NodeExpandVolume接口对volume进行扩容 External Snapshotter：一个Snapshot Controller的sidecar容器，Snapshot Controller会根据集群中创建的Snapshot对象创建对应的VolumeSnapshotContent，而External Snapshotter负责监听之，监听到其发生变化时，将其对应参数传递给CSI Controller，调用其CreateSnapshot接口 另一组需要存储提供者实现，也是卷插件必须的组成部分，这组中包括3个服务，分别需要实现三组grpc接口\nCSI Identity： 提供插件信息、能力、探测插件状态 CSI Controller（Provision和Attach）：负责创建和管理卷 CSI Node（mount）：在节点上完成和卷相关的功能，如Publish/Unpublish，Stage/Unstage CSI中Capabilities会标识出来此插件提供哪些能力，如IdentityServer中的GetPluginCapabilities方法，ControllerServer中的ControllerGetCapabilities方法和NodeServer中的NodeGetCapabilities\nCSI交互模型\nKubelet和CSI插件的交互方式：\nKubelet直接通过UDS，向CSI发起NodeStageVolume、NodePublishVolume等调用 Kubelet通过插件注册机制来发现CSI插件及其UDS。这意味着CSI插件必须在任何节点上进行Kubelet插件注册 Master和CSI插件的交互方式：\nK8S控制平面不直接和CSI插件交互 K8S控制平面组件仅仅通过K8S API进行相互交互 CSI插件必须监控相关K8S API资源，并触发对应的CSI操作，例如卷创建、Attach、快照生成等 CSI对象\nKubernetes提供了2个CSI相关的API对象CSIDriver和CSINode，方便CSI插件集成到Kubernetes\nCSIDriver提供的功能：\n简化CSI驱动的发现：在安装时附带一个CISDrive对象，就可以将存储提供者的插件注册到Kubernetes中 定制K8S的行为：Kubernetes具有一套和CSI驱动交互的默认规则，例如默认它会调用Attach/Detach操作。使用CSIDriver··对象可以定制这一行为 CSIDriver示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: storage.k8s.io/v1 kind: CSIDriver metadata: # 和CSI驱动的全名一致 name: mycsidriver.example.com spec: # 提示K8S，此驱动需要Attach操作（因为驱动实现了ControllerPublishVolume方法）， # 并且需要在Attach之后等待操作完成，然后再进行后续的Mount操作 # 默认值true attachRequired: true # 提示K8S，在挂载阶段，此驱动需要Pod的信息（名称、Pod的UID等） # Pod信息会在NodePublishVolume调用中作为volume_context传递： # \u0026#34;csi.storage.k8s.io/pod.name\u0026#34;: pod.Name # \u0026#34;csi.storage.k8s.io/pod.namespace\u0026#34;: pod.Namespace # \u0026#34;csi.storage.k8s.io/pod.uid\u0026#34;: string(pod.UID) # \u0026#34;csi.storage.k8s.io/serviceAccount.name\u0026#34;: pod.Spec.ServiceAccountName podInfoOnMount: true # 1.16中添加，到1.18为止beta # 此驱动支持的Volume Mode volumeLifecycleModes: - Persistent # 默认，常规PV/PVC机制 - Ephemeral # 内联临时存储（inline ephemeral volumes） 由CSIDrive注册后就可以通过kubectl查看所有安装的CSI驱动\n1 kubectl get csidrivers.storage.k8s.io CSINode对象存放CSI驱动产生的、节点相关的信息，它的功能是：\n映射K8S节点名称到CSI节点名称：CSI的GetNodeInfo调用返回的name，是存储系统引用节点使用的名字。在后续的ControllerPublishVolume调用中K8S使用该名字引用节点 为kubelet提供和kube-controller-manager、kube-scheduler交互的机制，不管CSI插件是否可用（注册到节点） 卷拓扑：CSI的GetNodeInfo调用会返回一系列标签（键值对），来识别节点的拓扑信息。K8S使用这些信息进行拓扑感知的卷创建。这些键值对存放在Node对象中，Kubelet会把键存放在CSINode中，供后续引用 CSINode示例：\n1 2 3 4 5 6 7 8 9 apiVersion: storage.k8s.io/v1 kind: CSINode metadata: name: node1 spec: drivers: - name: mycsidriver.example.com nodeID: storageNodeID1 topologyKeys: [\u0026#39;mycsidriver.example.com/regions\u0026#39;, \u0026#34;mycsidriver.example.com/zones\u0026#34;] 1.6 CSI插件实现 存储提供者需要实现三个服务，CSI Identity，CSI Controller和CSI Node，这是在CSI规范中定义的，即上文提到的外部组件，这三个服务必须实现一组grpc接口\nCSI Identity\n1 2 3 4 5 6 7 8 9 10 11 12 // 让调用者（K8S组件、CSI Sidecar容器）能识别驱动，知晓它具有哪些可选特性 service Identity { // 获取插件名称和版本 rpc GetPluginInfo(GetPluginInfoRequest) returns (GetPluginInfoResponse) {} // 获取插件功能 rpc GetPluginCapabilities(GetPluginCapabilitiesRequest) returns (GetPluginCapabilitiesResponse) {} // 检查插件是否运行 rpc Probe (ProbeRequest) returns (ProbeResponse) {} } CSI Controller（Provision和Attach），可以运行在任何节点，实现创建卷、创建快照等功能，可选\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 service Controller { // 必须实现 rpc CreateVolume (CreateVolumeRequest) returns (CreateVolumeResponse) {} // 必须实现 rpc DeleteVolume (DeleteVolumeRequest) returns (DeleteVolumeResponse) {} rpc ControllerPublishVolume (ControllerPublishVolumeRequest) returns (ControllerPublishVolumeResponse) {} rpc ControllerUnpublishVolume (ControllerUnpublishVolumeRequest) returns (ControllerUnpublishVolumeResponse) {} // 必须实现 rpc ValidateVolumeCapabilities (ValidateVolumeCapabilitiesRequest) returns (ValidateVolumeCapabilitiesResponse) {} rpc ListVolumes (ListVolumesRequest) returns (ListVolumesResponse) {} rpc GetCapacity (GetCapacityRequest) returns (GetCapacityResponse) {} // 必须实现 rpc ControllerGetCapabilities (ControllerGetCapabilitiesRequest) returns (ControllerGetCapabilitiesResponse) {} // nfs-csi已实现 rpc CreateSnapshot (CreateSnapshotRequest) returns (CreateSnapshotResponse) {} // nfs-csi已实现 rpc DeleteSnapshot (DeleteSnapshotRequest) returns (DeleteSnapshotResponse) {} rpc ListSnapshots (ListSnapshotsRequest) returns (ListSnapshotsResponse) {} rpc ControllerExpandVolume (ControllerExpandVolumeRequest) returns (ControllerExpandVolumeResponse) {} rpc ControllerGetVolume (ControllerGetVolumeRequest) returns (ControllerGetVolumeResponse) { option (alpha_method) = true; } rpc ControllerModifyVolume (ControllerModifyVolumeRequest) returns (ControllerModifyVolumeResponse) { option (alpha_method) = true; } } CSI Node（mount），任何存储提供者的卷，想要Publish的节点都需要运行此插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 service Node { rpc NodeStageVolume (NodeStageVolumeRequest) returns (NodeStageVolumeResponse) {} rpc NodeUnstageVolume (NodeUnstageVolumeRequest) returns (NodeUnstageVolumeResponse) {} // 将卷挂载到节点上 rpc NodePublishVolume (NodePublishVolumeRequest) returns (NodePublishVolumeResponse) {} // 卸载卷 rpc NodeUnpublishVolume (NodeUnpublishVolumeRequest) returns (NodeUnpublishVolumeResponse) {} // 获取卷状态 rpc NodeGetVolumeStats (NodeGetVolumeStatsRequest) returns (NodeGetVolumeStatsResponse) {} rpc NodeExpandVolume(NodeExpandVolumeRequest) returns (NodeExpandVolumeResponse) {} // 必须实现 rpc NodeGetCapabilities (NodeGetCapabilitiesRequest) returns (NodeGetCapabilitiesResponse) {} // 必须实现，返回运行插件的节点的信息 rpc NodeGetInfo (NodeGetInfoRequest) returns (NodeGetInfoResponse) {} } 某些部署架构下，也可由一个服务（可以是一个二进制文件）同时提供CSI Controller和CSI Node两组接口\n1.7 CSI部署架构 CSI规范的主要关注点是Kubernetes和卷插件之间的协议。Kubernetes应该同时支持中心化部署、headless部署的Plugin。几种可能的部署架构：\n注：headless指Kubernetes中的一种服务的配置方式，它允许您直接访问服务中的各个Pod而不是通过一个集群IP来访问整个服务。headless服务实现上是为与服务关联的每个 Pod 创建 DNS 记录。然后，可以使用这些 DNS 记录直接对每个 Pod 进行寻址\n插件运行在所有节点上，在Master上运行中心化的控制器，所有节点上运行Node Plugin： 注： CO即为容器编排系统（指Kubernetes），使用CSI的RPC接口和CSI插件交互\nHeadless部署，在所有节点上运行Plugin，Controller Plugin、Node Plugin分开部署： Headless部署，在所有节点上运行Plugin，Controller Plugin、Node Plugin合并部署： Headless部署，在所有节点上运行Plugin，只运行Node Plugin。GetPluginCapabilities调用不会报告CONTROLLER_SERVICE特性： 2 Kubernetes接入NFS存储方式及配置示例 直接使用nfs卷，k8s内置支持(提前部署nfs-server：10.1.33.53) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 volumeMounts: - name: data mountPath: /usr/share/nginx/html volumes: - name: data nfs: path: /opt/nfs-deployment server: 10.1.33.53 将nfs创建为PV，并创建相应PVC，在容器中使用，静态绑定 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # PV apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs spec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteMany nfs: path: /opt/nfs-deployment server: 172.26.204.144 --- # PVC kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-nfs spec: storageClassName: manual accessModes: - ReadWriteMany resources: requests: storage: 10Gi --- # 使用 apiVersion: apps/v1 kind: Deployment metadata: name: busybox labels: app: busybox spec: replicas: 1 selector: matchLabels: app: busybox template: metadata: labels: app: busybox spec: containers: - name: busybox image: busybox command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;echo \u0026#34;Hello, Kubernetes!\u0026#34; \u0026amp;\u0026amp; sleep 3600\u0026#39;] volumeMounts: - name: data mountPath: /data volumes: - name: data persistentVolumeClaim: claimName: pvc-nfs K8S官方CSI插件，本身只提供了集群中的资源和NFS服务器之间的通信层，Driver直接使用官方的安装即可，使用如下 注：动态绑定需要注意权限问题，弄清楚是以什么账号权限访问的，配置读写权限是否具有读写权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 # 静态绑定 apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs-csi spec: capacity: storage: 10Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain mountOptions: - hard - nfsvers=4.1 csi: driver: nfs.csi.k8s.io readOnly: false volumeHandle: unique-volumeid # #确保它是集群中的唯一 ID volumeAttributes: server: 172.26.204.144 share: /opt/nfs-deployment --- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-nfs-csi-static spec: accessModes: - ReadWriteMany resources: requests: storage: 10Gi volumeName: pv-nfs-csi storageClassName: \u0026#34;\u0026#34; # 动态绑定 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: nfs-csi provisioner: nfs.csi.k8s.io parameters: server: 172.26.204.144 share: /opt/nfs-deployment reclaimPolicy: Delete volumeBindingMode: Immediate mountOptions: - hard - nfsvers=4.1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-nfs-csi-dynamic spec: accessModes: - ReadWriteMany resources: requests: storage: 10Gi storageClassName: nfs-csi 3 Reference https://github.com/container-storage-interface/spec/blob/master/spec.md\nhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.29/#api-overview\nhttps://kubernetes-csi.github.io/docs/introduction.html\n","date":"2023-12-01T00:00:00Z","permalink":"https://morsuning.github.io/p/kubernetes-%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E7%AE%80%E5%8D%95%E7%A4%BA%E4%BE%8B/","title":"Kubernetes 存储实现原理及简单示例"},{"content":"记录一次视频监控场景下对文件系统进行性能测试及简单调优的过程及思路，相关内容已脱敏\n1 性能分析方法 可通过日志和检测工具来监控基于fuse实现的用户态文件系统性能\n以JuiceFS为例，它提供了访问日志和性能日志以及命令行工具监控文件系统性能，使用方式分别如下：\n1 2 3 4 5 $ cat /path/to/your/.accesslog $ cat /path/to/your/.perfmetric $ juicefs stats /path/to/your 2 性能分析思路 在视频监控场景下，文件为多路监源连续追加写入文件系统\n假设网络无瓶颈，文件系统内所有存储介质写入速率一致，理想情况下最大带宽：\n单节点：服务端从本地写入JuiceFS速度为该节点的最大写入速度 3节点：期望最大写入速度为单节点最大写入速度 * 3 测试得服务端单节点从本地写入JuiceFS速度如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 fiotest: (g=0):rw=write,bs=(R)16.0MiB-16.0MiB, (W) 16.0MiB-16.0MiB, (T) 16.0MiB-16.0MiB,ioengine=libaio, iodepth=1 fio-3.29 Starting 1 process fiotest: Laying out I0 file (1 file / 4096MiB) Jobs: 1 (f=1): [W(1)][100.0%][w=256MiB/s][w=16 IOPS][eta 00m:00s] fiotest: (groupid=0, jobs=1): err= 0: pid=528243: Sun Nov 26 02:26:37 2023 write: IOPS=16, BW=257MiB/s (269MB/s)(4096MiB/15937msec); 0 zone resets slat (usec): min=8557, max=18135, avg=9782.97, stdev=718.53 clat (nsec) : min=2590, max=19341, avg=6322.75, stdev=2224.38 lat (usec): min=8560, max=18145, avg=9791.82, stdev=719.24 clat percentiles (nsec): 1.00th=[ 2928]. 5.00th=[ 3376], 10.00th=[ 3856], 20.00th=[ 4448], 30.00th=[ 5152], 40.00th=[ 5728], 50.00th=[ 6176], 60.00th=[ 6624], 70.00th=[ 7264], 80.00th=[ 7776], 90.00th=[ 8512], 95.00th=[ 8896], 99.00th=[15936], 99.50th=[18560], 99.90th=[19328], 99.95th=[19328], 99.99th=[19328] bw ( KiB/s) : min=229376, max=294912, per=100.00%, avg=263201.03, stdev=15791.93, samples=31 iops: min= 14, max= 18, avg=16.06, stdev= 0.96, samples=31 lat (usec) : 4=11.33%, 10=85.16%, 20=3.52% fsync/fdatasync/sync_file_range: sync (nsec) : min=220, max=2550, avg=1182.90, stdev=474.05 sync percentiles (nsec): 1.00th[3301], 5.00th[410], 10.00th[524], 20.00th[700], 30.00th[900], 40.00th[1064], 50.00th[1176], 60.00th[1336], 70. 00th[1432], 80.00th[1608], 90.00th[1848], 95.00th[2008], 99.00th[2192], 99.50th[2352], 99.90th[2544], 99.95th[2544], 99.99th[2544] cpu usr=1.26%, sys=0.51%, ctx=4608, majf=0, minf=11 IO depths : 1=199.6%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, \u0026gt;64=0.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u0026gt;64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u0026gt;64=0.0% issued rwts: total=0, 256, 0, 255 short=0, 0, 0, 0 dropped=0, 0, 0, 0 latency : target=0, window=0, percentile=100.00%, depth=1 Run status group 0 (all jobs): WRITE: bw=257MiB/s (269MB/s), 257MiB/s-257MiB/s (269MB/s-269MB/s), io=4096MiB (4295MB), run=15937-15937msec io路径分析\nnfs → 通过前端网络 → JuiceFS → 通过后端网络 → 分布式持久层 → 磁盘\nnfs向JuiceFS并发发送io请求，JuiceFS将收到的数据暂写入缓存，达到指定大小后写缓存分布式持久层，分布式持久层返回后该次落盘操作才算成功\n因此上述过程中存在2个时延，第一个时延为JuiceFS等待io请求，直到io请求达到指定大小；第二个时延为JuiceFS等待分布式持久层返回\n理论上这两个时延时间一致且周期一致，性能最优\n3 性能分析环境配置及操作 3.1 测试环境 服务端配置：曙光Rack/R6440H0 * 3; 2U 32Core; RAM 128G 网络：fio和mdtest测试：3服务端，1客户端，均组bond6_front，网络最大带宽20G/s 3.2 测试配置 首先JuiceFS在块大小 \u0026gt;= 16m时会直接将数据写对象，因此测试块大小16M的文件写入时需要调大写对象块大小上限，同时打开文件元数据缓存和目录项缓存超时时间来提高连续写入效率\n需修改的配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 juicefs: cacheDir: /var/powercache uploadDelay: 10m trashDays: 0 logDir: \u0026#34;/var/log/juicefs\u0026#34; xxxClientPackagePath: \u0026#34;/opt/xxx/xxx_client.tar\u0026#34; xxxClientPort: 33999 backupMeta: 24h attr-cache: 1 # 修改项 entry-cache: 1 # 修改项 dir-entry-cache: 1 # 修改项 namespaceRootDir: \u0026#34;/xxx\u0026#34; disable-lock: false cache-type: free-ratio-raw: 0.15 free-ratio-staging: 0.10 extendedParams : \u0026#34;--upload-block-size 32 max-uploads 32 --flush-by-no-write 100\u0026#34; # 修改项 bucketName: xxx-03e89688 测试前准备\n在服务端view上共享1个NFS文件夹nfstest 在客户端挂载该目录: mount -t nfs -o vers=3 业务网:/xxx/nfstest /mnt/nfstest 在客户端执行fio和mdtest进行测试 3.3 测试操作 执行cp复制3.5G文件结果 1 [root@node1]# time cp openEuler-22.03-LTS-SP1-x86_64-dvd.iso /mnt/nfstest/testos real 0m8.210s user 0m0.000s sys 0m2.236s 1 [root@node1]# ls -1lh openEuler-22.03-LTS-SP1-x86_64-dvd.iso root root 3.5G Nov 25 09:58 openEuler-22.03-LTS-SP1-x86_64-dvd.iso\n执行2个fio测试，参数及结果如下\n(1)4K随机写入:\n1 fio -directory=/mnt/nfstest/test1 -ioengine=libaio -iodepth=1 -direct=1 -fsync=1 -bs=4K -flesize=8M --rw=write -numjobs=56 -name=fiotest -group_reporting -output=4k_randw.data 结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 fiotest: (groupid=0, jobs=56): err= 0: pid=1668325: Sat Nov 25 16:48:17 2023 write: I0PS=2444, BW=9778KiB/s (10.0MB/s)(448MiB/46919msec); 0 zone resets slat (nsec): min=1551, max=q7180, avg=3033.72, stdev=2019.74 clat (msec): min=6, max=438, avg=21.69, stdev=22.42 Lat (msec): min=6, max=438, avg=21.70, stdev=22.42 clat percentiles (msec): 1 1.00th=[q], 5.00th=[11], 10.00th=[12], 20.00th=[13], 30.00th=[15], 40.00th=[16], 50.00th=[18], 60.00th=[20], 70.00th=[22], 80.00th=[25], 90.00th=[34], 95.00th=[42], 99.00th=[79], 99.50th=[220], 99.90th=[239], 99.95th=[251], 99.99th=[430] bw ( KiB/s): min= 1752, max=19184, per=100.00%, avg=10366.19, stdev=53.86, samples=4947 iops : min= 438, max= 4796, avg=2591.49, stdev=13.46, samples=4947 lat (msec) : 10=4.31%，20=60.64%，50=32.90%，100=1.18%，250=0.90% lat (msec) : 500=0.05% fsync/fdatasync/sync_file_range: sync (nsec): min=16, max=4702, avg=40.81, stdev=30.54 sync percentiles (nsec): 1.00th=[22]， 5.00th=[23], 10.00th=[26], 20.00th=[32], 30.00th=[33], 40.00th=[34], 50.00th=[34], 60.00th=[39] 70.00th=[43],80.00th=[47], 90.00th=[54], 95.00th=[64], 99.00th=[145], 99.50th=[151], 99.90th=[193]，99.95th=[338], 99.99th=[532] cpu : usr=0.01%, sys=0.03%, ctx=114944, majf=0, minf=56 I0 depths : 1=200.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, \u0026gt;=64=0.0% submit : 0=0.0%， 4=100.0%， 8=0.0%， 16=0.0%， 32=0.0%， 64=0.0%， \u0026gt;=64=0.0% complete : 0=0.0%， 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u0026gt;=64=0.0% issued rwts: total=0,114688,0,114632 short=0,0,0,0 dropped=0,0,0,0 Latency : target=0, window=0, percentile=100.00%, depth=1 Run status group 0 (all jobs): WRITE: bw=9778KiB/s (10.0MB/s), 9778KiB/s-9778KiB/s (10.0MB/s-10.0MB/s), io=448MiB (470MB), run=46919-46919msec (2)16M大文件连续写入：\n1 fio -directory=/mnt/nfstest/test2 -ioengine=libaio -iodepth=1 -direct=1 -fsync=1 -bs=16M -filesize=1G --rw=write -numjobs=16 -name=fiotest -group_reporting -output=16_w.data 结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 fiotest2: (groupid=0, jobs=16): err= 0: pid=166q561: Sat Nov 25 16:49:02 2023 write: I0PS=38, BW=608MiB/s (638MB/s)(16.0GiB/26934msec); 0 zone resets slat (usec): min=1144, max=3439, avg=1612.21, stdev=208.03 clat (msec): min=142, max=643, avg=414.0q, stdev=41.20 lat (msec): min=144, max=644, avg=415.70, stdev=41.15 clat percentiles (msec): 1.00th=[284]， 5.00th=[355], 10.00th=[368], 20.00th=[384], 30.00th=[397], 40.00th=[409], 50.00th=[418], 60.00th=[426], 70.00th=[439], 80.00th=[447], 90.00th=[460], 95.00th=[468], 99.00th=[489], 99.50th=[502], 99.90th=[542], 99.95th=[642], 99.99th=[642] bw ( KiB/s): min=523436, max=1048576, per=100.00%, avg=624827.94, stdev=12902.57, samples=845 iops: min=25，max=64, avg=38.00, stdev=0.80, samples=845 lat (msec) : 250=0.68%，500=98.83%, 750=0.49% fsync/fdatasync/sync_file_range: sync (nsec): min=16, max=604, avg=159.23, stdev=85.32 sync percentiles (nsec): 1.00th=[35]， 5.00th=[56], 10.00th=[70], 20.00th=[129] , 30.00th=[139], 40.00th=[147], 50.00th=[151], 60.00th=[157] , 70.00th=[161], 80.00th=[169], 90.00th=[191], 95.00th=[342], 99.00th=[540], 99.50th=[580], 99.90th=[604], 99.95th=[604], 99.99th=[604] cpu usr=0.17%, sys=0.21%, ctx=1082, majf=0, minf=16 I0 depths : 1=198.4%， 2=0.0%， 4=0.0%， 8=0.0%， 16=0.0%， 32=0.0%， \u0026gt;=64=0.0% submit ： 0=0.0%， 4=100.0%， 8=0.0%， 16=0.0%， 32=0.0%， 64=0.0%， \u0026gt;=64=0.0% complete : 0=0.0%， 4=100.0%， 8=0.0%， 16=0.0%， 32=0.0%， 64=0.0%， \u0026gt;=64=0.0% issued rwts: total=0,1024,0,1008 short=0,0,0,0 dropped=0,0,0,0 Latency : target=0, window=0, percentile=100.00%, depth=1 Run status group 0 (all jobs): WRITE: bw=608MiB/s (638MB/s), 608MiB/s-608MiB/s (638MB/s-638MB/s)， io=16.0GiB (17.2GB), run=26934-26934msec 执行3次mtest元数据测试 1 2 3 4 5 $ mpirun --allow-run-as-root localhost:64 -np 64 mdtest -I 20 -z 2 -b 10 -w 131072 -e 131072 -d /mnt/nfstest/perf1 -t -u $ mpirun --allow-run-as-root localhost:56 -np 56 mdtest -I 50 -z 2 -b 10 -w 524288 -e 524288 -d /mnt/nfstest/perf2 -t -u $ mpirun --allow-run-as-root localhost:32 -np 32 mdtest -I 20 -z 2 -b 10 -w 1048576 -e 1048576 -d /mnt/nfstest/perf3 -t -u 结果略\n4 测试中产生的部分数据 iostat - 每块磁盘IO情况\nmpstat - 系统CPU资源占用情况\njuicefs stat - JuiceFS实时性能指标\njuicefs .perfmetric - JuiceFS单位时间内IO情况\njuicefs .accesslog - JuiceFS访问日志\n具体数据略\n5 测试结果分析 观察到2个问题\n从perfmetric看出，每次JuiceFS写分布式持久层大小(write_cache)不均，理论应该是统一大小 从accesslog看出，刷新时间不均衡，连续写文件理论上间隔应该统一 针对问题1，推测可能是NFS问题，尝试在服务器本地写JuiceFS，观察perfmetric日志，发现写入大小一致，证明推测成立，是NFS客户端单位时间内发出的IO大小不一致导致\n针对问题2，推测有其他机制触发刷新，将强制刷新时间更改为100s，再次写入数据查看accesslog，发现还是有不均匀的刷新，支持推测成立\n","date":"2023-11-27T00:00:00Z","permalink":"https://morsuning.github.io/p/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","title":"记一次文件系统性能测试"},{"content":"本文的目标是以一篇文章的篇幅，介绍存储领域的各种概念以及他们是用来解决什么需求的\n这次聊一聊存储相关的概念，就是计算机基础架构中的三个主要领域计算、存储和网络中的存储\n存储架构 jbod san nas\n数据冗余技术 ecc纠删码 多副本\nSDS\n存储方式 分布式存储类型 对象存储，块存储，文件存储\n集中式存储，分布式存储https://www.zhihu.com/question/343713625\n存储介质 存储介质 ssd hdd scm\n硬件支持技术 nvme-of fiber iSCSI\nRDMA\nSPDK\n存储访问协议 网络文件系统及接口 NFS CIFS SMB HDFS Lustre POSIX\n存储访问协议 Amazon S3协议 https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html\nLinux文件系统 Linux文件系统类型 磁盘文件系统 内存文件系统 网络文件系统\n存储系统监控和管理 存储系统监控和管理\n典型存储项目 存储项目 minIO Ceph daos JuiceFS\n从一个通常的具有计算机使用经验的人展开，存储方式，存储介质，文件系统，访问协议sds\n","date":"2023-09-15T00:00:00Z","permalink":"https://morsuning.github.io/p/%E5%AD%98%E5%82%A8%E9%A2%86%E5%9F%9F%E7%9A%84%E6%A6%82%E5%BF%B5/","title":"存储领域的概念"},{"content":"一 Golang错误处理机制panic和recover简要介绍 使用panic抛出异常后, 将立即停止当前函数的执行并运行所有被defer的函数，然后将panic抛向上一层，直至程序crash。但是也可以使用被defer的recover函数来捕获异常阻止程序的崩溃，recover只有被defer后才是有意义的 使用示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main() { print(123) defer func() { if err := recover(); err != nil { print(\u0026#34;recover it\u0026#34;) } }() print(456) panic(\u0026#34;throw an error\u0026#34;) print(678) //IDE会有提示: Unreachable code } 输出结果为：\n1 123456recover it 如果有两个recover，则捕获异常的是后一个（defer遵循栈规划，即后定义的优先触发） panic之后的任何代码都不会继续执行，前提是panic不在if里面 使用panic抛出异常后, 将立即停止当前函数的执行并运行所有被defer的函数，然后将panic抛向上一层，直至程序crash，但是也可以使用被defer的recover函数来捕获异常阻止程序的崩溃，recover只有被defer后才是有意义的 对于goroutine中的panic，协程外面的recover是无法恢复的；goroutine中的recover，同样无法恢复协程外的panic；但协程中的recover可以恢复协程中的panic 主方法中的recover，也可以恢复子方法里的panic 因为panic发生的时候，panic函数后面的语句都不会执行了，所以recover函数不能放在panic语句后面执行，而要放在defer函数中执行 使用 panic 抛出异常后，函数执行将从调用 panic 的地方停止，如果函数内有 defer 调用，则执行 defer 后边的函数调用，如果 defer 调用的函数中没有捕获异常信息，这个异常会沿着函数调用栈往上传递，直到 main 函数仍然没有捕获异常，将会导致程序异常退出 recover不能捕获所有错误，以下是不能捕获的情形 堆栈内存耗尽(如递归) 并发读写 map fatal error: concurrent map read and map write 将 nil 函数作为 goroutine 启动 fatal error: go of nil func value goroutines 死锁 fatal error: all goroutines are asleep - deadlock! 线程超过设置的最大限制 fatal error: thread exhaustion 超出可用内存 fatal error: runtime: out of memory 二 推荐使用场景 panic 在程序启动的时候，如果有强依赖的服务出现故障时 panic 退出 在程序启动的时候，如果发现有配置明显不符合要求， 可以 panic 退出（防御编程） 其他情况下只要不是不可恢复的程序错误，都不应该直接 panic 应该返回 error 在程序入口处，例如 gin 中间件需要使用 recover 预防 panic 程序退出 在程序中应该避免使用野生的 goroutine 如果是在请求中需要执行异步任务，应该使用异步 worker ，消息通知的方式进行处理，避免请求量大时大量 goroutine 创建 如果需要使用 goroutine 时，应该使用同一的 Go 函数进行创建，这个函数中会进行 recover ，避免因为野生 goroutine panic 导致主进程退出 1 2 3 4 5 6 7 8 9 10 11 func Go(f func()){ go func(){ defer func(){ if err := recover(); err != nil { log.Printf(\u0026#34;panic: %+v\u0026#34;, err) } }() f() }() } error 在应用程序中使用 github.com/pkg/errors 处理应用错误，注意在公共库当中，一般不使用这个 error 应该是函数的最后一个返回值，当 error 不为 nil 时，函数的其他返回值是不可用的状态，不应该对其他返回值做任何期待 func f() (io.Reader, *S1, error) 在这里，不知道 io.Reader 中是否有数据，可能有，也有可能有一部分 错误处理的时候应该先判断错误， if err != nil 出现错误及时返回，使代码是一条流畅的直线，避免过多的嵌套 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // good case func f() error { a, err := A() if err != nil { return err } // ... 其他逻辑 return nil } // bad case func f() error { a, err := A() if err == nil { // 其他逻辑 } return err } 在应用程序中出现错误时，使用 errors.New 或者 errors.Errorf 返回错误 1 2 3 4 5 6 7 8 func (u *usecese) usecase1() error { money := u.repo.getMoney(uid) if money \u0026lt; 10 { errors.Errorf(\u0026#34;用户余额不足, uid: %d, money: %d\u0026#34;, uid, money) } // 其他逻辑 return nil } 如果是调用应用程序的其他函数出现错误，请直接返回，如果需要携带信息，请使用 errors.WithMessage 1 2 3 4 5 6 7 8 9 func (u *usecese) usecase2() error { name, err := u.repo.getUserName(uid) if err != nil { return errors.WithMessage(err, \u0026#34;其他附加信息\u0026#34;) } // 其他逻辑 return nil } 如果是调用其他库（标准库、企业公共库、开源第三方库等）获取到错误时，请使用 errors.Wrap 添加堆栈信息\n切记，不要每个地方都是用 errors.Wrap 只需要在错误第一次出现时进行 errors.Wrap 即可 根据场景进行判断是否需要将其他库的原始错误吞掉，例如可以把 repository 层的数据库相关错误吞掉，返回业务错误码，避免后续分割微服务或者更换 ORM 库时需要去修改上层代码 注意在基础库，被大量引入的第三方库编写时一般不使用 errors.Wrap 避免堆栈信息重复 1 2 3 4 5 6 7 8 9 func f() error { err := json.Unmashal(\u0026amp;a, data) if err != nil { return errors.Wrap(err, \u0026#34;其他附加信息\u0026#34;) } // 其他逻辑 return nil } 禁止每个出错的地方都打日志，只需要在进程的最开始的地方使用 %+v 进行统一打印，例如 http/rpc 服务的中间件\n错误判断使用 errors.Is 进行比较\n1 2 3 4 5 6 7 8 9 func f() error { err := A() if errors.Is(err, io.EOF){ return nil } // 其他逻辑 return nil } 错误类型判断，使用 errors.As 进行赋值 1 2 3 4 5 6 7 8 9 10 11 func f() error { err := A() var errA errorA if errors.As(err, \u0026amp;errA){ // ... } // 其他逻辑 return nil } 如何判定错误的信息是否足够，想一想当你的代码出现问题需要排查的时候你的错误信息是否可以帮助你快速的定位问题，例如在请求中一般会输出参数信息，用于辅助判断错误 对于业务错误，推荐在一个统一的地方创建一个错误字典，错误字典里面应该包含错误的 code，并且在日志中作为独立字段打印，方便做业务告警的判断，错误必须有清晰的错误文档 不需要返回，被忽略的错误必须输出日志信息 同一个地方不停的报错，最好不要不停输出错误日志，这样可能会导致被大量的错误日志信息淹没，无法排查问题，比较好的做法是打印一次错误详情，然后打印出错误出现的次数 对同一个类型的错误，采用相同的模式，例如参数错误，不要有的返回 404 有的返回 200 处理错误的时候，需要处理已分配的资源，使用 defer 进行清理，例如文件句柄 何时使用panic，何时使用error 在 Go 中 panic 会导致程序直接退出，是一个致命的错误，如果使用 panic recover 进行处理的话，会存在很多问题 性能问题，频繁 panic recover 性能不好 容易导致程序异常退出，只要有一个地方没有处理到就会导致程序进程整个退出 不可控，一旦 panic 就将处理逻辑移交给了外部，我们并不能预设外部包一定会进行处理 什么时候使用 panic 呢？ 对于真正意外的情况，那些表示不可恢复的程序错误，例如索引越界、不可恢复的环境问题、栈溢出，才使用 panic 使用 error 处理有哪些好处？ 简单 考虑失败，而不是成功(Plan for failure, not success) 没有隐藏的控制流 完全交给你来控制 error Error are values 返回错误时的抉择 这是一个不需要额外信息的简单错误吗？如果是，errors.New即可 客户需要检测并处理此错误吗？如果是，则应该使用自定义类型并实现该Error()方法，可添加更多信息 是否正在传播下游函数返回的错误而且需要添加上下文信息？如果是，则应该包装此错误 否则fmt.Errorf就可以 如果要将错误发送到另一个系统，就应该明确是错误消息及来源 三 Q \u0026amp; A 1. 为什么标准库中 errors.New 会返回一个指针？ 翻看标准库的源代码可以发现， errors 库中的 errorString 结构体实现了 error 接口，为什么在 New 一个 error 的时候会返回一个结构体的指针呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // New returns an error that formats as the given text. // Each call to New returns a distinct error value even if the text is identical. func New(text string) error { return \u0026amp;errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 先来看一个例子，同样创建了 errorString 的结构体，自定义的和标准库中的唯一不同就是，自建的这个返回的是值，而不是指针。\n在 main 函数的对比中就可以发现，自定义的 errorString 在对比的时候只要对应的字符串相同就会返回 true，但是标准库的包不会。\n这是因为，在对比两个 struct 是否相同的时候，会去对比，这两个 struct 里面的各个字段是否是相同的，如果相同就返回 true，但是对比指针的时候会去判断两个指针的地址是否一致。\n2. 如果字符串相等就返回 true 会导致什么问题呢？ 如果有两个包，定义了两个错误，他们其实是两个相同的字符串，在其他库调用对比的时候，可能会由于不同的书写顺序，走进不同的分支导致一些奇奇怪怪的错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 type errorString struct { text string } func (e errorString) Error() string { return e.text } // New 创建一个自定义错误 func New(s string) error { return errorString{text: s} } var errorString1 = New(\u0026#34;test a\u0026#34;) var err1 = errors.New(\u0026#34;test b\u0026#34;) func main() { if errorString1 == New(\u0026#34;test a\u0026#34;) { fmt.Println(\u0026#34;err string a\u0026#34;) // 会输出 } if err1 == errors.New(\u0026#34;test b\u0026#34;) { fmt.Println(\u0026#34;err b\u0026#34;) // 不会输出 } } 3. error type: 错误定义与判断 Sentinel Error 哨兵错误，就是定义一些包级别的错误变量，然后在调用的时候外部包可以直接对比变量进行判定，在标准库当中大量的使用了这种方式\n例如下方 io 库中定义的错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // EOF is the error returned by Read when no more input is available. // Functions should return EOF only to signal a graceful end of input. // If the EOF occurs unexpectedly in a structured data stream, // the appropriate error is either ErrUnexpectedEOF or some other error // giving more detail. var EOF = errors.New(\u0026#34;EOF\u0026#34;) // ErrUnexpectedEOF means that EOF was encountered in the // middle of reading a fixed-size block or data structure. var ErrUnexpectedEOF = errors.New(\u0026#34;unexpected EOF\u0026#34;) // ErrNoProgress is returned by some clients of an io.Reader when // many calls to Read have failed to return any data or error, // usually the sign of a broken io.Reader implementation. var ErrNoProgress = errors.New(\u0026#34;multiple Read calls return no data or error\u0026#34;) 在外部判定的时候一般使用等值判定或者使用 errors.Is 进行判断\n1 2 3 4 5 6 7 if err == io.EOF { //... } if errors.Is(err, io.EOF){ //... } 这种错误处理方式有一个问题是，将 error 当做包的 API 暴露给了第三方，这样会导致在做重构或者升级的时候很麻烦，并且这种方式包含的错误信息会十分的有限\nerror types 这个就类似前面定义的 errorString 一样实现了 error 的接口，然后在外部是否类型断言来判断是否是这种错误类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type MyStruct struct { s string name string path string } // 使用的时候 func f() { switch err.(type) { case *MyStruct: // ... case others: // ... } } 这种方式相对于哨兵来说，可以包含更加丰富的信息，但是同样也将错误的类型暴露给了外部，例如标准库中的 os.PathError\nOpaque errors 不透明的错误处理，这种方式最大的特点就是只返回错误，暴露错误判定接口，不返回类型，这样可以减少 API 的暴露，后续的处理会比较灵活，这个一般用在公共库会比较好\n1 2 3 4 5 6 7 8 type temporary interface { Temporary() bool } func IsTemporary(err error) bool { te, ok := err.(temporary) return ok \u0026amp;\u0026amp; te.Temporary() } 这种方式可以断言错误实现了特定的行为，而不是断言错误是特定的类型或值\n4. error handle: 错误处理优化 在 go 中常常会存在大量的 if err 代码，下面介绍两种常见的减少这种代码的方式\nbufio.scan\n对比下面两个函数的处理可以发现， count2 使用 sc.Scan 之后一个 if err 的判断都没有，极大的简化了代码，这是因为在 sc.Scan 做了很多处理，像很多类似的，需要循环读取的都可以考虑像这样包装之后进行处理，这样外部包调用的时候就会非常简洁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // 统计文件行数 func count(r io.Reader) (int, error) { var ( br = bufio.NewReader(r) lines int err error ) for { // 读取到换行符就说明是一行 _, err = br.ReadString(\u0026#39;\\n\u0026#39;) lines++ if err != nil { break } } // 当错误是 EOF 的时候说明文件读取完毕了 if err != io.EOF { return 0, err } return lines, err } func count2(r io.Reader) (int, error) { var ( sc = bufio.NewScanner(r) lines int ) for sc.Scan() { lines++ } return lines, sc.Err() } error writer\n看一个来自 go blog 的例子：https://blog.golang.org/errors-are-values\n一般代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 _, err = fd.Write(p0[a:b]) if err != nil { return err } _, err = fd.Write(p1[c:d]) if err != nil { return err } _, err = fd.Write(p2[e:f]) if err != nil { return err } // and so on errWriter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 type errWriter struct { w io.Writer err error } func (ew *errWriter) write(buf []byte) { if ew.err != nil { return } _, ew.err = ew.w.Write(buf) } // 使用时 ew := \u0026amp;errWriter{w: fd} ew.write(p0[a:b]) ew.write(p1[c:d]) ew.write(p2[e:f]) // and so on if ew.err != nil { return ew.err } 如果去翻 标准库中 bufio.Writer 的源代码，你会发现也有这种用法，这种就是将重复的逻辑进行了封装，然后把 error 暂存，然后就只需要在最后判断一下 error 就行了\n5. wrap error: 错误包装 errors.wrap 有何作用，为什么不用标准库的 fmt.Errorf(\u0026quot;%w\u0026quot;) 先看一下标准库的源码，我们可以发现当 p.wrappedErr != nil 的时候（也就是有 %w）的时候，会使用一个 wrapError 将错误包装，看 wrapError 的源码可以发现，这个方法只是包装了一下原始错误，并且可以做到附加一些文本信息，但是没有堆栈信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func Errorf(format string, a ...interface{}) error { p := newPrinter() p.wrapErrs = true p.doPrintf(format, a) s := string(p.buf) var err error if p.wrappedErr == nil { err = errors.New(s) } else { err = \u0026amp;wrapError{s, p.wrappedErr} } p.free() return err } type wrapError struct { msg string err error } func (e *wrapError) Error() string { return e.msg } func (e *wrapError) Unwrap() error { return e.err } 在看一下 pkg/errors 的源码，我肯可以发现除了使用 withMessage 附加了错误信息之外还使用 withStack 附加了堆栈信息，这样在程序入口处打印日志信息的时候就可以将堆栈信息一并打出了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Wrap returns an error annotating err with a stack trace // at the point Wrap is called, and the supplied message. // If err is nil, Wrap returns nil. func Wrap(err error, message string) error { if err == nil { return nil } err = \u0026amp;withMessage{ cause: err, msg: message, } return \u0026amp;withStack{ err, callers(), } } 6. 为什么不允许处处使用 errors.Wrap 因为每一次 errors.Wrap的调用都会为错误添加堆栈信息，如果处处调用那会有大量的无用堆栈\n先看一下只有一处 wrap\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func main() { fmt.Printf(\u0026#34;err: %+v\u0026#34;, c()) } func a() error { return errors.Wrap(fmt.Errorf(\u0026#34;xxx\u0026#34;), \u0026#34;test\u0026#34;) } func b() error { return a() } func c() error { return b() } 看结果可以发现已经可以打印出全部的堆栈信息了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 err: xxx test main.a /home/ll/project/Go-000/Week02/blog/wrap.go:14 main.b /home/ll/project/Go-000/Week02/blog/wrap.go:18 main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 再看多处 wrap 的现象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func main() { fmt.Printf(\u0026#34;err: %+v\u0026#34;, c()) } func a() error { return errors.Wrap(fmt.Errorf(\u0026#34;xxx\u0026#34;), \u0026#34;a\u0026#34;) } func b() error { return errors.Wrap(a(), \u0026#34;b\u0026#34;) } func c() error { return errors.Wrap(b(), \u0026#34;c\u0026#34;) } 可以看到每一处 wrap 都添加了一次堆栈信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 err: xxx a main.a /home/ll/project/Go-000/Week02/blog/wrap.go:14 main.b /home/ll/project/Go-000/Week02/blog/wrap.go:18 main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 b main.b /home/ll/project/Go-000/Week02/blog/wrap.go:18 main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 c main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 7. 标准库 errors.Is / As 怎么判断错误 errors.Is 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func Is(err, target error) bool { if target == nil { return err == target } // 通过反射判读 target 是否可以被比较 isComparable := reflectlite.TypeOf(target).Comparable() for { // 循环判断是否相等 if isComparable \u0026amp;\u0026amp; err == target { return true } // 判断是否实现了 is 接口，如果有实现就直接判断 if x, ok := err.(interface{ Is(error) bool }); ok \u0026amp;\u0026amp; x.Is(target) { return true } // 去判断是否实现了 unwrap 的接口，如果实现了就进行 unwrap if err = Unwrap(err); err == nil { return false } } } errors.As 和 is 的逻辑类似，就是不断的进行 unwrap 进行比较，只要有一个相同就返回，如果一直到底都不行就返回 false\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func As(err error, target interface{}) bool { if target == nil { panic(\u0026#34;errors: target cannot be nil\u0026#34;) } val := reflectlite.ValueOf(target) typ := val.Type() if typ.Kind() != reflectlite.Ptr || val.IsNil() { panic(\u0026#34;errors: target must be a non-nil pointer\u0026#34;) } if e := typ.Elem(); e.Kind() != reflectlite.Interface \u0026amp;\u0026amp; !e.Implements(errorType) { panic(\u0026#34;errors: *target must be interface or implement error\u0026#34;) } targetType := typ.Elem() for err != nil { if reflectlite.TypeOf(err).AssignableTo(targetType) { val.Elem().Set(reflectlite.ValueOf(err)) return true } if x, ok := err.(interface{ As(interface{}) bool }); ok \u0026amp;\u0026amp; x.As(target) { return true } err = Unwrap(err) } return false } ","date":"2023-06-21T00:00:00Z","permalink":"https://morsuning.github.io/p/go%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","title":"Go错误处理最佳实践"},{"content":"云原生漫谈 云原生的5w1h，what，why，where，how，who when -\u0026gt; anytime 云原生概念(定义、优势、总结); 云原生技术领域介绍：容器-\u0026gt;容器编排-\u0026gt;服务治理(简要介绍代表技术Docker、Kubernetes、Istio和Linkerd)、微服务架构 \u0026amp; Serverless架构、DevOps \u0026amp; 可观测性; Kubernetes简介(如何满足12-Factor)、架构及开发方式; 应用的现代化改造思路; 云原生时代下的团队(对新出现一些岗位和名词的解释); CNCF(简介、对cncf landscape的介绍);\nWhat - 云原生的定义与核心概念 定义演进 云原生概念并非一蹴而就，而是随着云计算技术的发展逐步形成的。其定义经历了从简单到复杂、从单一到系统的演进过程：\n早期定义（2013-2015）： Pivotal 公司的 Matt Stine 在2015年首次系统性地提出了云原生概念，将其定义为包含12-Factor应用原则、微服务架构、自服务敏捷架构、基于API的协作和抗脆弱性的综合体系。\nCNCF官方定义（2017至今）：\n云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。\n权威专家观点： Martin Fowler 强调，云原生描述了一种高效组织的模式，可以快速地、一致地、可靠地、规模化地交付软件。持续交付、DevOps 和微服务这三个核心要素分别指明了为什么、怎么样和什么是云原生。\n核心特征 云原生架构具备以下核心特征：\n容器化封装：基于容器技术实现应用封装和隔离 动态编排：通过容器编排平台实现资源的动态调度 微服务架构：将应用拆分为小型、独立的服务单元 服务治理：提供服务发现、负载均衡、熔断降级等能力 声明式API：通过声明而非命令的方式来描述期望状态 不可变基础设施：基础设施变更通过替换而非修改实现 云原生12要素（12-Factor） 云原生12要素由 Heroku 公司的 Adam Wiggins 提出，是构建现代化云原生应用的重要指导原则：\n1. 基准代码（Codebase） 原则：一份基准代码，多份部署 实践：所有部署的基准代码相同，但每份部署可以使用不同版本 意义：确保开发、测试、生产环境的一致性 2. 依赖（Dependencies） 原则：显式声明依赖关系 实践：通过依赖清单（如 package.json、requirements.txt）确切声明所有依赖项 意义：避免依赖地狱，确保环境一致性 3. 配置（Config） 原则：在环境中存储配置 实践：将应用配置存储于环境变量中 意义：不同部署间修改配置无需改动代码 4. 后端服务（Backing Services） 原则：把后端服务当做附加资源 实践：应用不区别对待本地或第三方服务 意义：实现服务解耦，便于替换和扩展 5. 构建、发布、运行（Build, Release, Run） 原则：严格区分构建、发布、运行三个阶段 实践：构建阶段将代码转换为可执行包，发布阶段将构建产物与配置结合 意义：确保部署流程的可控性和可追溯性 6. 进程（Processes） 原则：以一个或多个无状态进程运行应用 实践：应用进程必须无状态且无共享 意义：支持水平扩展和故障恢复 7. 端口绑定（Port Binding） 原则：通过端口绑定提供服务 实践：应用完全自我加载，通过端口直接对外服务 意义：实现应用的独立性和可移植性 8. 并发（Concurrency） 原则：通过进程模型进行扩展 实践：运用进程模型设计应用架构，分配不同工作给不同进程类型 意义：支持应用的弹性伸缩 9. 易处理（Disposability） 原则：快速启动和优雅终止可最大化健壮性 实践：应用进程可瞬间开启或停止 意义：提高系统的可靠性和资源利用率 10. 开发环境与线上环境等价（Dev/Prod Parity） 原则：尽可能保持开发、预发布、线上环境相同 实践：缩小本地与线上差异，实现持续部署 意义：减少环境不一致导致的问题 11. 日志（Logs） 原则：把日志当做事件流 实践：应用不存储或管理日志文件，而是输出到标准输出 意义：实现日志的集中管理和分析 12. 管理进程（Admin Processes） 原则：后台管理任务当做一次性进程运行 实践：一次性管理进程与常驻进程使用相同环境 意义：确保管理操作的一致性 Why - 云原生的价值与优势 发展历程与驱动力 云原生的兴起不是偶然，而是技术发展和业务需求共同推动的必然结果：\n技术演进脉络：\n2000-2008：虚拟化技术兴起（VMware、Xen） 2008-2013：云计算普及（AWS、OpenStack） 2013-2016：容器化革命（Docker 2013年发布） 2014-2017：容器编排成熟（Kubernetes 2014年开源） 2016-至今：云原生生态繁荣（CNCF成立，服务网格、Serverless等） 业务驱动因素：\n数字化转型加速：企业需要快速响应市场变化 用户体验要求提升：随时可用、按需服务的期望 成本控制压力：IT基础设施投入产出比优化需求 技术债务累积：传统单体架构维护成本高企 核心优势分析 1. 业务敏捷性（Business Agility） 表现：\n快速迭代：从开发到上线的时间从数月缩短到数天甚至数小时 灵活部署：支持跨云、混合云部署，避免厂商锁定 渐进式发布：支持蓝绿部署、金丝雀发布等策略 案例： Netflix 通过云原生架构，能够每天进行数百次部署，快速推出新功能并A/B测试效果。\n2. 系统弹性（Resilience） 表现：\n故障隔离：单个服务故障不影响整体系统 自动恢复：容器重启、服务自愈等机制 弹性伸缩：根据负载自动扩缩容 数据： Google Kubernetes Engine (GKE) 声称可实现99.95%的可用性，年停机时间少于4.38分钟。\n3. 资源效率（Resource Efficiency） 表现：\n高密度部署：容器相比虚拟机资源占用更少 动态调度：资源按需分配，避免浪费 成本优化：Pay-as-you-go的计费模式 对比： 容器启动时间通常在秒级，而虚拟机需要分钟级；容器资源占用通常仅为虚拟机的10-20%。\n4. 开发效率（Developer Productivity） 表现：\n标准化环境：开发、测试、生产环境一致 自动化流水线：CI/CD自动化部署流程 微服务架构：团队可以独立开发、部署、扩展各自的服务 实践： Spotify 的\u0026quot; squad\u0026quot; 模型，每个小团队负责特定的微服务，实现了高度的自治和效率。\n5. 技术创新（Technical Innovation） 表现：\n架构现代化：从单体架构向微服务演进 技术栈灵活：不同服务可选择最适合的技术栈 开源生态：充分利用云原生开源技术红利 解决的核心问题 云原生从根本上解决了软件工程中的几个核心难题：\n1. 复杂性管理（Complexity Management） 问题：大型软件系统固有的复杂性 解决方案：微服务架构将复杂系统分解为简单组件 效果：每个服务职责单一，易于理解和维护 2. 变更适应（Change Adaptation） 问题：业务需求快速变化，传统架构难以适应 解决方案：持续交付和DevOps实践 效果：支持小步快跑、快速验证的开发模式 3. 可扩展性（Scalability） 问题：传统架构扩展成本高、难度大 解决方案：容器编排和自动扩缩容 效果：系统可以根据负载自动调整资源 4. 故障容忍（Fault Tolerance） 问题：组件故障导致系统整体不可用 解决方案：服务治理和容错机制 效果：局部故障不影响整体服务 商业价值量化 根据Puppet《2021年DevOps现状报告》：\n高性能组织特征：\n部署频率：比低绩效组织高208倍 变更前置时间：比低绩效组织快106倍 故障恢复时间：比低绩效组织快2,604倍 变更失败率：比低绩效组织低7倍 具体收益指标：\n开发效率提升：30-50% 运维成本降低：20-40% 系统可用性：从99.9%提升到99.99%+ 产品上市时间：缩短50-70% 这些数据充分说明了云原生在提升组织技术能力和商业竞争力方面的巨大价值。\nWhere - 云原生技术领域 技术栈概览 云原生技术栈形成了一个完整的生态系统，从基础设施到应用开发，涵盖了现代化的方方面面。整个技术栈分为多个层次：最底层是基础设施层，包括公有云、私有云、虚拟机和物理机；向上是容器运行时层，如containerd、CRI-O和Docker；再往上是容器编排层，以Kubernetes为核心；服务治理层提供服务网格、服务发现和配置中心能力；最上层是应用层，支持微服务架构、Serverless和API网关等模式。\n容器技术 Docker：容器化的开创者 历史背景： Docker 最初是 dotCloud 公司内部的一个项目，2013年由 Solomon Hykes 正式开源。它通过将 LXC（Linux Container）技术标准化，极大地简化了容器的使用，开启了容器化时代。\n核心概念：\n镜像（Image）：只读的模板，用于创建容器 容器（Container）：镜像的运行实例 仓库（Registry）：存储镜像的仓库服务（如 Docker Hub） Dockerfile：构建镜像的文本文件 技术优势：\n轻量化：相比虚拟机，容器启动时间从分钟级降至秒级 标准化：一次构建，处处运行 隔离性：进程级隔离，资源限制 可移植性：跨环境部署的一致性 实际应用： Docker 能够快速构建应用镜像、运行容器实例，并支持镜像的分发和管理。\n容器运行时演进 containerd：\nDocker 核心运行时的独立组件 CNCF 毕业项目，工业级标准 提供标准的容器运行时接口（CRI） CRI-O：\n专为 Kubernetes 设计的轻量级容器运行时 支持 OCI（Open Container Initiative）标准 与 Kubernetes 集成更紧密 容器编排 Kubernetes：云原生操作系统 发展历程：\n2014年 Google 基于 Borg 开源 2015年 v1.0 发布 2018年成为 CNCF 毕业项目 目前已成为容器编排的事实标准 核心架构： Kubernetes采用主从架构，Master节点负责集群管理和调度，Worker节点负责运行实际的容器化应用。Master节点包含API Server、Scheduler、Controller Manager和etcd等核心组件，Worker节点运行kubelet、kube-proxy和容器运行时。\n核心组件详解：\n1. API Server\n集群的统一入口，提供 RESTful API 所有组件都要通过 API Server 进行通信 认证、授权、准入控制 2. etcd\n分布式键值存储系统 存储集群的所有状态数据 基于 Raft 协议保证一致性 3. Scheduler\n负责Pod的调度决策 考虑资源需求、亲和性、约束等 支持多种调度策略和插件 4. Controller Manager\n运行各种控制器 Node Controller、Replication Controller等 维持集群的期望状态 5. kubelet\n每个节点上的代理 负责 Pod 的生命周期管理 与容器运行时交互 6. kube-proxy\n服务代理和负载均衡 实现 Service 的网络规则 支持 iptables、IPVS 等模式 Kubernetes 核心概念 Pod：\n最小的部署单元 一个或多个容器的组合 共享网络和存储 Service：\n服务的抽象定义 提供稳定的访问入口 支持多种类型：ClusterIP、NodePort、LoadBalancer Deployment：\n声明式应用部署 支持滚动更新和回滚 确保Pod副本数量 Ingress：\n集群外部访问规则 基于域名的路由 支持SSL终止 服务治理 Istio：服务网格的领军者 背景介绍：\n2017年由 Google、IBM、Lyft 联合开源 2022年成为 CNCF 毕业项目 目前是服务网格领域的事实标准 核心架构： Istio采用数据平面和控制平面分离的架构。数据平面由Envoy代理组成，以Sidecar模式部署在每个应用服务旁边，负责处理服务间的所有通信。控制平面包含Pilot（流量管理）、Citadel（安全策略）和Galley（配置管理）等组件，负责管理和配置数据平面代理。\n核心功能：\n1. 流量管理\n智能路由：基于权重、请求内容的路由 故障注入：模拟故障，测试系统弹性 超时和重试：自动重试和超时控制 熔断器：防止级联故障 2. 安全性\n双向TLS：服务间通信加密 身份认证：基于身份的访问控制 授权策略：细粒度的访问控制 审计日志：完整的安全审计链 3. 可观测性\n指标收集：Prometheus 格式的指标 分布式追踪：Jaeger、Zipkin 集成 访问日志：详细的请求响应日志 Linkerd：轻量级服务网格 特点对比：\n性能：Rust 实现，性能更优 复杂度：架构更简单，学习成本低 资源占用：相比 Istio 资源占用更少 生态：功能相对简单，适合中小规模部署 微服务架构 架构模式 单一职责原则：\n每个服务专注于单一业务功能 独立开发、测试、部署 技术栈可以选择最适合的 API 设计原则：\nRESTful API 或 GraphQL 版本控制策略 向后兼容性设计 数据管理：\n每个服务独立的数据库 数据一致性通过事件驱动保证 分布式事务处理 服务间通信 同步通信：\nHTTP/REST：简单易用 gRPC：高性能，支持流式传输 GraphQL：灵活的数据查询 异步通信：\n消息队列：RabbitMQ、Kafka 事件流：Apache Kafka、Pulsar 发布订阅：Redis Pub/Sub、NATS Serverless 架构 FaaS（Function as a Service） 核心概念：\n按需执行：事件触发，自动扩缩容 按使用量计费：实际运行时间计费 无服务器管理：运维负担最小 主流平台：\nAWS Lambda：市场份额最大 Azure Functions：微软云服务 Google Cloud Functions：谷歌云服务 Apache OpenWhisk：开源实现 BaaS（Backend as a Service） 典型服务：\n数据库服务：DynamoDB、Firestore 认证服务：Auth0、Firebase Auth 存储服务：S3、Blob Storage 消息服务：SNS、Event Grid DevOps 与可观测性 CI/CD 流水线 持续集成：\n代码提交自动构建 自动化测试执行 代码质量检查 持续交付：\n自动化部署到测试环境 人工确认后部署到生产环境 支持回滚和版本管理 工具链：\nJenkins：传统且功能强大 GitLab CI：集成度高，易用性好 GitHub Actions：生态丰富，社区活跃 Argo CD：GitOps 实践 可观测性三大支柱 1. 指标（Metrics）\nPrometheus：CNCF 毕业项目，事实标准 Grafana：可视化展示 AlertManager：告警管理 2. 日志（Logging）\nELK Stack：Elasticsearch + Logstash + Kibana Fluentd：CNCF 毕业项目 Loki：轻量级日志系统 3. 追踪（Tracing）\nJaeger：CNCF 毕业项目，Uber 开源 Zipkin：Twitter 开源，历史悠长 SkyWalking：国产优秀开源项目 总结 云原生技术领域涵盖了从基础设施到应用开发的完整技术栈，每个层次都有成熟的开源解决方案和商业产品。理解这些技术的定位、特点和适用场景，是构建现代化云原生应用的基础。\nHow - 实施路径与最佳实践 应用现代化改造策略 将传统应用改造为云原生应用是一个系统性工程，需要根据应用特点选择合适的改造策略。改造过程通常遵循以下演进路径：\n应用现代化改造遵循从传统单体架构逐步向云原生架构演进的路径，包括容器化封装、微服务拆分、服务网格治理和Serverless优化等阶段。\n改造路径详解 第一阶段：容器化\n目标：将应用打包为容器镜像 关键步骤： 分析应用依赖和环境要求 编写 Dockerfile 和构建脚本 创建容器编排配置 建立镜像仓库和CI/CD流程 第二阶段：容器编排\n目标：实现容器化应用的自动化管理 关键步骤： 学习 Kubernetes 核心概念和API 设计应用的 Kubernetes 部署架构 实现服务发现和负载均衡 配置资源限制和自动扩缩容 第三阶段：微服务拆分\n目标：将单体应用拆分为独立的服务 关键步骤： 识别业务边界和拆分点 设计服务间接口和数据模型 实现API网关和服务注册 处理分布式事务和数据一致性 第四阶段：服务治理\n目标：实现高级的服务治理能力 关键步骤： 引入服务网格（Istio/Linkerd） 配置流量管理和安全策略 建立可观测性体系 实现混沌工程和故障测试 第五阶段：Serverless优化\n目标：最大化资源利用率和运维效率 关键步骤： 识别适合无服务化的业务场景 重构代码为函数式架构 集成事件驱动架构 优化成本和性能 主流改造模式 绞杀者模式（Strangler Fig Pattern） 概念来源： 借鉴自然界的绞杀榕现象，新的藤蔓逐渐包裹并取代老树。在软件架构中，通过逐步替换旧系统的功能来实现现代化改造。\n实施步骤：\n建立反向代理：在单体应用前部署API网关 识别替换点：选择合适的功能模块进行拆分 逐步迁移：将流量逐步切换到新服务 最终替换：完成所有功能迁移后下线旧系统 优势：\n风险可控，每次只迁移少量功能 业务连续性好，用户体验无感知 可以逐步积累微服务经验 实施案例： 通过API网关配置路由规则，可以将特定路径的请求（如\u0026quot;/api/v2/users\u0026quot;）导向新的微服务，而其他请求继续路由到原有的单体应用，实现平滑的渐进式迁移。\n防腐层模式（Anti-Corruption Layer） 概念说明： 在新旧系统之间建立一个适配层，防止新系统被旧系统的设计缺陷\u0026quot;污染\u0026quot;。这个层负责协议转换、数据模型转换和业务逻辑适配。\n应用场景：\n新服务需要调用老服务 老系统调用新服务（反向适配） 数据模型和接口协议不兼容 实现方式： 防腐层通过适配器模式实现新旧系统之间的接口转换。例如，当新系统需要调用旧的用户服务时，防腐层可以调用旧服务获取用户数据，然后将数据结构转换为新的DTO格式，隐藏新旧系统之间的数据结构差异。\n事件驱动迁移模式 核心思想： 通过事件总线作为新旧系统之间的通信桥梁，实现数据的同步和业务流程的协调。\n实施步骤：\n建立事件总线：部署消息队列或事件流平台 定义事件契约：设计标准的事件格式 同步数据：通过事件保持数据一致性 渐进式迁移：逐步将业务逻辑迁移到新系统 Kubernetes原生应用开发 设计原则 1. 声明式配置 通过声明式API能够定义应用的期望状态，Kubernetes会自动维护实际状态与期望状态的一致性。这种方式可以指定副本数量、容器镜像、端口配置等关键参数，实现应用的自动化部署和管理。\n2. 健康检查 健康检查机制通过存活性探针和就绪性探针来监控应用运行状态。存活性探针能够检测容器是否正常运行并在异常时自动重启，就绪性探针可以确保应用完全准备好接收流量后才对外提供服务，从而提高系统的可靠性。\n3. 资源管理 通过设置资源请求和限制可以实现对容器资源的精确控制。资源请求确保容器获得所需的最小资源量，资源限制则防止单个容器占用过多资源影响其他应用，这种机制能够优化集群资源利用率和保证服务质量。\nSidecar模式 概念说明： 将辅助功能容器与主应用容器部署在同一个Pod中，实现功能的解耦和复用。\n典型应用场景：\n1. 日志收集 Sidecar模式能够在同一个Pod中部署日志收集容器与应用容器，通过共享存储卷实现日志数据的实时收集。日志收集容器可以监控应用日志文件的变化，并将日志转发到集中式日志系统，实现日志的统一管理和分析。\n2. 服务代理 通过服务网格的Sidecar注入机制，能够自动在应用容器旁边部署代理容器。这些代理容器负责处理服务间的通信、流量管理、安全策略等跨切面关注点，使应用开发人员可以专注于业务逻辑的实现。\n发布策略 1. 滚动更新（Rolling Update） 滚动更新策略能够实现应用的零停机部署，通过逐步替换旧版本实例来更新应用。这种策略可以控制同时更新的实例数量，确保在整个更新过程中始终有足够的服务实例可用，从而保证服务的连续性。\n2. 蓝绿部署（Blue-Green Deployment） 蓝绿部署通过维护两个完全相同的生产环境来实现快速切换。新版本部署在绿色环境中，测试通过后通过修改服务选择器将流量瞬间切换到新版本，这种方法可以实现快速回滚和零停机发布。\n3. 金丝雀发布（Canary Deployment） 金丝雀发布策略允许将少量流量（如10%）引导到新版本应用，而大部分流量继续使用旧版本。这种渐进式发布方式可以在真实生产环境中验证新版本的稳定性，降低发布风险，同时支持基于请求特征的精确流量控制。\n可观测性实施 监控体系 1. 应用监控 Prometheus监控配置能够自动发现和收集应用指标。通过定义服务监控器，可以指定监控目标、采集间隔和指标路径，实现对应用性能、资源使用情况等关键指标的持续监控和告警。\n2. 日志管理 Fluentd日志收集器能够监控容器日志文件的变化，实时收集和转发日志数据。通过配置输入源、解析格式和输出目标，可以构建统一的日志收集管道，实现日志的集中存储、分析和检索。\n3. 分布式追踪 分布式追踪系统通过在代码中添加追踪注解和手动创建Span，能够记录请求在微服务间的完整调用链路。这种机制可以可视化请求的传播路径、识别性能瓶颈、定位故障点，是实现系统可观测性的重要组成部分。\n最佳实践总结 架构设计 领域驱动设计：基于业务边界进行服务拆分 API优先：先设计API，再实现服务 数据分离：每个服务独立的数据库 异步通信：优先使用消息队列解耦 开发实践 配置外部化：使用 ConfigMap 和 Secret 健康检查：实现标准的健康检查接口 优雅关闭：处理SIGTERM信号 幂等设计：支持重试机制 运维管理 基础设施即代码：使用Git管理配置 自动化测试：完整的测试金字塔 安全扫描：镜像和代码安全检查 成本监控：持续优化资源使用 通过系统性地采用这些策略和最佳实践，组织可以成功地将传统应用改造为现代化的云原生应用，获得云原生带来的所有优势。\nWho - 云原生时代下的团队与人才 组织架构演进 云原生不仅是技术变革，更是组织和文化的变革。传统的开发和运维角色正在被新的角色和协作模式所取代。\n传统团队 vs 云原生团队 传统团队结构： 传统组织采用职能分工的团队结构，开发团队、测试团队和运维团队各自独立工作，通过交付环节衔接，存在沟通壁垒和协作效率低的问题。\n云原生团队结构： 云原生团队采用价值流导向的跨职能协作模式，产品团队、开发团队、平台工程团队和运维/SRE团队共同组成完整的价值交付单元，实现端到端的责任制和快速反馈循环。\n核心角色与职责 1. 云原生工程师（Cloud Native Engineer） 定义： 具备云原生技术栈综合能力的工程师，能够设计、开发和运维云原生应用。\n核心技能：\n容器化技术：Docker、containerd、Podman 容器编排：Kubernetes、Docker Swarm 服务网格：Istio、Linkerd 监控观测：Prometheus、Grafana、Jaeger CI/CD：Jenkins、GitLab CI、Argo CD 编程语言：Go、Python、Java、Node.js 职责范围：\n设计和实施云原生架构 编写基础设施即代码（IaC） 建立CI/CD流水线 实施微服务拆分 配置监控和告警系统 薪资水平：\n初级：15-25万/年 中级：25-40万/年 高级：40-60万/年 专家：60万+/年 2. SRE工程师（Site Reliability Engineer） 历史背景： SRE概念由Google在2003年提出，将软件工程方法应用于基础设施运维，强调通过自动化手段提高系统可靠性。\n核心理念：\n错误预算：允许一定比例的错误存在 自动化运维：减少手动操作，提高效率 可观测性：全面监控和故障诊断 容量规划：前瞻性的资源管理 关键指标：\n可用性目标：通常为99.9%或更高 错误预算：1 - 可用性目标 变更频率：衡量部署效率 恢复时间：衡量故障处理能力 日常工作：\n编写运维脚本和自动化工具 处理生产环境故障 优化系统性能和成本 制定容量规划策略 3. 平台工程师（Platform Engineer） 角色定位： 构建内部开发者平台（IDP），为开发团队提供自助式的开发和部署环境。\n核心产品：\n开发者门户：统一的服务入口 CI/CD模板：标准化的部署流程 环境管理：开发、测试、生产环境 服务目录：可复用的技术组件 技术栈：\nKubernetes Operator：自定义控制器 Crossplane：多云资源管理 Backstage：开发者门户框架 Tekton：云原生CI/CD框架 4. DevOps工程师 核心使命： 打破开发和运维之间的壁垒，建立持续交付的文化和流程。\n能力模型： DevOps工程师需要具备综合性的能力结构，包括技术能力（脚本编程、CI/CD工具链、容器技术、云平台服务）、流程能力（敏捷方法论、持续集成交付、基础设施即代码、监控反馈）以及文化能力（协作沟通、问题解决、持续学习、风险管理），三者并重支撑DevOps实践的有效实施。\n新兴角色分析 1. Kubernetes开发工程师 专业化方向：\nK8s Operator开发：编写自定义控制器 K8s API扩展：开发CRD和Webhook K8s网络插件：CNI插件开发 K8s存储：CSI驱动开发 技能要求：\n深入理解Kubernetes架构 熟练掌握Go语言 了解控制器模式 熟悉client-go库 2. 服务网格工程师 专业领域：\nIstio配置和调优：流量管理、安全策略 Envoy代理：高级网络配置 可观测性集成：分布式追踪、指标收集 安全治理：mTLS、认证授权 3. 云安全工程师 关注领域：\n容器安全：镜像扫描、运行时保护 Kubernetes安全：RBAC、NetworkPolicy、PodSecurity 供应链安全：签名验证、SBOM 合规管理：SOC2、ISO27001、GDPR 4. 混沌工程师 核心理念： 通过主动注入故障来测试系统的弹性，发现潜在问题。\n实践方法：\n故障注入：网络延迟、Pod删除、磁盘满载 故障演练：Game Day、红蓝对抗 监控改进：故障检测和恢复时间 系统加固：提高容错能力 团队协作模式 1. 跨职能团队（Cross-functional Team） 团队组成：\n产品经理（1名） 前端开发（2-3名） 后端开发（3-4名） 测试工程师（1-2名） SRE/运维（1名） UX设计师（1名） 协作特点：\n共同的业务目标 端到端的责任制 快速的反馈循环 自组织的工作方式 2. 平台即产品（Platform as Product） 理念转变： 将基础设施团队转变为产品团队，将内部平台视为产品来开发和运营。\n产品特性：\n用户中心：以开发者体验为核心 持续迭代：基于用户反馈不断改进 文档完善：提供详细的使用指南 技术支持：专门的技术支持团队 3. Guild（行会）模式 组织形式：\nChapter（章节）：垂直的专业技能组 Guild（行会）：水平的技术兴趣组 Tribe（部落）：跨部门的业务单元 协作优势：\n专业知识共享 技术标准统一 创新文化培养 人才成长加速 人才培养路径 1. 技术路线 初级阶段（0-2年）：\n掌握Linux基础和脚本编程 学习容器化技术（Docker） 了解基础云服务 掌握一种编程语言 中级阶段（2-5年）：\n深入Kubernetes生态 掌握CI/CD工具链 学习监控和日志系统 了解微服务架构 高级阶段（5-8年）：\n系统架构设计能力 性能优化和调优 团队管理和 mentoring 技术规划和选型 专家阶段（8年+）：\n技术战略制定 开源项目贡献 行业影响力建设 创新技术探索 2. 认证体系 云原生相关认证：\nCKA/CKAD：Kubernetes管理员/开发者认证 CNCF certifications：各类云原生技术认证 云厂商认证：AWS、Azure、GCP专业认证 安全认证：CISSP、CISA等 3. 学习资源 官方文档：\nKubernetes官方文档 CNCF项目文档 云厂商最佳实践 在线课程：\nCoursera、Udemy平台课程 Cloud Native Computing Foundation培训 KubeAcademy免费课程 实践平台：\nKatacoda交互式教程 Killercoda场景练习 个人实验环境搭建 薪资趋势与前景 1. 市场需求 热门职位排行（2024年）：\n云原生架构师 Kubernetes工程师 DevOps工程师 SRE工程师 平台工程师 2. 薪资水平 一线城市薪资范围：\n初级工程师：15-30万/年 中级工程师：30-50万/年 高级工程师：50-80万/年 架构师/专家：80-150万/年 3. 技能溢价 高需求技能：\nGo语言编程：+20-30% Kubernetes深度：+25-35% 服务网格经验：+20-25% 多云管理：+15-20% 安全专长：+25-30% 云原生时代的团队建设不仅是技能升级，更是思维模式的转变。成功的云原生团队需要具备技术深度、协作能力和持续学习的心态，在快速变化的技术环境中保持竞争力。\nWhen - 云原生应用时机与场景 何时采用云原生 技术成熟度评估 容器化准备度：\n应用架构：是否为12-Factor应用 依赖管理：是否显式声明依赖关系 配置管理：是否支持外部配置 无状态设计：应用是否无状态或可以改造为无状态 团队技能评估：\n技术栈：团队是否掌握容器和编排技术 DevOps实践：是否有CI/CD经验 监控能力：是否具备系统监控和故障处理能力 学习意愿：团队是否有持续学习的文化 业务驱动因素：\n增长预期：业务是否需要快速扩展 更新频率：是否需要频繁发布新功能 可用性要求：对系统可用性的要求程度 成本控制：是否有优化IT成本的压力 最佳应用场景 1. 互联网和移动互联网应用 典型场景：\n电商平台的秒杀活动 社交媒体的高并发访问 在线教育的直播课堂 短视频平台的内容分发 云原生优势：\n弹性伸缩：应对流量峰值 快速迭代：支持A/B测试和灰度发布 全球化部署：多地域就近服务 成本优化：按需使用资源 2. 金融科技（FinTech） 应用场景：\n移动支付系统 量化交易平台 数字银行服务 区块链应用 特殊要求：\n安全合规：满足金融监管要求 高可用性：99.99%以上的可用性 数据一致性：分布式事务处理 审计追踪：完整的操作日志 3. 物联网（IoT）平台 典型特征：\n海量设备连接 数据实时处理 边缘计算需求 低延迟响应 云原生解决方案：\n消息队列：Kafka、Pulsar处理设备数据 流处理：Flink、Spark Streaming实时分析 边缘计算：KubeEdge管理边缘节点 Serverless：函数式处理设备事件 4. 游戏行业 应用场景：\n大型多人在线游戏 手机网络游戏 游戏直播平台 电竞赛事系统 技术需求：\n低延迟：实时互动要求 高并发：大量玩家同时在线 全球部署：就近接入减少延迟 快速扩容：应对玩家数量变化 5. 媒体和娱乐 典型应用：\n视频点播平台 音乐流媒体服务 直播平台 数字内容分发 技术特点：\n大文件处理：视频编码和转码 CDN分发：全球内容分发 个性化推荐：实时内容推荐 版权保护：DRM和加密技术 不适合的场景 1. 传统单体应用 特征：\n架构复杂，耦合度高 数据库设计复杂，大量存储过程 对性能要求极其苛刻（如高频交易） 依赖特定的硬件设备 建议：\n先进行架构重构 逐步容器化 考虑混合部署方案 2. 小型简单应用 特征：\n用户量小，访问稳定 功能简单，更新频率低 运维成本有限 技术团队规模小 替代方案：\nPaaS平台（如Heroku、Vercel） 传统云服务（EC2、虚拟机） 托管式服务 3. 严格合规的行业 特殊要求：\n数据本地化存储 严格的网络隔离 传统的审批流程 复杂的合规要求 解决方案：\n私有云部署 混合云架构 等保合规云服务 实施时间表规划 第一阶段：准备期（3-6个月） 目标评估：\n技术选型和架构设计 团队技能培训 基础环境搭建 PoC项目验证 关键产出：\n技术架构文档 团队培训计划 基础设施方案 PoC验证报告 第二阶段：试点期（6-12个月） 试点项目：\n选择非核心业务试点 建立完整的CI/CD流程 实施监控告警体系 总结最佳实践 成功指标：\n部署频率提升50% 故障恢复时间缩短70% 资源利用率提升30% 团队满意度\u0026gt;80% 第三阶段：推广期（12-24个月） 规模化推广：\n核心业务逐步迁移 建立平台工程团队 完善治理和规范 建立供应商生态 组织变革：\n调整团队结构 建立DevOps文化 优化协作流程 建立考核机制 第四阶段：成熟期（24个月+） 持续优化：\n成本优化和效率提升 技术栈持续演进 创新技术引入 生态体系完善 成本收益分析 投入成本 人力成本：\n团队培训：50-100万/年 外部咨询：100-300万 人员招聘：薪资溢价20-40% 技术成本：\n云平台费用：初期增加20-50% 工具采购：50-200万 第三方服务：30-100万/年 组织成本：\n流程改造：难以量化但显著 文化变革：长期投入 风险承担：潜在的短期生产力下降 预期收益 量化收益：\n开发效率：提升30-50% 运维成本：降低20-40% 系统可用性：从99.9%提升到99.99% 产品上市时间：缩短50-70% 质化收益：\n团队技术能力提升 创新能力增强 客户满意度提高 市场竞争力增强 ROI计算示例 假设一个中等规模的互联网公司：\n投入：\n第一年：500万 第二年：300万 第三年：200万 总投入：1000万 收益：\n开发效率提升：年节省200万 运维成本降低：年节省100万 业务增长加速：年增收300万 年收益：600万 投资回报期： 1.7年 3年ROI： 80%\n决策框架 评估矩阵 云原生技术采用决策需要综合考虑技术成熟度和业务需求两个维度。对于技术成熟度高且业务需求强烈的场景应立即采用，技术成熟度高但业务需求较低的可逐步尝试，而技术成熟度低的则需要根据业务紧迫性决定是投资建设还是暂缓考虑。\n关键决策因素 必须考虑：\n业务匹配度：云原生是否能解决核心业务痛点 技术可行性：团队是否有能力实施和维护 成本效益：投入产出比是否合理 风险控制：是否有应对潜在风险的方案 加分因素：\n竞争压力：竞争对手是否已经采用 技术趋势：是否符合行业发展方向 人才储备：是否能吸引和留住优秀人才 创新能力：是否能支持业务创新 通过全面的评估和规划，组织可以在合适的时机引入云原生技术，最大化其价值并最小化风险。\nCNCF - 云原生计算基金会 组织简介 成立背景： CNCF（Cloud Native Computing Foundation）成立于2015年7月，由Google联合多家公司共同发起，致力于推动云原生技术的开源发展和标准化。\n使命愿景：\n使命：使云原生技术普及且可持续 愿景：构建开放、可扩展的云原生生态系统 价值观：开放、中立、社区驱动 组织架构： CNCF采用分层治理结构，包括技术监督委员会负责技术决策，最终用户委员会代表用户声音，营销委员会推广生态发展，公共健康委员会维护项目健康，以及各种专业工作组负责特定领域的治理工作。\n会员体系：\n白金会员：年费50万美元，拥有理事会席位 包括：Google、Microsoft、Oracle、IBM、Intel、Red Hat等 黄金会员：年费15万美元，参与技术决策 银牌会员：年费7.5万美元，基础参与权限 最终用户会员：免费，享受技术咨询和交流 成熟度模型 CNCF采用四级成熟度模型来评估项目：\n1. 初级项目（Sandbox）\n新加入的项目 处于早期发展阶段 需要社区验证和培育 2. 孵化项目（Incubating）\n通过初步验证 有明确的治理结构 社区活跃度较高 3. 毕业项目（Graduated）\n完全成熟的项目 广泛的行业采用 强大的社区支持 高质量和安全性 4. 归档项目（Archived）\n不再维护的项目 建议迁移到替代方案 核心项目生态 毕业项目（2024年） 1. Kubernetes（2018年毕业）\n定位：容器编排平台 GitHub Stars：10万+ 贡献者：4000+ 采用率：90%的容器化应用使用K8s 2. Prometheus（2018年毕业）\n定位：监控和告警系统 特点：时间序列数据库、Pull模型 生态：Grafana、AlertManager 3. Envoy（2019年毕业）\n定位：高性能代理 应用：服务网格数据平面 特性：动态配置、热重载 4. CoreDNS（2019年毕业）\n定位：DNS服务发现 特点：插件化架构、云原生友好 5. containerd（2019年毕业）\n定位：容器运行时 集成：Docker、Kubernetes cri-o 6. Fluentd（2019年毕业）\n定位：日志收集器 特点：统一日志层、插件丰富 7. Jaeger（2020年毕业）\n定位：分布式追踪系统 兼容：OpenTracing、OpenTelemetry 8. TiKV（2020年毕业）\n定位：分布式事务性键值数据库 特性：ACID事务、水平扩展 9. Vitess（2021年毕业）\n定位：数据库集群系统 兼容：MySQL协议 10. OPA（Open Policy Agent，2021年毕业）\n定位：策略引擎 应用：访问控制、合规检查 11. Helm（2022年毕业）\n定位：Kubernetes包管理器 生态：Chart仓库、模板管理 12. Argo（2022年毕业）\n定位：云原生工具链 组件：Argo CD、Argo Workflows、Argo Events 13. CNI（Container Networking Interface，2022年毕业）\n定位：容器网络接口标准 实现：Calico、Flannel、Weave 14. etcd（2023年毕业）\n定位：分布式键值存储 应用：Kubernetes元数据存储 15. Rook（2023年毕业）\n定位：云原生存储编排 支持：Ceph、EdgeFS等 重要孵化项目 Istio：服务网格控制平面 Linkerd：轻量级服务网格 Thanos：全局Prometheus视图 Cortex：多租户Prometheus KEDA：Kubernetes事件驱动自动伸缩 Crossplane：通用控制平面 Backstage：开发者平台 Dapr：分布式应用运行时 KubeEdge：边缘计算平台\nCNCF Landscape全景图 结构化分类 CNCF Landscape将云原生生态分为以下几个主要类别：\n1. 应用定义与开发（App Definition and Development） 应用定义与开发层涵盖数据库（关系型如TiDB、NoSQL如MongoDB、时序数据库如InfluxDB、缓存如Redis）、流处理与消息系统（Kafka、Pulsar、NATS等）、应用运行时框架（Serverless平台Knative、运行时环境、微服务框架Dapr等）以及配置管理工具（配置中心Consul、密钥管理Vault、服务发现CoreDNS）等关键技术组件。\n2. 编排与管理（Orchestration \u0026amp; Management） 编排与管理层包含编排调度工具（核心Kubernetes、多集群管理Karmada、工作流引擎Argo）、服务网格技术（Istio、Linkerd、Consul Connect）、安全合规方案（镜像扫描Trivy、运行时安全Falco、策略引擎OPA、密钥管理Vault）以及可观测性组件（监控Prometheus、日志Fluentd、追踪Jaeger、可视化Grafana）等。\n3. 运行时（Runtime） 运行时层提供容器运行时环境（核心containerd、安全增强gVisor、WebAssembly运行时WasmEdge）、云原生网络解决方案（CNI插件Calico、负载均衡器NGINX、服务代理Envoy）、存储系统（CSI驱动、分布式存储Ceph、对象存储MinIO）以及无服务器计算框架（FaaS平台OpenFaaS、事件驱动Knative、后端服务BaaS）。\n4. 平台（Platform） 平台层提供各类云服务平台，包括公有云容器服务（AWS EKS、Azure AKS、Google GKE、国内阿里云ACK）、私有云混合云解决方案（Red Hat OpenShift、Rancher、VMware Tanzu）以及PaaS开发平台（Heroku等开发平台、OutSystems等低代码平台、Backstage等内部开发者平台）。\n典型云原生架构组合 基于CNCF Landscape，一个典型的生产级云原生架构采用分层设计，从上到下包括应用层（微服务应用、Serverless函数、API网关）、服务治理层（Istio服务网格、配置管理、密钥管理）、数据层（关系型数据库、缓存系统、消息队列）、编排层（Kubernetes集群、Helm包管理、Argo CD GitOps）、可观测性层（Prometheus监控、Grafana可视化、Jaeger分布式追踪、Fluentd日志收集、AlertManager告警）以及基础设施层（Containerd容器运行时、Calico网络插件、Longhorn存储系统）。\n云原生能力评估框架 技术成熟度评估 1. 基础设施层（20%）\n容器化程度 自动化运维 资源编排 多云管理 2. 应用层（30%）\n微服务架构 服务治理 API管理 事件驱动 3. DevOps层（25%）\nCI/CD流水线 代码质量 测试自动化 安全扫描 4. 可观测性层（15%）\n监控覆盖度 日志管理 追踪能力 告警机制 5. 安全与治理（10%）\n身份认证 访问控制 合规检查 供应链安全 组织能力评估 1. 人员能力（30%）\n技术技能水平 学习能力 创新能力 团队协作 2. 流程成熟度（25%）\n开发流程 运维流程 安全流程 变更管理 3. 文化建设（25%）\nDevOps文化 实验精神 容错机制 知识分享 4. 商业价值（20%）\n业务敏捷性 成本效率 创新能力 客户满意度 云原生未来趋势 技术发展方向 1. 边缘计算与云原生融合\nKubeEdge、K3s等边缘计算技术 5G网络与云原生结合 IoT设备的云原生管理 2. WebAssembly（Wasm）崛起\nWasmEdge、Wasmtime等运行时 与容器技术互补共存 跨平台、高性能、安全隔离 3. 平台工程（Platform Engineering）\n内部开发者平台（IDP） 开发者体验（DX）优化 低代码/无代码平台 4. 绿色计算与可持续性\n资源利用率优化 碳足迹监控 节能调度算法 5. AI/ML与云原生结合\nKubeflow机器学习平台 MLOps最佳实践 智能运维（AIOps） 行业发展趋势 1. 普遍化采用\n从互联网行业向传统行业扩展 政府、金融、制造业逐步采用 中小企业普及化 2. 标准化推进\nOCI标准成熟 服务网格标准（SMI） 可观测性标准（OpenTelemetry） 3. 商业化模式\n托管服务（Managed Services） 企业级支持服务 咨询和培训市场 4. 生态系统完善\n更多开源项目涌现 供应商整合与收购 国际化与本地化并重 通过CNCF的组织推动和开源社区的共同努力，云原生技术正在成为现代应用开发的标准范式，为数字化转型提供强有力的技术支撑。\n参考资料 \u0026amp; 推荐阅读 核心技术书籍 云原生基础理论 《深入剖析Kubernetes》 - 张磊著，Kubernetes核心原理详解 《Cloud Native: Designing Containers-Based Systems》 - Boris Scholl等，2020年出版 《Designing Distributed Systems》 - Brendan Burns，容器化分布式系统设计模式 《云原生应用设计模式》 - InfoQ技术文章，详细介绍了云原生设计模式 DevOps实践 《凤凰项目：一个IT运维的传奇故事》 - Gene Kim等，DevOps文化启蒙之作 《DevOps实践指南》 - Gene Kim等，DevOps实施方法论 《持续交付》 - Jez Humble等，CI/CD最佳实践 微服务架构 《微服务架构设计模式》 - Chris Richardson，微服务设计权威指南 《Building Microservices》 - Sam Newman，微服务架构实践 《微服务设计》 - 理查德森，微服务架构理论与实践 企业级实践 《企业IT架构转型之道：阿里巴巴中台战略思想与架构实战》 - 阿里巴巴技术团队 《大型网站技术架构：核心原理与案例分析》 - 李智慧 在线资源 官方文档 Kubernetes官方文档：https://kubernetes.io/docs/ CNCF官方文档：https://cncf.io/ Docker官方文档：https://docs.docker.com/ 技术社区 InfoQ云原生专栏：https://www.infoq.cn/topic/cloud-native CNCF Landscape：https://landscape.cncf.io/ Cloud Native Computing Foundation Blog：https://www.cncf.io/blog/ 开源项目 Kubernetes GitHub：https://github.com/kubernetes/kubernetes Prometheus GitHub：https://github.com/prometheus/prometheus Istio GitHub：https://github.com/istio/istio 技术博客 Google Cloud Blog：https://cloud.google.com/blog/topics/containers AWS Blog - Containers：https://aws.amazon.com/blogs/containers/ Microsoft Azure Blog：https://azure.microsoft.com/en-us/blog/topics/containers/ 认证与培训 官方认证 CKA (Certified Kubernetes Administrator)：Kubernetes管理员认证 CKAD (Certified Kubernetes Application Developer)：Kubernetes应用开发者认证 CKS (Certified Kubernetes Security Specialist)：Kubernetes安全专家认证 在线课程 Coursera - Cloud Computing by University of Illinois edX - Introduction to Kubernetes by The Linux Foundation A Cloud Guru - Kubernetes Deep Dive KubeAcademy：免费的Kubernetes学习平台 行业报告与研究 市场分析 Puppet State of DevOps Report：年度DevOps发展报告 CNCF Survey：云原生技术采用率调查 Gartner Magic Quadrant for Container Management：容器管理平台评估 技术趋势 ThoughtWorks Technology Radar：技术趋势雷达图 Red Hat State of Enterprise Open Source：企业开源现状报告 实践案例 互联网公司 Netflix云原生实践：微服务架构、混沌工程 Google Borg to Kubernetes演进：大规模容器编排实践 阿里巴巴中台架构：大型电商平台的云原生转型 传统企业 ING银行数字化转型：金融行业云原生应用 ** Walmart电商升级**：零售企业技术现代化 工具与平台 开发工具 Visual Studio Code：轻量级IDE，支持云原生开发 IntelliJ IDEA：Java开发，支持Kubernetes插件 Lens：Kubernetes可视化管理工具 监控与调试 Grafana：可视化监控面板 Jaeger UI：分布式追踪界面 K9s：Kubernetes命令行管理工具 CI/CD平台 Jenkins：开源CI/CD工具 GitLab CI/CD：集成的DevOps平台 GitHub Actions：基于GitHub的自动化工作流 标准与规范 技术标准 OCI (Open Container Initiative)：容器镜像和运行时标准 CNI (Container Networking Interface)：容器网络接口标准 CSI (Container Storage Interface)：容器存储接口标准 安全标准 NIST Cybersecurity Framework：网络安全框架 CIS Benchmarks：安全配置基线 通过系统学习这些资源，可以深入理解云原生的理论、实践和发展趋势，为实际工作提供指导。\n","date":"2022-09-20T00:00:00Z","permalink":"https://morsuning.github.io/p/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%9A%845w1h/","title":"云原生的5W1H"},{"content":"1 CMMI概述 80年代早期，在SEI的资助下美国空军成立了一项研究来分析为什么许多软件合同都会超出工期和预算。由此得出的结论是：糟糕的过程。CMM\u0026amp;CMMI也因此产生。CMMI的中文名称是能力成熟度模型，是一个过程改进方法和模型，它为组织提供了实现高效的软件交付过程所必需的基本元素，关注通过切实改进过程域的成熟度，实现过程改进的目标。它可以用来指导一个项目、一个部门甚至整个组织的过程改进。CMMI能帮助我们整合以往各自为政的组织功能，建立过程改进的目标与优先级，指导我们进行质量改进，还提供了评价现有过程的参照点，最关键的一点是，它提供了过程改进的线路图，目前最主要的用途是评价一个组织的组织级能力。\n2 敏捷方法概述 敏捷是用来指导解决快速高质量交付高价值产品的思想与框架，是一种允许快速业务变更的开发实践。敏捷的核心是敏捷的4个核心价值观和12条原则，外围则是满足不同团队需求的各种敏捷实践，敏捷的不同之处在于其更关注团队协作、关注质量、关注可工作的软件。敏捷来源于实践而不是理论。在追求卓越的过程中，组织会尝试多种途经，采用不同的原则、方法及技术。一个对敏捷实践感兴趣的组织可能也会对PMI的OPM3、ISO或能力成熟度模型集成（CMMI）感兴趣，反之亦然，因为这些都是通向卓越的手段。敏捷代表着一种极简的实用主义。\n敏捷的本质是，项目组全体人员以及所有员工和公司，同处于一个利益集体。表现出来的特征是所有人对项目的成功负责、需求驱动地工作、跨领域合作、持续交付，迭代开发，小步前进，持续改进。\n敏捷过程的特点则是：项目目标明确的过程，只做对项目进展有帮助的事，不进行额外的工作，有效和高效是项目管理原则、强调让人工作愉快，充满热情。\n3 CMMI 和敏捷 经常有一种说法是 CMMI 和敏捷是对立的，这是一种错误的理解，最根本的原因是 CMMI 不是开发过程，而大部分敏捷则是具体的开发过程，这两种之间并无冲突的基础，在 CMMI 的一些过程域中，可以使用敏捷方法进行实践，也可以不使用[3]，有些时候，敏捷方法是达成某个 CMMI 过程域目标的最佳选择。其次，CMMI 存在所谓的标准化，不管是评估方法还是实施办法都有标准化的趋势。而敏捷往往拒绝标准(追求灵活)。再次，作用，即让不熟悉的第三方认可上有差异。尽管 CMMI 目前的现状不乐观，但是，毕竟这种方式提供了一些有价值的线索来了解某个软件组织的能力和成熟度的可能。而这一点敏捷过程还无法提供。有一种说法，CMMI 是主要是组织级过程，而敏捷是项目小组的过程。应该说这种说法有一定的问题，敏捷也可以是组织过程， CMMI 也可以只是关注在小组级别（2 级）。\n说完本质，具体地，可以从目标，过程，关注点，适用范围，核心理念等方面来分析和对比 CMMI。\n从目标上说，CMMI和敏捷都是人们为了解决在软件生产过程中出现的质量低下、进度延迟、预算超支等问题，而产生的标准或过程改进的模型或方法实践。在这一点上是一致的，这也是为什么人们认为这两种方法是完成同一件事的不同方法因此会产生冲突的原因。但是，接下来，如果从其他角度看，这两种方法思考的角度，范围完全并不一致。\n比如，从过程来看，过程的四要素分别是人、方法、技术和工具，在 CMMI 中，对于人的要求涉及GP2.3提供资源、GP2.4分配职责、GP2.5培训、OT组织培训，而敏捷中对人部分的关注在于如何提高人的工作积极性和效率，这在 CMMI 中也有体现，但 CMMI 还关注人的技能，技能培养和团队资源等，明显范围更大，考虑更深。对于方法，涉及所有PA 的SP，而敏捷则强调一组价值观。对于技术和工具，CMMI在GP2.3 提供资源，工程类PA ，OT 组织培训，OPD 组织过程定义，OPM 组织性能管理中谈及了技术在GP 2.3 提供资源谈及了工具，而敏捷对于技术和工具的选择仍基于其价值观，CMMI 则是通过各种目标综合考虑，这里又是CMMI 考虑的更为全面。\n从它们的关注点看，敏捷是达成商业目标的极简方法，CMMI 是达成商业目标的方法体系，也是为商业目标服务，不能为商业目标服务也就会违背 CMMI本意，可以依据需求选择执行的部分，比如一个项目是质量优先还是工期优先，该过程和执行和过程还有执行的结果和效果可以被 CMMI 评估和追踪。CMMI和ISO关注为了实现组织软件生产目标，我们应该做什么？但却不关注如何做。而敏捷开发作为一个实践性方法，更关注怎么做。因此，在具体操作过程中，可以通过有效结合，能够使组织更快、更好地实现过程改进目标。为了能够有效结合各种CMMI和敏捷开发，组织必须明确它们的区别和联系，以及每种方法的主要关注点。CMMI和敏捷开发的主要冲突来自于双方产生的环境、目标客户和团队文化要素，例如CMMI早期客户,主要关注大型项目、复杂系统、使命关键(Mission Critical)系统，而敏捷开发主要关注小项目、简单应用和灵活多变的系统；CMMI的假想市场和用户主要面向成熟市场，面向那些关注流程创新的企业，而敏捷开发主要关注在新兴市场和多变的市场环境；文化方面，CMMI强调流程和管理，而敏捷更强调高度信任的氛围中，被激励起来的个人之间的协作创新。\n从最一般的适用范围来说，CMMI最初是美国国防部为评价一个组织的开发能力而定义的模型，它是站在组织级的角度看待过程能力。它定义了高层管理者的治理职责，要求组织级要定义管理的方针、流程、裁剪指南、模版等，组织级要进行流程执行情况的检查，要给团队提供资源、工具、培训等支持，组织级要采集经验教训、典型案例、改进建议、度量数据等进行持续改进，要将组织的规范固化为大家的工作习惯。SCRUM，XP等敏捷方法大都是侧重于构建团队级的能力，给出了一个小团队的角色划分、管理实践与技术实践，如果需要进行大产品的开发，可以采用规模化敏捷的方法，如LeSS， SAFe等。当团队规模越大时，需要的管理活动就越多，SAFe之类的大规模敏捷框架受到的质疑就比较多。组织级敏捷文化的形成需要借助变革管理的理论、方法来辅助Scrum, XP, LeSS, SAFe等敏捷方法构建组织级的能力，在组织内如果不能形成敏捷文化，敏捷不能持久。\n从核心理念来说，敏捷宣言，敏捷的12个原则以及各种敏捷方法自己的原则，构成了敏捷的价值观，这些是敏捷的思想理念，是敏捷的根本。CMMI推崇的价值观，理想以及自己的原则并没有明确的官方描述，CMMI的共性实践可以认为代表了它的一些核心理念，不是全部，它是通过实践来描述的，没有提炼、抽象出来。可以做如下概括：商业目标驱动改进，转型过程实现目标，定量数据量化性能，固化习惯成为文化，高层支持全员参与，循序渐进持续优化。\n总结一下，CMMI 和敏捷要达成的目标其实是一致的，在适用范围上，它们皆可大可小适用于组织和团队，但是由于基本价值观的不同，思考问题的角度和方式也不同，CMMI 更像是一种管理方法，而敏捷更像是一种实践的指导思想。从实际使用的角度来说，目前敏捷方法在开发软件项目的时候使用的跟多，而 CMMI 则主要用来了解一个组织的能力和成熟度，不过并非是必要条件。在一些情形下也比敏捷方法更加适用。\n4 CMMI 引入敏捷的得与失 从整体上说，CMMI和敏捷开发能够很好地相互补充、相互支持。首先在关注点上CMMI关注组织级或企业级改进，关注回答项目应该做什么，而不是具体怎么做的方法，而敏捷开发则更关注项目级改进，关注项目具体怎么做的方法和最佳实践，这使双方在定位方面形成很好的相互补充的态势，一方面CMMI为敏捷提供组织级扩展的能力和必须的组织治理框架，便于组织级对敏捷最佳实践的推广和重用；另一方面，敏捷为CMMI提供了项目级的具体实践方法，确保团队在CMMI框架下能够快速响应，不断创新，持续交付价值。两者的有效结合，能够有效实现个人绩效向团队绩效、向组织绩效的转变过程。同时，也可以通过敏捷实践，规避CMMI实施过程中重文档、重流程的不良倾向，使CMMI实施时更加关注组织的实际价值、关注客户、关注创新。\n需求明确，技术明确的简单项目，用传统模式管理，套用CMMI模型，成熟、没大毛病，而且效率还会更高一些。部分复杂和复杂的可以使用敏捷，拥抱变更，需求边做边涌现，于是不断进行改进，会比使用传统项目管理更灵活一些，变更成本和风险都会降低。\n谴责CMMI模型不好或者谴责敏捷方法不好，都是片面的，更大程度上是落地方法有问题，是去落地的人的问题。在一个组织内，谁最先发起要导入CMMI与敏捷的呼吁呢？如果是市场的呼吁，那可能侧重的是证书，是投标的需要。如果是开发的呼吁，那可能侧重的是减负，是提高效率的需求。如果是老板的呼吁，那可能侧重的是交付高质量的产品，快速响应市场的需求。对企业而言，对老板而言，要平衡短期利益与长期利益，活下去，活得好，活得久，需要平衡。CMMI与敏捷都不是万能的，都有其适用场景，不能盲目迷信，盲目崇拜，要秉持开放的心态，持续发展的心态，兼收并蓄，取长补短。总之，这两者的目标是一致的，因此要根据实际情况，选择更加适合的方法来达成这个目标，而不是为了方法本身纠结。\nCMMI 中提供了一些良好的实践，这些实践中CMMI 过程域和敏捷方法相互帮助，共同实现了对方的目标/理念，这一过程中不但具有 CMMI 的优点也兼具了敏捷方法的优点，比如说：想达到 CMMI 2（已管理级）的 SCRUM（一种迭代式增量软件开发过程）团队在日常工作中需要实施下列过程域：“需求管理”（REQM）、“项目计划”（PP）、“项目监控”（PMC）、“过程和产品质量保证”（PPQA）、“配置管理”（CM）和“度量与分析”。SCRUM 团队在 SCRUM 规划会议期间执行项目计划，在每天的 SCRUM 中执行项目监控，但他们处理积压的订单时需要执行需求管理。很多时候，他们持续交付环境需要一个好的配置管理。此外，他们还需要实施一些 CMMI 3 的过程域，为他们进行审查性会议，使用类似 TFS 和 CollabNat 平台支持他们日常活动，以提供分析标准。然而，CMMI 3 的一个集成项目管理（IPM）却要求 SCRUM 团队改变管道生产方式，放弃纯 SCRUM，这是很难实现的。集成项目管理提供了强大的良好实践过程以帮助团队满足特定项目的几乎所有需求。想象一下，一个利益相关者谁还需要一系列基于模板而编写的特定文档。这类事情本应该由产品所有者来解决，现在 CMMI 却优雅地做到了这一点。\n最后再总结一下，CMMI引入敏捷方法，二者共同以最高效和完美的方式达成了本来的共同目标，即解决在软件生产过程中出现的质量低下、进度延迟、预算超支等问题。同时，由于敏捷方法为 CMMI 某个过程域的最佳实践，使得这一过程兼具了 CMMI 可监控度量追踪等优点和敏捷方法成本最小化的同时质量最优化的优点。存在的问题就是，还是存在使用敏捷方法需要让 CMMI 进行妥协的情况。但是，鉴于二者都是为同样的商业目标服务的，这样的妥协显然是十分值得的。\n5 Reference [1] Hillel Glazer, Jeff Dalton, etc. CMMI or Agile: Why Not Embrace Both!. SEI. 2008\n[2] CMMI Institute. A Guide to Scrum and CMMI: Improving Agile Performance with CMMI. 2016\n[3] CMMI 产品团队, CMMI开发模型，版本 1.3, 2010\n","date":"2021-04-12T00:00:00Z","permalink":"https://morsuning.github.io/p/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E6%94%B9%E8%BF%9B%E7%AE%80%E8%BF%B0%E5%9C%A8cmmi%E4%B8%AD%E5%BC%95%E5%85%A5%E6%95%8F%E6%8D%B7/","title":"软件过程改进简述——在CMMI中引入敏捷"},{"content":"《软件管理沉思录》是一本介绍SEI项目管理、人际沟通和团队协作的要诀。不论读者是软件开发者抑或是管理者，都能够从这本书中挖掘到价值。\n本书分为四个部分，分别介绍了项目管理，团队管理，与上级沟通和自我管理。\n在关于项目管理的部分中，作者强调了软件质量的重要性。作者指出一条被广为认同的公理：一个软件系统是不可能没有缺陷的。一个小型的软件系统尚可能存在着不易察觉的缺陷，一个涉及到用户或者极为复杂的软件系统更是难以根除缺陷。所以提高软件质量，减少软件的不稳定性对于软件的开发维护人员是一个巨大的挑战。\n针对这一问题，我们可以使用8个步骤规则，来控制软件质量：确立质量控制的策略、目标和计划；正确训练、指导和支持开发人员及其团队；确立和维护软件工程过程的统计控制；审查、检查并评估所有的产品制品；评估所有缺陷，加以更正并用以识别、纠正和预防其他类似问题；确立和维护配置管理和变更控制系统；持续改进开发过程。这八步措施被越来越多的证据证明是有效的，且能帮助节约时间和金钱。软件质量的控制从分析需求开始，只有得到了清晰的需求，才可能开发出高质量的程序。开发中的软件缺陷是影响软件质量的一个重要因素，它指的是程序中的错误，简单的错误可能导致毁灭性的缺陷。缺陷往往是潜藏在系统中的，当缺陷暴露出来，引发了问题，产生了影响就成了漏洞。\n接下来讨论了高质量项目至关重要的一点——计划，其实制定合理有效的计划这一观念贯穿了本书始终，不论是开发人员个人在进行软件开发之前需要做详细的计划安排，团队合作之前也需要制定成员们都认可的计划，这是形成高效团队的条件之一。一份合格的产品计划应当包括三项内容：将要生产的产品规格和重要的性能指标；估算工作所需的时间；进度预测。对于重要的项目，管理者要做的第一件事就是组织一个计划和提案小组，并且制订出一个总体计划，计划的五条基本要求是：易于理解、清晰明白、详细具体、精确缜密、准确无误，如果你不能使计划准确无误，那就常做计划。\n第二部分主要讲团队，团队是指有着共同不表的一群人。本书作者修改了戴尔的定义来描述TSP团队：一支团队至少要有两名成员；所有成员都是为了同一目标而工作；每位成员至少扮演一个特定的角色；完成任务要求团队成员之间相互依赖。在一支高效的团队中，团队成员联合后的集体才智使得团队获得更全面的知识。本书中列出了团队遇到的七个常见问题：无效的领导、缺乏妥协或合作、缺少参与、拖延和缺乏信心、低劣的质量、功能蔓延、无效的对等评估。因此最常见的导致项目团队合作失败的原因有：资源不足、领导问题、不可能的目标、士气问题。任何一个都会导致一支团队失效甚至失败，并且这些问题通常一起发生。一支高效的项目团队被称为凝胶型团队，当团队成员集中在一个清晰的目标上时，就会发现有中神奇的力量，每个成员的表现都似乎能超越自身的能力。这样的团队能为成员带来工作中的快乐，所有成员能对团队全身心投入。一个高效团队常常有四个条件：凝聚力、有挑战性的目标、目标追踪和反馈、共同的工作架构。一个团队是随着时间成长的，在团队形成凝聚力的过程中，各成员会逐渐接受一系列共同的团队目标并投入巨大的实现热情。在创建凝胶型团队的过程中，交流至关重要。对于团队来说，交流最重要的三要素是：透明、倾听和协商。随着团队成立，它就进入了一个自然的生命周期，逐步经历组建、动荡和规范等阶段。在这个过程中努力变成一支高效的团队。伯恩把群体分为三种类型：工作型群体专心于工作，过程型群体专注于内部的动力学，对抗型群体则与外部威胁作斗争。不同的团队可以采用不同的工作风格。康斯坦丁把团队行为界定了四种类型：开放型群体、随意型群体、封闭型群体和同步型群体。但是现实的团队风格往往是表现为混合的形式。自主指导型团队对于任何类型的工作都是有效的，但这种团队对于完成复杂、创新性的工作尤其重要。本书提出了5条自主指导型团队的典型特征：具有团队感和归属感；共同对团队目标做出承诺；对过程和计划的主人翁以适；具有制订计划的技巧和执行计划的纪律；追求卓越。\n对于团队成员来说，一个优秀的成员应当会做任何需要做的事，并且应当作出负责人的承诺并努力实现。目标对于个人十分有用，它明确地提供了努力的目的，暗示了当前在过程中所处的位置。对于团队来说，需要一个所有成员都认可的共同目标，才能提高团队的凝聚力。项目团队提供的不仅仅是组织架构，还提供了一系列技巧和视角。团队只有恰当利用各个成员的知识和经验才能使每个成员都变成有力的资源。在团队交流中，不同的成员有不同的表现，组织者应当维持讨论的秩序和理性。要想让团队运行顺畅，每一位成员都应当奉献出他所知道的一切。在遇到麻烦的时候，团队的成员应当请求并接受帮助。本书中列举了团队创建的义务：接受并扮演一个团队中的角色、确定并努力实现团队目标、建立和维护团队。团队的创建和团队合作一样需要所有成员的主动参与。优秀的谈判者往往采用原则式谈判，可以避免立场的两极分化。本文在之前提到团队一定要做到共鸣型或主动型倾听。在原则式谈判中，基础是认识到立场只是满足利益的一种方式，应当将注意力集中在利益而不是立场上。经验表明，团队中如果有一个人不务正业的话，就会影响到其他所有人的表现，可以剔除不履行职责的团队成员来提升团队的整体表现。团队成员的一项重要责任是寻求帮助，很多软件工程师习惯各自解决难题，但其实及时寻求帮助能够很大程度上缩短解决问题需要的时间。同样团队成员除了自己的正式角色，还应当承担起团队公民的责任，帮助其他的团队成员解决问题。提供有效支持的关键是帮助团队伙伴相信他们自己的能力。\n然后是关于领导力，领导力事关成败，团队的做事方式很大程度上取决于他们与领导者进行协调的方式。三条最重要的激励因素是恐惧、贪婪和承诺，对于开发人员等从事创造性工作的人而言，激励因素还涉及技术挑战。领导者可以利用这三个因素推动团队的工作，但是也应当适度，确保可以引发需要的反应。激励的程度取决于做出承诺的方式，承诺的三个要素是协商、约定和执行。可信的团队承诺有四条要求：自愿、可见、可信、得到承诺，这四个要求构成了作出承诺的基础。为了在长期富有挑战性的项目中信守承诺，需要在任务过程中以某种方式定期强化承诺。为了及时提供反馈，可以把总体承诺划分为若干标识进展的里程碑。领导力的挑战之一是帮助团队成员设置中间目标，短期的目标可以制造紧迫感。团队中往往会有不是非常积极参与的成员，为了让他们参与进来，可以采取的技巧有：提问、装聋作哑、频繁地检查约定、感受没有说出的疑虑或不同意见、不要让某个人完全控制讨论、管理专家、指导团队领导者、关注事实和数据、不允许有旁观者。当团队处于动荡阶段，辅导的关键是让团队成员发泄他们的怒气和愤懑，然后着手解决他们的焦虑。管理团队时个部门的管理者应当从一开始就参与其中，充分考虑他们的观点。另外，这样还可以使管理者从已提出的问题中发现一些重要的新议题。构建管理团队的最后一步使鼓励管理团队成员共同工作。当管理团队以一种公开、坦诚的方式在一起工作时，其结果一定时最佳的。理性管理的四个要素：确定目标、计划和审查、评估和追踪、预测和纠正。他们彼此相关，都是高效管理风格所必需的。\n对于工程师如何与管理者相处，作者提到如果项目从一开始就遇到麻烦，工程师必须站稳立场，让管理者相信你知道项目会花费多长时间。当制定一份计划确定日期之后，就可以告诉管理者真正的交付期限，据理力争。我们的工作任务应当是让团队聚焦于优先级最高的事情。在面对管理者的压力时，我们应当制定一个可以让管理者相信整个团队正在努力实现的富有挑战性的计划。不过，制定一个合理详细的计划是掌控项目的第一步，接下来必须保持计划的更新。同时我们需要按照计划执行，让管理者了解情况。自主指导型团队面对管理层的控制时，应当制定详细的计划并与管理者商谈日程进度，而不仅仅是做那些要求做的事。默默为每一项变更制定调整计划可以有效应对管理者的控制。当一个项目注定失败时，如果不想放弃，我们应当试图解决问题。由于必须与管理者打交道，我们应当从他们的角度想想我们能做什么。在推行改进时我们需要管理者的支持才能让整个组织结构的人们改变工作方式。这时我们应当考虑三个问题：为什么想要改变、需要从哪些管理者那里取得支持、管理者为什么要支持？如果引起了高层管理者的关注，我们就需要给出战略性理由。这时我们要准备：阐明提议、理解当前的业务环境、找出关键点、作一次改进合理性检查、引入原型、前期引入成本、后期维护成本、过程改进的收益、有关收益的事实、计算节约的数额、衡量收益其他收益。突破管理者抵制的方式是证明当前面临的问题无法通过短期的权宜之计来解决，必须具备战略目光，可以采取的基本措施：让战略性改进活动具备战术吸引力，从小的、战术性努力开始，逐渐扩展成战略性改进方案。\n在注意“管理”你的领导的同时，我们也需要学会管理自己，把握主动，这时需要分成两步：1. 真正掌控自己的工作；2. 说服管理者同意由你管理自己。本书中列举了改进工作的步骤：确定质量目标、衡量产品质量、理解过程、调整过程、应用调整后的结果、衡量结果、把结果与目标进行比较、循环并不断改进。我们也要学会利用支持人员，学会计划工作，并促使你的团队伙伴和项目负责人也开始作计划。按计划完成工作的一个隐含好处是执行计划事实上会改变你的行为。我们需要学会负责任、信守承诺、执着追求卓越。\n最后，关于领导，作者讨论了作为领导，我们的行为方式会影响整个团队，因此我们需要为团队树立榜样。领导力低下的症状有：高层管理者在思考问题时以自我为中心，眼界短视狭隘；官僚惰性；管理者没有能力及时做出有效的决策；过犹不及。管理是利用资源达到某种结果，而领导则是激励人们实现某个目标。管理者和领导者之间最主要的区别是管理者命令员工服从指令，领导者则是带领他们完成任务。领导力是高度个人化的，它需要通过个人魅力来赢得。让员工对目标产生热情，并说服他们追随你一同取实现是一种内在激励或变革型领导。\n","date":"2020-12-22T00:00:00Z","permalink":"https://morsuning.github.io/p/%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86%E6%B2%89%E6%80%9D%E5%BD%95-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《软件管理沉思录》 - 读书笔记"},{"content":"在对失败的软件开发项目的分析中，人们倾向于将与人相关的失败因素归结于政治而不深入研究，这是一种误区，而本书中Tom DeMarco和Timothy Lister两位大师用严谨的科学实验和辛辣尖锐的解剖一步步为我们揭开知识经济下管理中的这种误区，与《人月神话》中给出一些成功的实践和准确的论断不同，《人件》更想给读者以警醒，激发对人的因素的思考。\n《人件》此书的核心观点是软件系统的主要问题不在于技术，而在于社会性因素。那么，究竟是哪些社会性因素呢？作者围绕如下几个问题，提出了需要注意的地方。\n管理人力资源； 改善办公环境； 招聘留用人才； 提高团队效率； 塑造企业文化； 营造快乐氛围； 通过对以上问题的探讨，本书会让管理者形成一种心态，这种心态会帮助他更好地激发员工的工作效率而不是进行不必要的压榨。在这些问题中，我选择几个关键因素进行探讨。\n单纯的技术问题绝不是导致项目失败的关键 “政治”是被访问者最常提及的失败原因，对于技术人员倘若面对政治范畴的问题，我们通常会逆来顺受，当与政治无关时，我们往往更加游刃有余。因此《人件》中认为的工作问题更多的属于社会学范畴，而非技术范畴。但是实际情况是，大多数管理者虽然承认他们对人的担心甚于对技术的担心，但是他们还是总以技术为主要的关注点，越俎代庖地去解决复杂而又有趣地难题上，却将最重要地与人相关地要素放到最低优先级。《人件》对此现象的解释就是该问题造成的原因就是管理者的提拔机制。 《人件》提出的几条管理脑力劳动者的建议或者警告： 错误在所难免 避免向工作者施压，反而采用一些手段让大家少工作一会儿，让大家做更有意义的事情 尊重每一位员工，“没有人是不可替换的”思想是不可靠的 稳定的生产思维对项目工作尤为有害，项目总是处于不断变化的状态，一个能让项目更加稳定的人抵得上两个做事的人 我们花时间去做事，但却从来不去考虑工作本身的问题 榨干员工的时间和精力是危险的 《人件》中提到的一个案例就是管理人员压榨员工，直接导致团队内两名成员离婚，一名成员的儿子染上毒瘾。管理者以牺牲员工的生活为代价来承担更大的工作强度和更长的工作时间，管理者鼓吹他们的员工加了多少班，并谋算着如何让大家加班更多的手段。这是完全不对，应该是引导员工意识到人生苦短，生活中还有很多事情比工作更重要。需要记得是：压力不会让工作得更好——只是工作得更快。 产品质量的影响因素——自信 新手管理者或许觉得工作可以不参杂个人情绪的，但是实际情况下，我们的工作给了我们表达情绪的很多机会。当我们面临一个背景毫无所知的项目，我们肯定十分胆怯，威胁到自信，并且我们倾向于将我们的自信与生产出的产品质量紧密相连。 再谈帕金森定律 当我们热爱我们的工作，我们绝不会让一项工作变得遥遥无期，因为这回推迟我们获得满足感的时间，在不需要降低标准、牺牲质量的时候，我们期望工作能快点完成。但是需要明确的是：帕金森定律是不能在工作中得到运用的。把团队中的成员当成帕金森性的员工是不可能奏效的，这只能消磨他们的意志，让他们失去前进的动力。《人件》中提出了帕金森定律的变异版本：一个组织的工作如果都忙忙碌碌，就会膨胀以至于占满整个工作日。 不要相信“苦杏素” 不少管理人员在“足够绝望”时会忽略对证据的审视，买到的技术缺乏任何客观证据的支撑。在实际项目中会存在这样类似的七宗罪： 有一个你不知道的新窍门可以让产能飙升 其他的管理者正在收获100%、200%乃至更多的增长！ 技术日新月异，你已经过时了！ 改变程序语言会给你带来巨大的提升 因为库存的缘故，你需要马上让产能翻倍 你自动化了其他所有东西；难道不是要你自动化掉你的软件开发人员吗？ 你的员工在巨大的压力下工作得更好 忘记掉这些准则，你和你的员工会工作得更好 似乎在朝九晚五得环境里啥都完成不了 软件行业里似乎形成一种风俗：加班就是命中注定。归根到底其实就是环境因素影响很 大。在《人件》中以下因素跟产出效率基本或根本没有关系：语言、经验年限、缺陷个数、薪酬。此外，从《人件》提供得数据来看，对工作环境设计上采用弃权政策是一个错误。那些安静、宽敞和注重隐私得环境不但能使你的团队更高效地完成工作，还能帮助你吸引和挽留住人才。 构建社区 成功构建社区的组织更能留在人。当员工有足够的社区意识时，他们就不想离开了。此时你对人力资本的投资由此也得到了回报，进而也愿意投资更多，再进而你的员工也会表现得更好，更喜欢呆在你的公司，这将会是一个增强得良性循环。 快乐地工作 作为一名管理者，你需要保证自己手下的人从工作中得到快乐。所谓的工作，就是要使员工的效率最大化，而这已经足以剥夺他们的快乐了。 纵观整本书，Tom DeMarco和Timothy Lister两位大师探索了技术项目中的人文问题，讨论了管理者在领导力上的病理征状，提出一些关于管理新旧成员水火不容的混合团队的建议方法。由于我的阅历尚浅，对有些章节读后并没有太多的感悟，有些章节有幡然醒悟的感觉，这类书还是需要在日后反复阅读。\n此外，通过阅读《人月神话》和《人件》这两本书，我们大概能总结出软件工程管理的核心目标是：成本和工作量的估算、计划和进度跟踪调整，风险分析与控制等，在此基础上，我们要最大化地激发人的力量，即让人尽可能大地提高工作效率，尽可能多地保持良好的关系，尽可能地减少工作时间等。\n","date":"2020-11-20T00:00:00Z","permalink":"https://morsuning.github.io/p/%E4%BA%BA%E4%BB%B6-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《人件》 - 读书笔记"},{"content":" 内容已过时，《黑客与画家》的核心应该是计算机、程序员与创业\n一直以来，对“黑客”这个词总是充满了神秘的想象，本科阶段学习了《信息安全》这门课以后，对“黑客”的工作自以为算是有了一些初步的认识，怀着这样的心情，阅读了《黑客与画家》这本书，本以为会了解到更多的我所以为的“黑客”的工作，却没想到，这本书带给我的不仅仅是对已深深印在脑海中的概念的推倒重建，更多的是引发我对很多以前从没想过的问题的全新思考，这些思考带给我不一样的新的视角去看待其他事情，我想这就是阅读的意义所在吧。\n首先，这本书绝不是你看到书名所能想象的那样，如果你对这块领域不那么熟悉的话。黑客，画家，看似两个毫无关联的职业，怎么能放在一起呢？然而，这正是该书的作者，他是黑客，也是画家，他是程序员，更是一名艺术家。书中，作者结合他的经历探讨了很多不同的问题，例如：怎样打破常规？怎样创业才会成功？如果你的想法是社会不能容忍的，该怎么办？为什么互联网软件是微软诞生后最大的机会？如何创造财富？怎样做出优秀的东西？一百年后，人类怎样编程？等等。总之，作者想要传达的是新的思想，来帮助读者理解我们所处的这个计算机时代，他的这些阐述，也的确带给我很多的启发。\n初读本书，我就在脑海里对“黑客”这个概念作了重新定义，不像大多数人所认为的那样，“黑客”是利用自己的技术入侵他人计算机并带来一些危害的人，在计算机世界里，黑客指的是专家级的程序员，根据理查德。斯托尔曼的说法，黑客行为具备三个特点：好玩、高智商、探索精神。真正的黑客致力于改变世界，让世界运转得更好，而不是犯罪或危害他人。\n基于这样的理解，作者在书的第一章讨论了这样一个问题：为什么书呆子不受欢迎？这里的书呆子，恰恰很可能就是一名未来的黑客，因为作者发现，“书呆子”与“高智商”有强烈的正相关关系，他们不会将注意力放在诸如穿衣打扮、开晚会上面，他们的脑子里想着别的事情，例如读书或观察世界上，他们从小就在琢磨如何变得更聪明，并打心底里追求这个，至于受不受欢迎，已经不在他们的考虑范围之内了，所以，在学校里书呆子也许会被大家歧视或欺负，但是离开学校以后，真实的世界却能友好的地对待他们，因为真实世界的庞大规模使得你做的每件事都能产生真正意义上的效果，发现正确的答案就开始变得重要了，而这恰恰是书呆子的优势所在。\n黑客与画家的共同之处在于他们都是创作者，与作曲家、建筑师、作家一样，他们都在试图创作出优秀的作品，从另一个角度来说，他们都能称作为艺术家，创作过程中，他们可能会发现一些新技术，但本质上，他们并不是在做研究。黑客与画家有很多共同之处，其中我认为最重要的一点就是：你不能指望一开始就有完美的设计规格，要编写一个程序，你把问题想清楚的时间点，应该是在编写代码的同时，而不是之前。因为这终究是一项实践性的工作，需要不断的练习和探索，甚至很多的失败，才能找到一个相对正确的答案，而这个答案在不久的将来很有可能要再次修改甚至推倒。很多同学说自己编程能力不强，排除不感兴趣和懒惰的情况，总有人认为自己要把某门语言掌握到滚瓜烂熟才开始写代码，这是最错误的行为，你应该从尝试去解决一个小问题开始，在实际操作的过程中，不断补充新的知识，产生新的想法，就像书中说的，“编程语言是用来帮助思考程序的，而不是用来表达你已经想好的程序”。\n程序员就像是手工艺人，他们创造人们需要的东西，也即财富，想要创造财富，就要做出优秀的软件，而实现最好的方法就是创业。作者结合自己创办viaweb的经历，探讨了一些创业的必备要素。其中最关键的就是：你必须了解用户的需求。就像桌面软件时代的过去，大多数的用户并不需要成为系统管理员，很多时候他们所需要的设备就只要有屏幕、浏览器、无线网卡就够了，互联网软件的诞生正好满足了这些需求，它们更加方便、易操作甚至更强大，同时数据会更安全，更重要的是，通过研究用户的行为，能及时的优化软件并马上得到反馈，带来更好用户体验的同时也带来了更多的用户数量，而这恰是决定一款软件成功与否的标志。创业的初始必然是艰辛的，同时压力也会很大，但小团队创业的优势是每个人的贡献是可测量的，在这种情况下，与其他愿意更努力工作的人一起组成一个团队，互相产生激励作用，从而共同谋取更高的回报，这远远好过加入大公司而将自己的工作与平庸之辈的工作平均化。这也是创业公司的意义所在。就如乔布斯曾经说过，创业的成败取决于最早加入公司的那十个人。\n要做出优秀的软件，就要有好的设计，对于很多学科来说，优秀设计的原则是共通的。例如，好的设计是简单的设计，当你被迫把东西做得很简单是，你就被迫直接面对真正的问题，也即设计的核心目的，做到这个，你就能以简洁又直接的方式满足用户的需求。又如，好的设计是启发性的设计，在软件行业中这意味着，你应该为用户提供一些基本模块，使得他们可以随心所欲的自由组合，这往往更加引人入胜。\n书中，作者还谈到了未来编程语言的发展方向，一种语言能否长期存在的最重要因素在于基本运算符，内核设计得越小、越干净，它的生命力就越顽强。对于黑客来说，他们需要简练的语言，这种语言具有最高层次的抽象和互动性，而且很容易装备，可以只用很少的代码就解决常见的问题，不管是什么程序，真正要写的代码几乎都与你自己的特点设置有关，其他具有普遍性的问题都有现成的函数库可以调用。然而，无论未来的编程语言发展如何，编程这项活动始终不会停止，它就像一种艺术创作，黑客就是艺术家，对于顶尖的黑客们来说，就像画家中流传的一句谚语，“画作永远没有完工的一天，你只是不再画下去而已”。\n","date":"2020-10-26T00:00:00Z","permalink":"https://morsuning.github.io/p/%E9%BB%91%E5%AE%A2%E4%B8%8E%E7%94%BB%E5%AE%B6-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《黑客与画家》 - 读书笔记"},{"content":"软件工程的历史演变要从软件发展，软件过程的发展和软件工程管理这三个角度去说。一方面，随着软件的快速发展，出现了许许多多越来越难以解决的问题，为统一地回答和解决这些问题，催生出了软件工程。另一方面，从软件工程中衍生出了软件过程和软件工程管理的概念，它们都是为了解决软件系统开发中的本质困难而诞生的。前者目标是更好地解决问题，而后者的目标则是为了复制成功经验。无论为解决开发软件系统的困难而产生的学科会发展成什么样，它们的核心目标都是解决软件系统开发中的不可见性，复杂性，可变性和一致性这几个本质困难的。下面将就软件发展的历史阶段来说一说这些困难是怎样逐渐增大的以及与之对应的软件过程的演变。\n软件发展的第一个阶段是软硬件一体化阶段，即软件开发要从硬件考虑，根据硬件情况去设计软件。产生这个阶段的最主要原因是硬件性能的限制。这一阶段主要使用的是硬件，用硬件做到一些之前只能全凭人脑才能做的事。软件几乎完全绑定与特定的硬件，无法迁移和复用，因此也就无法做更多的应用，对软件的想象力被局限在了硬件。对于软件开发团队来说，也局限在了小作坊和“个人英雄主义”的形式。当然在这一阶段，随着硬件的发展和伴随的软件复杂度的增高，人们逐渐发现了目前所采用的粗糙的软件开发方式“编码加改错(code and fix)”的问题，也出现了类似硬件开发过程的软件开发过程SAGE等。但失败的软件项目的还是在增多，因此才催生出“软件工程”的概念。\n第二个阶段是软件成为了独立的产品。进入到这一阶段的最主要的原因是软件不再局限于硬件，高级语言的出现使得一个平台上的软件同样可以运行在其他平台，同时个人计算机的出现使得大量的公司开始开发软件为个人计算机用户服务。由于需求的空前增长和可迁移性，这一阶段的软件开始出现了爆发，这种爆发不止是软件产品数量上的，更是软件规模上的和占计算机系统产品比重上的。这一阶段的软件产品展现出了远胜之前的复杂性，可变性，在此基础上想保证一致性也更加的困难。与之对应的这一时期的软件过程也有了很大发展，其一是形式化方法，意图从数学上找到一个一般性的方法，一劳永逸地指导复杂软件系统的开发问题。其二是结构化程序设计的思想，通过对程序划分模块，能将复杂的问题转化为简单的问题去解决。还有就是经典的生命周期模型“瀑布模型的出现”，让软件开发过程第一次有了一个比较有效和完善的指导方案。但是这一时期诞生的方法还存在着许多问题，形式化方法能应用的领域太狭窄，使用瀑布模型开发软件系统效率太低，而且还缺乏对软件质量的评估和提升的方法。所幸在这一阶段又出现了面向对象开发技术，它极大地改变了软件过程，直面软件开发过程中不可见性、复杂性、一致性和可变性的问题，提供了套编程范式，并在此范式上产生了一系列的编程语言，框架，设计思想等等技术，它们同样具备更高的开发效率。同时，也出现了以 CMM 为代表的软件过程改进模型等。\n第三个阶段的发展特征是网络化和服务化。这一阶段的到来除了软件进一步发展之外，主要是因为互联网和移动互联网的出现，极大地增加了用户规模和软件产品的使用方式，对软件产生了额外的要求，这就不可避免地又增加了软件复杂度。同时,由于竞争的需要,需求不确定性和系统的快速演化成为一个日益突出的问题。最后，软件分发和使用方式也出现了显著的变化，从拷贝复制逐渐过渡到基于网络的服务乃至云计算的形式，使得软件系统的版本更迭时间有了大为缩短的潜力。这些新情况的出现，使得软件开发的四大本质难题中，可变性和一致性对软件开发的影响更为突出，因而也催生了整个软件过程历史上最为纷繁的一个时代，大量的软件过程在这个阶段涌现出来。其中最具代表性的是一系列具有迭代式特征的开发方法，比如增量模型，螺旋模型和原型法等，这与之前的单一过程有很大区别。但是这些还不够，大型软件开发过程正逐渐地被视为一个交流和学习的过程，而迭代式的开发只是遵从这一规律，而并没有完全从这一过程本身出发去考虑，因此又出现“敏捷”开发方法，一系列以此为指导思想的方法诞生了，它们被统称为“敏捷方法”，比较著名的有SCRUM，XP和 Kanban 等。在敏捷方法之后，还有着开源软件方法，这是一种基于并行开发模式的软件开发的组织与管理方式。这种方法依赖于分散在全球的开发者和使用者的协作，而只有 Internet才能为这种大规模协助提供交流沟通的工具。廉价的Internet是开源软件得以发展的必要条件。\n到了现在，随着互联网应用的日益普及，用户对软件系统和服务提出了更多的要求，“多快好省”已成为大多数互联网时代软件用户的基本期望。具体而言，功能要丰富、更新要及时、要稳定可靠，同时用户获取服务的成本不能过高。所有这一切，都使得人们对软件产品和服务的需求与软件产品和服务的开发能力之间越来越不匹配。DevOps 因此产生了，它足以胜任需求很难确定，需要快速响应变更，需要快速提供价值，需要高可靠性、安全性的当下互联网时代对软件的要求，同时又进一步解决了之前提到的软件开发的本质性难题。\n从软件发展及对应的应对软件开发遇到的困难的学科——软件工程的发展，我们可以看到一些非常有意思的特点。\n第一，软件工程中提出的方法总是落后于问题的出现，和自然科学可以用来预测一些事情的发生不同，软件工程总是总结成功和失败的经验并提出一套方法去避免你犯错而不是去预测问题的出现并提前提出解决方法，这是目前的特征。\n第二，软件工程所关注的对象不仅局限于技术——即用于控制和管理复杂度的技术，还在于人，因为软件工程任务并不是由一个人完成的，人与人之间的交流也是复杂度的一部分。甚至是，它还占主导地位。因此，除了软件过程外，还有软件工程管理，包括软件项目管理和软件过程管理，它们将人视为重要因素，已经属于管理学的范畴了。在软件工程发展的过程中，管理所占的比重是逐渐加大的，可以预见在未来，管理和技术在软件工程中也一定会共同发展下去。\n第三，关于软件的知识将会越来越容易让人理解和更为广泛地分发，高级程序设计语言、框架技术和设计模式甚至与开发范式不但可以提高开发效率，更有助于理解一个大型项目。同时，互联网和开源软件的存在也为软件知识的学习和分享提供了便利。这同样也是有助于我们理解和管理复杂度的。还有迭代式开发方式的经久不衰也能印证这个观点，因为迭代式的方式符合人的认知规律，相信在未来这也将一直是主流的方式。\n总览软件工程历史的演变，无外乎在解决两方面的问题，一是软件开发本质上的困难，再就是时代的发展中对于软件系统更多的要求。一个好的软件过程或者是软件工程管理方法一定是同时在这两方面有较大进展的。我们无法一劳永逸地解决软件开发本质上的困难，但可以知道一部分软件未来发展的方向，这样其实就可以为软件工程学科发展提供目标了。\n","date":"2020-10-21T00:00:00Z","permalink":"https://morsuning.github.io/p/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%9A%84%E5%8E%86%E5%8F%B2%E6%BC%94%E5%8F%98%E7%AE%80%E8%BF%B0/","title":"软件工程的历史演变简述"},{"content":"很显然，作为一名技术人员，阅读一本不能提供任何技术的“管理学”书籍，首先需要的是耐心，需要的是那种想明白这样一本书到底是存在什么价值才会被奉为经典的好奇心。同时我也希望我能在阅读这样一部已经想读了好多年的经典书籍后能给自己留下一些有用的东西，因此我力图在这篇读书笔记中保留我学习到的知识、对本书的思考与评价和我自己的一些观点。\n本书是作者开发 System/360 项目时的经验结晶，本书讨论了软件工程项目过程中较为完整的要素，并给出了一些赫赫有名的观点和结论。最令我印象深刻的有这么几个地方。\n首先，它指出程序和编程系统和编程产品和系统级的编程产品这些概念之间是有本质上的不同的。通过这一个观点，首先说明的是文档，系统测试等并不实际起到软件产品的作用，却又是软件产品的重要组成部分的这些软件产物的重要性。失去了这些，那么一个产品将不能被一个团队共同开发，不能保证良好运行，不能继续进行维护和迭代。这完全符合本书所强调的软件任务的根本性问题即软件复杂度问题以及如何降低或者控制复杂度的问题（使用软件工程的除程序外的产物）。\n其次，本书开创性地通过量化的形式，讨论了软件工程中工作量和参与人员的关系，同样符合软件复杂性的论述：人越多，添加的复杂性越高，工作进度并不能保证随着人数的增加而增加——即人月神话。在人月神话中，最令人印象深刻的莫过于作者指出添加了人意味着增加了沟通的难度，也就是增加了软件工程任务的复杂度，所以没有人月神话，并通过 Brooks 法则揭示了真实的情况。这是本书的核心观点之一。接着，既然说明了增加人员并不能有效地推进软件工程任务的推进，那么该如何做呢，接下来的 13 章作者给出了自己的观点和建议，以剖析创造性工作的本质为暗线，讲述自己在项目实践中的经验为明线，给出了一套解决方案，按照话题划分，我在这里大致总结如下，只挑关键的部分重点讲述：\n介绍了一种外科手术团队般的开发团队组成和分工。 这里也有一些重要结论，如软件开发应该为“精英模式”，也就是永远让最有才华的人解决最难解决的问题，而不是让很多人共同解决问题，那样只会得到更差的结果，除非是进度的压迫迫使我们需要分解问题让更多的人更快地解决。此外，还对小团队高效但是进度慢，大团队低效的问题给出了解决办法。 讲述了如何保证设计系统时的概念完整性。 保证了这种完整性的产品有一个明显的例子，苹果公司(Apple Inc.)的产品，作为一个科技巨头，苹果公司拥有一个 IT/互联网公司拥有的一切重要的东西，处理器，编程语言，操作系统（桌面+移动），独到的工业设计，软件生态等等。但是苹果公司的产品相较于其强大的实力——少的惊人，却又有着极为出众的体验。这就是保证了设计时的概念完整性的结果，产品极为简洁、易用却又能解决所有该解决的问题。当然本书中是在陈述如何做到这件事。 给出了一个在二次设计系统时添加不必要的东西的警示。 描述了在第二次设计一个具相似功能的系统时（也可以说在迭代开发同一个系统时），应该具有什么样的约束和心态。 讲述了如何严格执行设计目标。 这部分是讲述如何进行手册的书写，安排会议，登记日志，安排测试小组等方式达到目标。 说明了如何促进团队交流。 如何估计编码工作量。 如何控制软件规模。 讲述了功能换空间的理论和如何做到时间空间折中还有改变数据表现形式的观点。我想说一点就是现在一些产品设计上的问题，即会有用空间换时间的操作。现代性能和存储空间已不是瓶颈，存储空间甚至被认为是廉价的这也是一些问题现在不会被考虑的原因。但是，从整体上想，如果想在的系统设计都不考虑这些问题，那未来的某一天，对于一个没怎么考虑过这些问题的超大型复杂系统，显然它是可以正常运行的，但是会变得超级臃肿不堪，数据过度冗余到了无法接受的地步，这样总归是要吃以空间换时间的恶果的。 介绍了重要的文档。 如何为变化（需求变更，人员变更等）做准备。 通用工具的使用。 如何保证系统的整体性。 如何进行进度控制。、 需要对系统进行什么样的说明。 在这些话题中，作者同样给出了很多结论和建议，它们共同组成了一个软件工程活动如何进行的指导方案，或者至少是一个 40 多年前的较为完美的方案。\n本书的另外一个核心观点是没有银弹，这是一个预言，一个谦虚的预言，到现在也能成立。作者指出没有任何技术或者管理上的进展，能够独立地许诺在生产率、可靠性或简洁性上取得数量级地提高。这是建立在对软件工程活动本质上的认识上的，虽然作者没有直接地指出这一点，但我们很容易能得出这样的结论：软件工程的本质是一种纯粹的创造活动，我们没有办法大幅度提高人的创造力，也就没有办法大幅度提高生产力。如果对于本质的论断正确，那毫无疑问这个预言是能够成立的。当然，四十多年后的今天，软件的生产率确实提升了，这也是建立在无数抽象和好用的工具及理念的基础之上的。时至今日，仍然没有一个实质意义上的银弹出现。本书也讨论了一些根本解决问题的方法，最让人印象深刻的是“构建软件最可能的彻底解决方案是不开发任何软件”，这个观点完全可以套用到现代的云计算技术上，结合本书的上下文，可以解释云计算所拥有的巨大优势——几乎实现了量化购买“人月”，成本当然远远低于开发自己的全套系统。同时也能解释互联网公司为什么要追求“唯快不破”，其中一方面是因为一旦竞争对手的产品占据了市场，那么自己开发的系统实际上是徒增成本而且还得不到多少收益了。\n结合软件工程管理的角度说，我们可以做一个简单的总结。我们要管理的终极目标，正如 SCIP 第一课中所讲述的观点——计算机科学家的任务就是学会如何管理复杂度所说，就是通过人，去设计一个复杂度很高的东西并很好地管理它的复杂度，只不过计算机科学家还要更加地关注硬件罢了。所以说，管理的主要要素，即为人员（团队），文档，成本，进度，工作空间。我们在软件工程管理这个话题下所讨论的一切都要围绕着如何组织这些，这些东西里面包含哪些内容能最大化地帮助我们完成目标进行，而重中之重，是为组织沟通。\n本书最大的价值在于对企业项目管理人员的启示，也对创业者大有裨益。它开创性地，系统性地思考了计算机产品开发过程中会出现的问题。同时，还让我们对软件工程管理中的核心问题有一个认识和思考的过程，所以此书中的理论历经 40 多年经久不衰。本书中的很多经验已经被进一步发展形成一套新的管理方式与体系，同时还有一些以前存在的问题被完全解决。如第七章中有明显已不在当前时代的出现的印制工作手册，目前文档基本完全以电子形式。第十章提到的按版本印制的团队文档，现在已被共享文档和项目知识库取代。第十二章提到的程序库，现在已有成熟的分布式版本控制工具如 Git 等，也有在线代码库 GitHub 等，还有集成经理的角色，现在则被成熟的 Code Review 机制取代。第十三章中提到的非常具有前瞻性的结构化编程现在则发展成了开发框架，计算框架和脚手架项目甚至设计模式等形式。第十五章提到的代码格式化规范等等现在已经可以通过工具来实现。\n可以看到，很多提到的技术都变成规范化的东西，本书所讲的内容没有被抛弃的，这让我知道了这些东西是因为什么需要而出现的。\n由于缺乏具体的实践经验我只能讨论我从书中学习到的东西和我的看法而不是在书中所表达的观点引发的我对实际问题的思考和改进，这也是这一篇笔记的遗憾，希望在未来的某一天，我能带着这本书中的观点，重新审视我做过的事，完成从单纯的技术人员到管理人员的转变。\n","date":"2020-09-26T00:00:00Z","permalink":"https://morsuning.github.io/p/%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《人月神话》 - 读书笔记"}]