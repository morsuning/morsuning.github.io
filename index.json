[{"categories":["分享"],"content":"常用软件 ","date":"2024-05-11","objectID":"/post/:1:0","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["分享"],"content":"软件来源 macwk 学习版MacOS软件下载 Mac App Store 苹果官方应用商店，方便下载、卸载、更新和付费 Homebrew MacOS软件包管理器，通常用来安装开源软件 各软件官方网站 ","date":"2024-05-11","objectID":"/post/:1:1","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["分享"],"content":"必备软件 applite brew GUI 建议在此安装推荐的软件和任何brew安装的软件，方便管理 appcleaner App卸载工具 clash-verge-rev | hiddify-next 科学上网工具 The Unarchiver 压缩工具 item2 | wrap 终端模拟器 edge | arc 浏览器 motrix 全功能下载管理器 VSCode 全能代码编辑器 欧陆词典 单词查询\u0026翻译 Notion 在线笔记 | Anytype 本地+在线笔记 Obsidian 离线可同步笔记 Microsoft Office 微软全家桶，办公专用 SnippetsLab | Lepton 优秀的代码片段管理工具, 轻量, 可基于菜单栏操作 reeder RSS订阅浏览器 iina or infuse 视频播放器 koodo Reader 电子书管理，可替代calibre，支持多设备同步及epub等多种电子书格式 dash 开发文档查阅 buhontfs NTFS磁盘工具，可读写NTFS磁盘，我是免费期入的，可用其他软件替代 stats iStats开源平替，菜单栏系统资源监视器 tailscale 内网穿透工具 raycast | utools 效率工具平台，可集成各类效率插件，补全系统级功能，raycast 插件推荐 Barbee | Bartender 菜单栏项自定义隐藏，避免被刘海遮挡 PDF Expert pdf编辑工具 XnViewMP 图片查看格式转换压缩 rustdesk 远程桌面工具 whisky 运行windows应用 playcover 运行未在Mac App Store上架的ios应用 UTM | Parallels Desktop 虚拟机软件 Quick Look 插件: 选中文件，按空格预览 QuicklookStephen - 查看未知拓展名的纯文本文件 brew install –cask qlstephen QLMarkdown - 空格键预览 Markdown 文本效果 - brew install –cask qlmarkdown ","date":"2024-05-11","objectID":"/post/:1:2","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["分享"],"content":"可选软件 capslock 将CapsLock键改造为强力功能修饰键 Downie 下载视频，也可以使用cobalt这个网站 switchhosts host切换 KeyCastr 将mac按键显示在屏幕上，分享演示、录制视频或动图时超赞 pixpin 截图\u0026OCR工具 QSpace \u0026 TotalFinder 访达增强 BetterMouse 全能鼠标驱动设置 permute3 格式转换 android file transfer 传输安卓系统文件 Etcher 制作 U 盘镜像 ventoy 新一代多系统启动U盘解决方案 CheatSheet 按command显示当前应用快捷键 AlDente 用于MacBooks的ALL-IN-ONE充电限制器应用软件 开发者工具 DBeaver ｜ Naviat 数据库客户端 postman API管理工具 chsrc 全平台一件换源工具 ","date":"2024-05-11","objectID":"/post/:1:3","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["分享"],"content":"命令行工具简要推荐 wget 下载工具 tmux 终端复用 cloc 代码行数统计命令行工具 proxychains-ng 终端命令行下代理神器，可以让指定的命令走设置好的代理，内网渗透、科学上网必备工具 brew install proxychains-ng 配置文件: /usr/local/etc/proxychains.conf proxychains4 curl https://www.google.com.hk 通过代理访问 proxychains4 -q /bin/zsh 开启zsh全局代理 配置文件最后一行配置示例: http 127.0.0.1 7897 建议配置alias pc=’proxychains4’ ","date":"2024-05-11","objectID":"/post/:1:4","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["分享"],"content":"Shell 使用当前MacOS下体验最佳终端Warp，搭配MacOS自带的zsh及其配置框架oh-my-zsh 先依次安装 oh-my-zsh: zsh配置框架 sh -c “$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" brew: 包管理工具 ","date":"2024-05-11","objectID":"/post/:2:0","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["分享"],"content":"配置oh-my-zsh 修改～/.zshrc 主题 ZSH_THEME=”robbyrussell”默认 推荐主题：简洁 - cloud, af-magic;详细 - ys, dst zsh插件 自动跳转插件autojump git clone https://github.com/wting/autojump.git $ZSH_CUSTOM/plugins/autojump; cd $ZSH_CUSTOM/plugins/autojump; python3 install.py; 只要访问过某个目录直接 j 目录 即可跳转到该目录 extract (oh-my-zsh内置)一个命令解压所有文件 x \u003c文件名\u003e 即可解压该文件 zsh-syntax-highlighting 语法高亮插件 git clone https://github.com/zsh-users/zsh-syntax-highlighting $ZSH_CUSTOM/plugins/zsh-syntax-highlighting; zsh-autosuggestions 命令自动补全插件 git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions; 最终的参考.zshrc文件 # If you come from bash you might have to change your $PATH. export PATH=$HOME/env/bin:$HOME/.local/bin:/usr/local/bin:/opt/homebrew/bin:$PATH # Homebrew mirror export HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/brew.git\" export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/homebrew-core.git\" export HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.ustc.edu.cn/homebrew-bottles\" export HOMEBREW_API_DOMAIN=\"https://mirrors.ustc.edu.cn/homebrew-bottles/api\" # Path to your oh-my-zsh installation. export ZSH=\"$HOME/.oh-my-zsh\" # Set name of the theme to load --- if set to \"random\", it will # load a random theme each time oh-my-zsh is loaded, in which case, # to know which specific one was loaded, run: echo $RANDOM_THEME # See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes ZSH_THEME=\"ys\" # Set list of themes to pick from when loading at random # Setting this variable when ZSH_THEME=random will cause zsh to load # a theme from this variable instead of looking in $ZSH/themes/ # If set to an empty array, this variable will have no effect. # ZSH_THEME_RANDOM_CANDIDATES=( \"robbyrussell\" \"agnoster\" ) # Uncomment the following line to use case-sensitive completion. # CASE_SENSITIVE=\"true\" # Uncomment the following line to use hyphen-insensitive completion. # Case-sensitive completion must be off. _ and - will be interchangeable. # HYPHEN_INSENSITIVE=\"true\" # Uncomment one of the following lines to change the auto-update behavior # zstyle ':omz:update' mode disabled # disable automatic updates # zstyle ':omz:update' mode auto # update automatically without asking # zstyle ':omz:update' mode reminder # just remind me to update when it's time # Uncomment the following line to change how often to auto-update (in days). # zstyle ':omz:update' frequency 13 # Uncomment the following line if pasting URLs and other text is messed up. # DISABLE_MAGIC_FUNCTIONS=\"true\" # Uncomment the following line to disable colors in ls. # DISABLE_LS_COLORS=\"true\" # Uncomment the following line to disable auto-setting terminal title. # DISABLE_AUTO_TITLE=\"true\" # Uncomment the following line to enable command auto-correction. # ENABLE_CORRECTION=\"true\" # Uncomment the following line to display red dots whilst waiting for completion. # You can also set it to another string to have that shown instead of the default red dots. # e.g. COMPLETION_WAITING_DOTS=\"%F{yellow}waiting...%f\" # Caution: this setting can cause issues with multiline prompts in zsh \u003c 5.7.1 (see #5765) # COMPLETION_WAITING_DOTS=\"true\" # Uncomment the following line if you want to disable marking untracked files # under VCS as dirty. This makes repository status check for large repositories # much, much faster. # DISABLE_UNTRACKED_FILES_DIRTY=\"true\" # Uncomment the following line if you want to change the command execution time # stamp shown in the history command output. # You can set one of the optional three formats: # \"mm/dd/yyyy\"|\"dd.mm.yyyy\"|\"yyyy-mm-dd\" # or set a custom format using the strftime function format specifications, # see 'man strftime' for details. # HIST_STAMPS=\"mm/dd/yyyy\" # Would you like to use another custom folder than $ZSH/custom? # ZSH_CUSTOM=/path/to/new-custom-folder # Which plugins would you like to load? # Standard plugins can be found in $ZSH/plugins/ # Custom plugins may be added to $ZSH_CUSTOM/plugins/ # Example format: plugins=(rails git textmate ruby lighthouse) # Add ","date":"2024-05-11","objectID":"/post/:2:1","tags":["MacOS","Shell"],"title":"MacOS 开发软件及 Shell 配置推荐","uri":"/post/"},{"categories":["问题"],"content":"记录一次对象存储在曙光服务器（Hygon CPU）上CPU占用异常问题的定位过程，相关信息已脱敏 ","date":"2023-12-21","objectID":"/post/:0:0","tags":["对象存储","问题定位","CPU"],"title":"记一次CPU占用过高问题定位","uri":"/post/"},{"categories":["问题"],"content":"环境说明 CPU规格：每个服务器2 * Hygon C86 7380 32-Core Processor，一共128个虚拟核，具体规格如下： 通过lstopo –of png \u003e out.png 命令可以看到服务器CPU（numa架构）的及其外设（内存、硬盘、网卡）的拓扑结构图 ","date":"2023-12-21","objectID":"/post/:1:0","tags":["对象存储","问题定位","CPU"],"title":"记一次CPU占用过高问题定位","uri":"/post/"},{"categories":["问题"],"content":"问题现象 3个节点的集群跑216并发的128M大对象，测试集群带宽，对象存储进程CPU占用上千，是正常节点CPU占用的数十倍，且CPU利用率高在三个节点中随机出现，最少1个节点出现，最多3个节点出现 通过perf命令抓取性能数据，发现CPU利用率与IPC负相关，与L1-dcache-loads负相关，与dTLB-loads负相关 下图最右边节点的CPU利用率最高 ","date":"2023-12-21","objectID":"/post/:2:0","tags":["对象存储","问题定位","CPU"],"title":"记一次CPU占用过高问题定位","uri":"/post/"},{"categories":["问题"],"content":"定位结论 是Hygon CPU本身的问题，CPU占用高是CPU内部调度的问题 ","date":"2023-12-21","objectID":"/post/:3:0","tags":["对象存储","问题定位","CPU"],"title":"记一次CPU占用过高问题定位","uri":"/post/"},{"categories":["问题"],"content":"定位过程 确定硬盘和网络都不是瓶颈 屏蔽对象存储服务进程的后台任务，不改变该现象 使用go pprof工具排除程序本身的问题 通过perf工具确定CPU利用率高的节点上CPU流水线的效率很低，各节点CPU效率有数倍差距 经过绑核验证，使用128核/64核/32核/16核/8核都能支持1.5G的对象带宽，无论绑多少核CPU都能用满 ","date":"2023-12-21","objectID":"/post/:4:0","tags":["对象存储","问题定位","CPU"],"title":"记一次CPU占用过高问题定位","uri":"/post/"},{"categories":["问题"],"content":"调优建议 建议在Hygon CPU上部署对象存储服务时使用16核的绑核方式（即numa中的一个node），例： taskset -apc 32-39, 96-103 2638647 其中，32-29, 96-103是绑定的CPU核的变化，可以通过Iscpu获取，或者numactl-H获取；2638647 是需要绑核的进程ID 当限制核数以后，会导致prometheus获取metrics效据变慢，具体表现在对象存储服务和node_exporter向prometheus回写数据非常慢。绑16核的场景下，回写metrics最多要花37秒，因此建议作出如下调整： ﻿﻿延长prometheus的指标拉取周期，由15秒拉取一次调整为1分钟拉取一次 延长prometheus的指标拉取超时时长，由10秒超时调整为55秒超时 ","date":"2023-12-21","objectID":"/post/:5:0","tags":["对象存储","问题定位","CPU"],"title":"记一次CPU占用过高问题定位","uri":"/post/"},{"categories":["Kubernetes"],"content":"1 Kubernetes存储相关概念及实现原理 ","date":"2023-12-01","objectID":"/post/:1:0","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.1 PV \u0026 PVC 概念 Kubernetes定义了PV（PersistentVolume）与PVC（PersistentVolumeClaim）这两个概念让用户使用持久化存储，是在用户与存储服务提供者之间添加的一个中间层。 用户指Kubernetes应用的开发者，存储服务提供者一般是Kubernetes集群的运维人员，或者是第三方存储服务提供商的服务人员 存储服务提供者事先根据PV支持的存储卷插件及适配的存储方案（目标存储系统）细节定义好可以支撑存储卷的底层存储空间 然后由用户通过PVC声明要使用的存储特性来绑定符合条件的最佳PV定义存储卷，实现存储系统的使用与管理职能的解耦，大大简化了用户使用存储的方式 为什么这么设计 解决2个问题 卷对象的生命周期无法独立于Pod而存在 用户必须足够熟悉存储的使用和配置才能在Pod上配置和使用卷 PV是由集群管理员于全局级别配置的预挂载存储空间，它通过支持的存储卷插件及给定的配置参数关联至某个存储系统上可用数据存储的一段空间，这段存储空间可能是Ceph存储系统上的一个存储映像、一个文件系统（CephFS）或其子目录，也可能是NFS存储系统上的一个导出目录等。 PV将存储系统之上的存储空间抽象为Kubernetes系统全局级别的API资源，由集群管理员负责管理和维护。 将PV提供的存储空间用于Pod对象的存储卷时，用户需要事先使用PVC在名称空间级别声明所需要的存储空间大小及访问模式并提交给Kubernetes API Server，接下来由PV控制器负责查找与之匹配的PV资源并完成绑定。随后，用户在Pod资源中使用persistentVolumeClaim类型的存储卷插件指明要使用的PVC对象的名称即可使用其绑定到的PV所指向的存储空间，如图所示。 PV和PVC是一对一的关系：一个PVC仅能绑定一个PV，而一个PV在某一时刻也仅可被一个PVC所绑定。 为了能够让用户更精细地表达存储需求，PV资源对象的定义支持存储容量、存储类、卷模型和访问模式等属性维度的约束。相应地，PVC资源能够从访问模式、数据源、存储资源容量需求和限制、标签选择器、存储类名称、卷模型和卷名称等多个不同的维度向PV资源发起匹配请求并完成筛选。 PV与PVC示例 \u0026 用户使用示例 # PV apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs spec: # 存储类名称 storageClassName: manual # 存储资源 capacity: storage: 10Gi # 访问模式 accessModes: - ReadWriteMany # 数据源 nfs: path: /opt/nfs-volume server: 172.26.204.144 --- # PVC kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-nfs spec: storageClassName: manual accessModes: - ReadWriteMany resources: requests: storage: 10Gi --- # 用户使用 apiVersion: apps/v1 kind: Deployment metadata: name: test-nfs labels: app: test spec: replicas: 1 selector: matchLabels: app: test template: metadata: labels: app: test spec: containers: - name: busybox image: busybox # 使用卷 volumeMounts: - name: data mountPath: /data # 声明卷 volumes: - name: data persistentVolumeClaim: claimName: pvc-nfs PV和PVC的生命周期如下表所示 操作 PV 状态 PVC 状态 创建 PV Available - 创建 PVC Available Pending Bound Bound 删除 PV -/Terminating Lost/Bound 重新创建 PV Bound Bound 删除 PVC Released - 后端存储不可用 Failed - 删除 PV 的 claimRef Available - PV生命周期 创建后未能正确关联到存储设备的PV处于Pending状态，成功关联后转为Available 一个Available状态的PV与PVC关联后变为Bound状态 处于Bound状态的PV，其关联的PVC被删除后，变为Release状态 当PV的回收策略为recycle或手动删除PVC引用时，PV从Release状态变为Available状态 可选的回收策略： Retain（保留）：删除PVC后将保留其绑定的PV及存储的数据，但会把该PV置为Released状态，它不可再被其他PVC所绑定，且需要由管理员手动进行后续的回收操作：首先删除PV，接着手动清理其关联的外部存储组件上的数据，最后手动删除该存储组件或者基于该组件重新创建PV Delete（删除）：对于支持该回收策略的卷插件，删除一个PVC将同时删除其绑定的PV资源以及该PV关联的外部存储组件；动态的PV回收策略继承自StorageClass资源，默认为Delete。多数情况下，管理员都需要根据用户的期望修改此默认策略，以免导致数据非计划内的删除 Recycle（回收）：对于支持该回收策略的卷插件，删除PVC时，其绑定的PV所关联的外部存储组件上的数据会被清空，随后，该PV将转为Available状态，可再次接受其他PVC的绑定请求。不过，该策略已被废弃 recycle失败时，PV将从Released状态变为Failed状态 可通过手动删除PVC将PV状态变成Available PVC生命周期 一个Pending状态PVC与PV绑定后变为Bound状态 处于Bound状态的PVC，与其关联的PV被删除后变为Lost状态 Lost状态的PVC再次与PV绑定后变成Bound状态 PV和PVC的生命周期可概括为存储制备（Provision）、存储绑定、存储使用、存储回收四个阶段 这是使用Kubernetes存储最基本的模式，但会产生2个问题： 存储服务提供者难以预测用户的真实需求，如果用户提交了一个PVC，但是PV控制器没有找到合适的PV与之绑定，容器创建就会失败 会造成资源浪费，如集群中创建的PV容量都是10G的，但是如果创建了一个声明使用5G的PVC，依然会绑定到10G的PV 因此Kubernetes提供了一种动态自动创建PV的机制，被称为动态制备（dynamic provision），刚刚说的手动创建PV的方式又被称为静态制备（static provision） ","date":"2023-12-01","objectID":"/post/:1:1","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.2 StorageClass \u0026 Plugin Kubernetes使用一种API对象叫做存储类（StorageClass）提供动态预配、按需创建PV的机制。需要存储服务提供者事先借助存储类创建出一到多个“PV模板”，并在模板中定义好基于某个存储系统创建PV所依赖的存储组件（例如Ceph RBD存储映像或CephFS文件系统等）时需要用到的配置参数，包括PV的属性如存储类型、Volume大小等以及创建这种PV需要的存储插件 # SC示例 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: nfs # 指定存储服务方（Provisioner，预配器），基于该字段判断使用的存储插件，内置插件以kubernetes.io/为前缀 provisioner: nfs.csi.k8s.io parameters: server: 10.0.0.11 share: /data # 默认回收策略 reclaimPolicy: Delete # 定义如何为PVC完成预配和绑定 volumeBindingMode: Immediate # 当前类动态创建的PV资源的默认挂载选项 mountOptions: - nfsvers=4.1 使用动态制备的方式创建PVC时，用户需要为其指定要使用PV模板（StorageClass资源），而后PV控制器会自动连接相应存储类上定义的 目标存储系统的管理接口 ，请求创建匹配该PVC需求的存储组件，并将该存储组件创建为Kubernetes集群上可由该PVC绑定的PV资源。 Kubernetes通过卷插件（Volume Plugins）的机制接入目标存储系统，Kubernetes定义了一系列管理接口，插件即是在一个存储系统的基础上实现了这些管理接口的代码 卷插件分为In-Tree和Out-of-Tree两类 In-Tree的代码是放在Kubernetes内部的，和Kubernetes一起发布、管理与迭代，优点是使用方便，缺点是迭代速度慢、灵活性差，目前除了少数通用存储如nfs，hostpath，正在逐渐被废弃 Out-of-Tree是由存储厂商提供的，有FlexVolume和CSI两种实现机制，目前FlexVolume已被废弃，Kubernetes官方目前提供了生产可用的NFS，SMB，NVMF、host-path四种CSI插件 ","date":"2023-12-01","objectID":"/post/:1:2","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.3 Kubernetes存储相关组件及架构 PV控制器（集群维度）：负责PV及PVC的整个生命周期管理，主要监听PV/PVC/SC三类资源，当发现这些资源的CRU操作时，PV控制器会判断是否需要创建、删除、绑定和回收卷；并根据需求进行存储卷的预配和删除操作 AD控制器（集群维度）：专用于存储设备的附加和拆除操作的组件，能够将存储设备关联（attach）至目标节点或从目标节点之上剥离（detach） AD控制器监听Pod/Node时间，如有必要，调用Volume Plugin执行AD操作 存储卷管理器也能触发AD操作，但它只监听调度到本节点的Pod 存储卷管理器（节点维度）：kubelet内置管理器组件之一，用于在当前节点上执行存储设备的挂载（mount）、卸载（unmount）和格式化（format）等操作；另外，存储卷管理器也可执行节点级别设备的附加（attach）及拆除（detach）操作 存储卷插件：Kubernetes存储卷功能的基础设施，是存储任务相关操作的执行方；它是存储相关的扩展接口，用于对接各类存储设备 PV控制器、AD控制器和存储卷管理器均构建于存储卷插件之上，以提供不同维度管理功能的接口，具体的实现逻辑均由存储卷插件完成 最初，只有VolumeManager能够Attach/Detach，但是节点宕掉后，它已经挂载的卷需要在其它节点进行Detach，然后再Attach，这个必须依赖外部才能完成，AD控制器因此产生 现在，到底在何处进行Attach/Detach，取决于Volume Plugin，如果实现了Attach相关接口，则在AttachDetach中执行，否则，在Volume Manager上执行 ","date":"2023-12-01","objectID":"/post/:1:3","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.4 Kubernetes存储实现原理 PV对象成为容器内的持久化存储过程，实际上就是将一个宿主机上的目录跟一个容器里的目录绑定挂载在了一起 如果使用远程存储服务实现容器数据的持久化，Kubernetes所做的就是将这个远程存储服务挂载到宿主机上的一个目录，以供将来进行绑定挂载时使用，这个准备宿主机目录的过程可以称为“两阶段处理” 1 第一阶段Attach，由AD控制器完成，类似于插入硬盘 当一个Pod调度到一个节点上后，kubelet要负责为这个pod创建它的volume目录，默认情况下，kubelet为volume创建的目录是一个宿主机上的路径，如 /var/lib/kubelet/pods/\u003cPod ID\u003e/volumes/kubernetes.io-\u003cvolume type\u003e/\u003cvulume name\u003e 接下来进行的操作取决于Volume类型，如使用远程块存储，会调用相应的API，将其提供的持久化盘挂载到宿主机上，如果使用CSI，则会调用相应的CSI接口 2 第二阶段mount，也由存储卷管理器完成，类似于格盘并挂载 完成Attach阶段后，kubelet需要格式化这个磁盘设备并将它挂载到宿主机指定的挂载点上，即之前提到的宿主机目录 mount完成后Volume的宿主机目录就是一个持久化目录了，容器写入的内容会被存储在存储服务中，如果Volume类型是远程文件存储服务（如NFS），kubelet会跳过attach阶段，因为使用NFS不需要经过“插盘”这个操作，直接mount即可 Kubernetes 通过在具体的插件实现接口上提供不同的参数列表，定义和区分这两个阶段 第一阶段Kubernetes通过nodeName，即宿主机的名字区分 第二阶段通过dir，即Volume宿主机的目录区分 完成两阶段处理后，kubelet只需将这个volume目录通过CRI里的Mounts参数传递给Docker，就可以为Pod里的容器挂载这个持久化的Volume了 ","date":"2023-12-01","objectID":"/post/:1:4","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.5 CSI 介绍 Kubernetes从1.8版本开始已经停止接受in-tree卷插件，并建议所有供应商实现out-of-tree卷插件，而2种out-of-tree卷扩展机制之一的flexvolume已经被废弃，所以目前CSI目前已成为接入自定义存储的唯一途径 CSI架构 CSI，全称Container Storage Interface，是一种规范，在Kubernetes核心存储(即上文提到的PV控制器、AD控制器等)之外，CSI又引入了2组外部组件，方便存储提供者开发和使用CSI标准 一组由Kubernetes官方提供，一系列external组件负责注册CSI Driver（即第三方提供的存储插件）或监听Kubernetes对象资源，从而发起csi Driver调用，都作为CSI Controller的sidecar容器 node-driver-register：一个sidecar容器，可从CSI driver获取驱动程序信息（使用NodeGetInfo），并使用kubelet插件注册机制在该节点上的kubelet中对其进行注册 External Provisioner：一个sidecar容器，用于监视Kubernetes PersistentVolumeClaim对象并针对驱动程序端点触发CSI CreateVolume和DeleteVolume操作。external-attacher还支持快照数据源。如果将快照CRD资源指定为PVC对象上的数据源，则此sidecar容器通过获取SnapshotContent对象获取有关快照的信息，并填充数据源字段，该字段向存储系统指示应使用指定的快照填充新卷 External Attacher：一个sidecar容器，用于监视Kubernetes VolumeAttachment对象并针对驱动程序端点触发CSI ControllerPublish和ControllerUnpublish操作 livenessprobe：一个sidecar容器，用于监视CSI驱动程序的运行状况，并通过Liveness Probe机制将其报告给Kubernetes。这使Kubernetes能够自动检测驱动程序问题并重新启动Pod以尝试解决问题 External Resizer：一个sidecar容器，监听PVC对象，如果用户在PVC对象请求更多存储，该组件会调用CSI Controller的NodeExpandVolume接口对volume进行扩容 External Snapshotter：一个Snapshot Controller的sidecar容器，Snapshot Controller会根据集群中创建的Snapshot对象创建对应的VolumeSnapshotContent，而External Snapshotter负责监听之，监听到其发生变化时，将其对应参数传递给CSI Controller，调用其CreateSnapshot接口 另一组需要存储提供者实现，也是卷插件必须的组成部分，这组中包括3个服务，分别需要实现三组grpc接口 CSI Identity： 提供插件信息、能力、探测插件状态 CSI Controller（Provision和Attach）：负责创建和管理卷 CSI Node（mount）：在节点上完成和卷相关的功能，如Publish/Unpublish，Stage/Unstage CSI中Capabilities会标识出来此插件提供哪些能力，如IdentityServer中的GetPluginCapabilities方法，ControllerServer中的ControllerGetCapabilities方法和NodeServer中的NodeGetCapabilities CSI交互模型 Kubelet和CSI插件的交互方式： Kubelet直接通过UDS，向CSI发起NodeStageVolume、NodePublishVolume等调用 Kubelet通过插件注册机制来发现CSI插件及其UDS。这意味着CSI插件必须在任何节点上进行Kubelet插件注册 Master和CSI插件的交互方式： K8S控制平面不直接和CSI插件交互 K8S控制平面组件仅仅通过K8S API进行相互交互 CSI插件必须监控相关K8S API资源，并触发对应的CSI操作，例如卷创建、Attach、快照生成等 CSI对象 Kubernetes提供了2个CSI相关的API对象CSIDriver和CSINode，方便CSI插件集成到Kubernetes CSIDriver提供的功能： 简化CSI驱动的发现：在安装时附带一个CISDrive对象，就可以将存储提供者的插件注册到Kubernetes中 定制K8S的行为：Kubernetes具有一套和CSI驱动交互的默认规则，例如默认它会调用Attach/Detach操作。使用CSIDriver··对象可以定制这一行为 CSIDriver示例： apiVersion: storage.k8s.io/v1 kind: CSIDriver metadata: # 和CSI驱动的全名一致 name: mycsidriver.example.com spec: # 提示K8S，此驱动需要Attach操作（因为驱动实现了ControllerPublishVolume方法）， # 并且需要在Attach之后等待操作完成，然后再进行后续的Mount操作 # 默认值true attachRequired: true # 提示K8S，在挂载阶段，此驱动需要Pod的信息（名称、Pod的UID等） # Pod信息会在NodePublishVolume调用中作为volume_context传递： # \"csi.storage.k8s.io/pod.name\": pod.Name # \"csi.storage.k8s.io/pod.namespace\": pod.Namespace # \"csi.storage.k8s.io/pod.uid\": string(pod.UID) # \"csi.storage.k8s.io/serviceAccount.name\": pod.Spec.ServiceAccountName podInfoOnMount: true # 1.16中添加，到1.18为止beta # 此驱动支持的Volume Mode volumeLifecycleModes: - Persistent # 默认，常规PV/PVC机制 - Ephemeral # 内联临时存储（inline ephemeral volumes） 由CSIDrive注册后就可以通过kubectl查看所有安装的CSI驱动 kubectl get csidrivers.storage.k8s.io CSINode对象存放CSI驱动产生的、节点相关的信息，它的功能是： 映射K8S节点名称到CSI节点名称：CSI的GetNodeInfo调用返回的name，是存储系统引用节点使用的名字。在后续的ControllerPublishVolume调用中K8S使用该名字引用节点 为kubelet提供和kube-controller-manager、kube-scheduler交互的机制，不管CSI插件是否可用（注册到节点） 卷拓扑：CSI的GetNodeInfo调用会返回一系列标签（键值对），来识别节点的拓扑信息。K8S使用这些信息进行拓扑感知的卷创建。这些键值对存放在Node对象中，Kubelet会把键存放在CSINode中，供后续引用 CSINode示例： apiVersion: storage.k8s.io/v1 kind: CSINode metadata: name: node1 spec: drivers: - name: mycsidriver.example.com nodeID: storageNodeID1 topologyKeys: ['mycsidriver.example.com/regions', \"mycsidriver.example.com/zones\"] ","date":"2023-12-01","objectID":"/post/:1:5","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.6 CSI插件实现 存储提供者需要实现三个服务，CSI Identity，CSI Controller和CSI Node，这是在CSI规范中定义的，即上文提到的外部组件，这三个服务必须实现一组grpc接口 CSI Identity // 让调用者（K8S组件、CSI Sidecar容器）能识别驱动，知晓它具有哪些可选特性 service Identity { // 获取插件名称和版本 rpc GetPluginInfo(GetPluginInfoRequest) returns (GetPluginInfoResponse) {} // 获取插件功能 rpc GetPluginCapabilities(GetPluginCapabilitiesRequest) returns (GetPluginCapabilitiesResponse) {} // 检查插件是否运行 rpc Probe (ProbeRequest) returns (ProbeResponse) {} } CSI Controller（Provision和Attach），可以运行在任何节点，实现创建卷、创建快照等功能，可选 service Controller { // 必须实现 rpc CreateVolume (CreateVolumeRequest) returns (CreateVolumeResponse) {} // 必须实现 rpc DeleteVolume (DeleteVolumeRequest) returns (DeleteVolumeResponse) {} rpc ControllerPublishVolume (ControllerPublishVolumeRequest) returns (ControllerPublishVolumeResponse) {} rpc ControllerUnpublishVolume (ControllerUnpublishVolumeRequest) returns (ControllerUnpublishVolumeResponse) {} // 必须实现 rpc ValidateVolumeCapabilities (ValidateVolumeCapabilitiesRequest) returns (ValidateVolumeCapabilitiesResponse) {} rpc ListVolumes (ListVolumesRequest) returns (ListVolumesResponse) {} rpc GetCapacity (GetCapacityRequest) returns (GetCapacityResponse) {} // 必须实现 rpc ControllerGetCapabilities (ControllerGetCapabilitiesRequest) returns (ControllerGetCapabilitiesResponse) {} // nfs-csi已实现 rpc CreateSnapshot (CreateSnapshotRequest) returns (CreateSnapshotResponse) {} // nfs-csi已实现 rpc DeleteSnapshot (DeleteSnapshotRequest) returns (DeleteSnapshotResponse) {} rpc ListSnapshots (ListSnapshotsRequest) returns (ListSnapshotsResponse) {} rpc ControllerExpandVolume (ControllerExpandVolumeRequest) returns (ControllerExpandVolumeResponse) {} rpc ControllerGetVolume (ControllerGetVolumeRequest) returns (ControllerGetVolumeResponse) { option (alpha_method) = true; } rpc ControllerModifyVolume (ControllerModifyVolumeRequest) returns (ControllerModifyVolumeResponse) { option (alpha_method) = true; } } CSI Node（mount），任何存储提供者的卷，想要Publish的节点都需要运行此插件 service Node { rpc NodeStageVolume (NodeStageVolumeRequest) returns (NodeStageVolumeResponse) {} rpc NodeUnstageVolume (NodeUnstageVolumeRequest) returns (NodeUnstageVolumeResponse) {} // 将卷挂载到节点上 rpc NodePublishVolume (NodePublishVolumeRequest) returns (NodePublishVolumeResponse) {} // 卸载卷 rpc NodeUnpublishVolume (NodeUnpublishVolumeRequest) returns (NodeUnpublishVolumeResponse) {} // 获取卷状态 rpc NodeGetVolumeStats (NodeGetVolumeStatsRequest) returns (NodeGetVolumeStatsResponse) {} rpc NodeExpandVolume(NodeExpandVolumeRequest) returns (NodeExpandVolumeResponse) {} // 必须实现 rpc NodeGetCapabilities (NodeGetCapabilitiesRequest) returns (NodeGetCapabilitiesResponse) {} // 必须实现，返回运行插件的节点的信息 rpc NodeGetInfo (NodeGetInfoRequest) returns (NodeGetInfoResponse) {} } 某些部署架构下，也可由一个服务（可以是一个二进制文件）同时提供CSI Controller和CSI Node两组接口 ","date":"2023-12-01","objectID":"/post/:1:6","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"1.7 CSI部署架构 CSI规范的主要关注点是Kubernetes和卷插件之间的协议。Kubernetes应该同时支持中心化部署、headless部署的Plugin。几种可能的部署架构： 注：headless指Kubernetes中的一种服务的配置方式，它允许您直接访问服务中的各个Pod而不是通过一个集群IP来访问整个服务。headless服务实现上是为与服务关联的每个 Pod 创建 DNS 记录。然后，可以使用这些 DNS 记录直接对每个 Pod 进行寻址 插件运行在所有节点上，在Master上运行中心化的控制器，所有节点上运行Node Plugin： 注： CO即为容器编排系统（指Kubernetes），使用CSI的RPC接口和CSI插件交互 Headless部署，在所有节点上运行Plugin，Controller Plugin、Node Plugin分开部署： Headless部署，在所有节点上运行Plugin，Controller Plugin、Node Plugin合并部署： Headless部署，在所有节点上运行Plugin，只运行Node Plugin。GetPluginCapabilities调用不会报告CONTROLLER_SERVICE特性： ","date":"2023-12-01","objectID":"/post/:1:7","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"2 Kubernetes接入NFS存储方式及配置示例 直接使用nfs卷，k8s内置支持(提前部署nfs-server：10.1.33.53) apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 volumeMounts: - name: data mountPath: /usr/share/nginx/html volumes: - name: data nfs: path: /opt/nfs-deployment server: 10.1.33.53 将nfs创建为PV，并创建相应PVC，在容器中使用，静态绑定 # PV apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs spec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteMany nfs: path: /opt/nfs-deployment server: 172.26.204.144 --- # PVC kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-nfs spec: storageClassName: manual accessModes: - ReadWriteMany resources: requests: storage: 10Gi --- # 使用 apiVersion: apps/v1 kind: Deployment metadata: name: busybox labels: app: busybox spec: replicas: 1 selector: matchLabels: app: busybox template: metadata: labels: app: busybox spec: containers: - name: busybox image: busybox command: ['sh', '-c', 'echo \"Hello, Kubernetes!\" \u0026\u0026 sleep 3600'] volumeMounts: - name: data mountPath: /data volumes: - name: data persistentVolumeClaim: claimName: pvc-nfs K8S官方CSI插件，本身只提供了集群中的资源和NFS服务器之间的通信层，Driver直接使用官方的安装即可，使用如下 注：动态绑定需要注意权限问题，弄清楚是以什么账号权限访问的，配置读写权限是否具有读写权限 # 静态绑定 apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs-csi spec: capacity: storage: 10Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain mountOptions: - hard - nfsvers=4.1 csi: driver: nfs.csi.k8s.io readOnly: false volumeHandle: unique-volumeid # #确保它是集群中的唯一 ID volumeAttributes: server: 172.26.204.144 share: /opt/nfs-deployment --- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: pvc-nfs-csi-static spec: accessModes: - ReadWriteMany resources: requests: storage: 10Gi volumeName: pv-nfs-csi storageClassName: \"\" # 动态绑定 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: nfs-csi provisioner: nfs.csi.k8s.io parameters: server: 172.26.204.144 share: /opt/nfs-deployment reclaimPolicy: Delete volumeBindingMode: Immediate mountOptions: - hard - nfsvers=4.1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-nfs-csi-dynamic spec: accessModes: - ReadWriteMany resources: requests: storage: 10Gi storageClassName: nfs-csi ","date":"2023-12-01","objectID":"/post/:2:0","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["Kubernetes"],"content":"3 Reference https://github.com/container-storage-interface/spec/blob/master/spec.md https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.29/#api-overview https://kubernetes-csi.github.io/docs/introduction.html ","date":"2023-12-01","objectID":"/post/:3:0","tags":["存储","PV","PVC","CSI"],"title":"Kubernetes 存储实现原理及简单示例","uri":"/post/"},{"categories":["文件系统"],"content":"记录一次视频监控场景下对文件系统进行性能测试及简单调优的过程及思路，相关内容已脱敏 ","date":"2023-11-27","objectID":"/post/:0:0","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"1 性能分析方法 可通过日志和检测工具来监控基于fuse实现的用户态文件系统性能 以JuiceFS为例，它提供了访问日志和性能日志以及命令行工具监控文件系统性能，使用方式分别如下： $ cat /path/to/your/.accesslog $ cat /path/to/your/.perfmetric $ juicefs stats /path/to/your ","date":"2023-11-27","objectID":"/post/:1:0","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"2 性能分析思路 在视频监控场景下，文件为多路监源连续追加写入文件系统 假设网络无瓶颈，文件系统内所有存储介质写入速率一致，理想情况下最大带宽： 单节点：服务端从本地写入JuiceFS速度为该节点的最大写入速度 3节点：期望最大写入速度为单节点最大写入速度 * 3 测试得服务端单节点从本地写入JuiceFS速度如下： fiotest: (g=0):rw=write,bs=(R)16.0MiB-16.0MiB, (W) 16.0MiB-16.0MiB, (T) 16.0MiB-16.0MiB,ioengine=libaio, iodepth=1 fio-3.29 Starting 1 process fiotest: Laying out I0 file (1 file / 4096MiB) Jobs: 1 (f=1): [W(1)][100.0%][w=256MiB/s][w=16 IOPS][eta 00m:00s] fiotest: (groupid=0, jobs=1): err= 0: pid=528243: Sun Nov 26 02:26:37 2023 write: IOPS=16, BW=257MiB/s (269MB/s)(4096MiB/15937msec); 0 zone resets slat (usec): min=8557, max=18135, avg=9782.97, stdev=718.53 clat (nsec) : min=2590, max=19341, avg=6322.75, stdev=2224.38 lat (usec): min=8560, max=18145, avg=9791.82, stdev=719.24 clat percentiles (nsec): 1.00th=[ 2928]. 5.00th=[ 3376], 10.00th=[ 3856], 20.00th=[ 4448], 30.00th=[ 5152], 40.00th=[ 5728], 50.00th=[ 6176], 60.00th=[ 6624], 70.00th=[ 7264], 80.00th=[ 7776], 90.00th=[ 8512], 95.00th=[ 8896], 99.00th=[15936], 99.50th=[18560], 99.90th=[19328], 99.95th=[19328], 99.99th=[19328] bw ( KiB/s) : min=229376, max=294912, per=100.00%, avg=263201.03, stdev=15791.93, samples=31 iops: min= 14, max= 18, avg=16.06, stdev= 0.96, samples=31 lat (usec) : 4=11.33%, 10=85.16%, 20=3.52% fsync/fdatasync/sync_file_range: sync (nsec) : min=220, max=2550, avg=1182.90, stdev=474.05 sync percentiles (nsec): 1.00th[3301], 5.00th[410], 10.00th[524], 20.00th[700], 30.00th[900], 40.00th[1064], 50.00th[1176], 60.00th[1336], 70. 00th[1432], 80.00th[1608], 90.00th[1848], 95.00th[2008], 99.00th[2192], 99.50th[2352], 99.90th[2544], 99.95th[2544], 99.99th[2544] cpu usr=1.26%, sys=0.51%, ctx=4608, majf=0, minf=11 IO depths : 1=199.6%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, \u003e64=0.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u003e64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u003e64=0.0% issued rwts: total=0, 256, 0, 255 short=0, 0, 0, 0 dropped=0, 0, 0, 0 latency : target=0, window=0, percentile=100.00%, depth=1 Run status group 0 (all jobs): WRITE: bw=257MiB/s (269MB/s), 257MiB/s-257MiB/s (269MB/s-269MB/s), io=4096MiB (4295MB), run=15937-15937msec io路径分析 nfs → 通过前端网络 → JuiceFS → 通过后端网络 → 分布式持久层 → 磁盘 nfs向JuiceFS并发发送io请求，JuiceFS将收到的数据暂写入缓存，达到指定大小后写缓存分布式持久层，分布式持久层返回后该次落盘操作才算成功 因此上述过程中存在2个时延，第一个时延为JuiceFS等待io请求，直到io请求达到指定大小；第二个时延为JuiceFS等待分布式持久层返回 理论上这两个时延时间一致且周期一致，性能最优 ","date":"2023-11-27","objectID":"/post/:2:0","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"3 性能分析环境配置及操作 ","date":"2023-11-27","objectID":"/post/:3:0","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"3.1 测试环境 服务端配置：曙光Rack/R6440H0 * 3; 2U 32Core; RAM 128G 网络：fio和mdtest测试：3服务端，1客户端，均组bond6_front，网络最大带宽20G/s ","date":"2023-11-27","objectID":"/post/:3:1","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"3.2 测试配置 首先JuiceFS在块大小 \u003e= 16m时会直接将数据写对象，因此测试块大小16M的文件写入时需要调大写对象块大小上限，同时打开文件元数据缓存和目录项缓存超时时间来提高连续写入效率 需修改的配置 juicefs: cacheDir: /var/powercache uploadDelay: 10m trashDays: 0 logDir: \"/var/log/juicefs\" xxxClientPackagePath: \"/opt/xxx/xxx_client.tar\" xxxClientPort: 33999 backupMeta: 24h attr-cache: 1 # 修改项 entry-cache: 1 # 修改项 dir-entry-cache: 1 # 修改项 namespaceRootDir: \"/xxx\" disable-lock: false cache-type: free-ratio-raw: 0.15 free-ratio-staging: 0.10 extendedParams : \"--upload-block-size 32 max-uploads 32 --flush-by-no-write 100\" # 修改项 bucketName: xxx-03e89688 测试前准备 在服务端view上共享1个NFS文件夹nfstest 在客户端挂载该目录: mount -t nfs -o vers=3 业务网:/xxx/nfstest /mnt/nfstest 在客户端执行fio和mdtest进行测试 ","date":"2023-11-27","objectID":"/post/:3:2","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"3.3 测试操作 执行cp复制3.5G文件结果 [root@node1]# time cp openEuler-22.03-LTS-SP1-x86_64-dvd.iso /mnt/nfstest/testos real 0m8.210s user 0m0.000s sys 0m2.236s [root@node1]# ls -1lh openEuler-22.03-LTS-SP1-x86_64-dvd.iso root root 3.5G Nov 25 09:58 openEuler-22.03-LTS-SP1-x86_64-dvd.iso 执行2个fio测试，参数及结果如下 (1)4K随机写入: fio -directory=/mnt/nfstest/test1 -ioengine=libaio -iodepth=1 -direct=1 -fsync=1 -bs=4K -flesize=8M --rw=write -numjobs=56 -name=fiotest -group_reporting -output=4k_randw.data 结果： fiotest: (groupid=0, jobs=56): err= 0: pid=1668325: Sat Nov 25 16:48:17 2023 write: I0PS=2444, BW=9778KiB/s (10.0MB/s)(448MiB/46919msec); 0 zone resets slat (nsec): min=1551, max=q7180, avg=3033.72, stdev=2019.74 clat (msec): min=6, max=438, avg=21.69, stdev=22.42 Lat (msec): min=6, max=438, avg=21.70, stdev=22.42 clat percentiles (msec): 1 1.00th=[q], 5.00th=[11], 10.00th=[12], 20.00th=[13], 30.00th=[15], 40.00th=[16], 50.00th=[18], 60.00th=[20], 70.00th=[22], 80.00th=[25], 90.00th=[34], 95.00th=[42], 99.00th=[79], 99.50th=[220], 99.90th=[239], 99.95th=[251], 99.99th=[430] bw ( KiB/s): min= 1752, max=19184, per=100.00%, avg=10366.19, stdev=53.86, samples=4947 iops : min= 438, max= 4796, avg=2591.49, stdev=13.46, samples=4947 lat (msec) : 10=4.31%，20=60.64%，50=32.90%，100=1.18%，250=0.90% lat (msec) : 500=0.05% fsync/fdatasync/sync_file_range: sync (nsec): min=16, max=4702, avg=40.81, stdev=30.54 sync percentiles (nsec): 1.00th=[22]， 5.00th=[23], 10.00th=[26], 20.00th=[32], 30.00th=[33], 40.00th=[34], 50.00th=[34], 60.00th=[39] 70.00th=[43],80.00th=[47], 90.00th=[54], 95.00th=[64], 99.00th=[145], 99.50th=[151], 99.90th=[193]，99.95th=[338], 99.99th=[532] cpu : usr=0.01%, sys=0.03%, ctx=114944, majf=0, minf=56 I0 depths : 1=200.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, \u003e=64=0.0% submit : 0=0.0%， 4=100.0%， 8=0.0%， 16=0.0%， 32=0.0%， 64=0.0%， \u003e=64=0.0% complete : 0=0.0%， 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u003e=64=0.0% issued rwts: total=0,114688,0,114632 short=0,0,0,0 dropped=0,0,0,0 Latency : target=0, window=0, percentile=100.00%, depth=1 Run status group 0 (all jobs): WRITE: bw=9778KiB/s (10.0MB/s), 9778KiB/s-9778KiB/s (10.0MB/s-10.0MB/s), io=448MiB (470MB), run=46919-46919msec (2)16M大文件连续写入： fio -directory=/mnt/nfstest/test2 -ioengine=libaio -iodepth=1 -direct=1 -fsync=1 -bs=16M -filesize=1G --rw=write -numjobs=16 -name=fiotest -group_reporting -output=16_w.data 结果 fiotest2: (groupid=0, jobs=16): err= 0: pid=166q561: Sat Nov 25 16:49:02 2023 write: I0PS=38, BW=608MiB/s (638MB/s)(16.0GiB/26934msec); 0 zone resets slat (usec): min=1144, max=3439, avg=1612.21, stdev=208.03 clat (msec): min=142, max=643, avg=414.0q, stdev=41.20 lat (msec): min=144, max=644, avg=415.70, stdev=41.15 clat percentiles (msec): 1.00th=[284]， 5.00th=[355], 10.00th=[368], 20.00th=[384], 30.00th=[397], 40.00th=[409], 50.00th=[418], 60.00th=[426], 70.00th=[439], 80.00th=[447], 90.00th=[460], 95.00th=[468], 99.00th=[489], 99.50th=[502], 99.90th=[542], 99.95th=[642], 99.99th=[642] bw ( KiB/s): min=523436, max=1048576, per=100.00%, avg=624827.94, stdev=12902.57, samples=845 iops: min=25，max=64, avg=38.00, stdev=0.80, samples=845 lat (msec) : 250=0.68%，500=98.83%, 750=0.49% fsync/fdatasync/sync_file_range: sync (nsec): min=16, max=604, avg=159.23, stdev=85.32 sync percentiles (nsec): 1.00th=[35]， 5.00th=[56], 10.00th=[70], 20.00th=[129] , 30.00th=[139], 40.00th=[147], 50.00th=[151], 60.00th=[157] , 70.00th=[161], 80.00th=[169], 90.00th=[191], 95.00th=[342], 99.00th=[540], 99.50th=[580], 99.90th=[604], 99.95th=[604], 99.99th=[604] cpu usr=0.17%, sys=0.21%, ctx=1082, majf=0, minf=16 I0 depths : 1=198.4%， 2=0.0%， 4=0.0%， 8=0.0%， 16=0.0%， 32=0.0%， \u003e=64=0.0% submit ： 0=0.0%， 4=100.0%， 8=0.0%， 16=0.0%， 32=0.0%， 64=0.0%， \u003e=64=0.0% complete : 0=0.0%， 4=100.0%， 8=0.0%， 16=0.0%， 32=0.0%， 64=0.0%， \u003e=64=0.0% issued rwts: total=0,1024,0,1008 short=0,0,0,0 dropped=0,0,0,0 Latency : target=0, window=0, percentile=100.00%, depth=1 Run status group 0 (all jobs): WRITE: bw=608MiB/s (638MB/s), 608M","date":"2023-11-27","objectID":"/post/:3:3","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"4 测试中产生的部分数据 iostat - 每块磁盘IO情况 mpstat - 系统CPU资源占用情况 juicefs stat - JuiceFS实时性能指标 juicefs .perfmetric - JuiceFS单位时间内IO情况 juicefs .accesslog - JuiceFS访问日志 具体数据略 ","date":"2023-11-27","objectID":"/post/:4:0","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["文件系统"],"content":"5 测试结果分析 观察到2个问题 从perfmetric看出，每次JuiceFS写分布式持久层大小(write_cache)不均，理论应该是统一大小 从accesslog看出，刷新时间不均衡，连续写文件理论上间隔应该统一 针对问题1，推测可能是NFS问题，尝试在服务器本地写JuiceFS，观察perfmetric日志，发现写入大小一致，证明推测成立，是NFS客户端单位时间内发出的IO大小不一致导致 针对问题2，推测有其他机制触发刷新，将强制刷新时间更改为100s，再次写入数据查看accesslog，发现还是有不均匀的刷新，支持推测成立 ","date":"2023-11-27","objectID":"/post/:5:0","tags":["JuiceFS","性能"],"title":"记一次文件系统性能测试","uri":"/post/"},{"categories":["存储"],"content":"本文的目标是以一篇文章的篇幅，介绍存储领域的各种概念以及他们是用来解决什么需求的 这次聊一聊存储相关的概念，就是计算机基础架构中的三个主要领域计算、存储和网络中的存储 存储架构 jbod san nas 数据冗余技术 ecc纠删码 多副本 SDS 存储方式 分布式存储类型 对象存储，块存储，文件存储 集中式存储，分布式存储https://www.zhihu.com/question/343713625 存储介质 存储介质 ssd hdd scm 硬件支持技术 nvme-of fiber iSCSI RDMA SPDK 存储访问协议 网络文件系统及接口 NFS CIFS SMB HDFS Lustre POSIX 存储访问协议 Amazon S3协议 https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html Linux文件系统 Linux文件系统类型 磁盘文件系统 内存文件系统 网络文件系统 存储系统监控和管理 存储系统监控和管理 典型存储项目 存储项目 minIO Ceph daos JuiceFS 从一个通常的具有计算机使用经验的人展开，存储方式，存储介质，文件系统，访问协议sds ","date":"2023-09-15","objectID":"/post/:0:0","tags":["存储架构","存储介质","存储访问协议","文件系统"],"title":"存储领域的概念","uri":"/post/"},{"categories":["Golang"],"content":"一 Golang错误处理机制panic和recover简要介绍 使用panic抛出异常后, 将立即停止当前函数的执行并运行所有被defer的函数，然后将panic抛向上一层，直至程序crash。但是也可以使用被defer的recover函数来捕获异常阻止程序的崩溃，recover只有被defer后才是有意义的 使用示例： func main() { print(123) defer func() { if err := recover(); err != nil { print(\"recover it\") } }() print(456) panic(\"throw an error\") print(678) //IDE会有提示: Unreachable code } 输出结果为： 123456recover it 如果有两个recover，则捕获异常的是后一个（defer遵循栈规划，即后定义的优先触发） panic之后的任何代码都不会继续执行，前提是panic不在if里面 使用panic抛出异常后, 将立即停止当前函数的执行并运行所有被defer的函数，然后将panic抛向上一层，直至程序crash，但是也可以使用被defer的recover函数来捕获异常阻止程序的崩溃，recover只有被defer后才是有意义的 对于goroutine中的panic，协程外面的recover是无法恢复的；goroutine中的recover，同样无法恢复协程外的panic；但协程中的recover可以恢复协程中的panic 主方法中的recover，也可以恢复子方法里的panic 因为panic发生的时候，panic函数后面的语句都不会执行了，所以recover函数不能放在panic语句后面执行，而要放在defer函数中执行 使用 panic 抛出异常后，函数执行将从调用 panic 的地方停止，如果函数内有 defer 调用，则执行 defer 后边的函数调用，如果 defer 调用的函数中没有捕获异常信息，这个异常会沿着函数调用栈往上传递，直到 main 函数仍然没有捕获异常，将会导致程序异常退出 recover不能捕获所有错误，以下是不能捕获的情形 堆栈内存耗尽(如递归) 并发读写 map fatal error: concurrent map read and map write 将 nil 函数作为 goroutine 启动 fatal error: go of nil func value goroutines 死锁 fatal error: all goroutines are asleep - deadlock! 线程超过设置的最大限制 fatal error: thread exhaustion 超出可用内存 fatal error: runtime: out of memory ","date":"2023-06-21","objectID":"/posts/:1:0","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"二 推荐使用场景 ","date":"2023-06-21","objectID":"/posts/:2:0","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"panic 在程序启动的时候，如果有强依赖的服务出现故障时 panic 退出 在程序启动的时候，如果发现有配置明显不符合要求， 可以 panic 退出（防御编程） 其他情况下只要不是不可恢复的程序错误，都不应该直接 panic 应该返回 error 在程序入口处，例如 gin 中间件需要使用 recover 预防 panic 程序退出 在程序中应该避免使用野生的 goroutine 如果是在请求中需要执行异步任务，应该使用异步 worker ，消息通知的方式进行处理，避免请求量大时大量 goroutine 创建 如果需要使用 goroutine 时，应该使用同一的 Go 函数进行创建，这个函数中会进行 recover ，避免因为野生 goroutine panic 导致主进程退出 func Go(f func()){ go func(){ defer func(){ if err := recover(); err != nil { log.Printf(\"panic: %+v\", err) } }() f() }() } ","date":"2023-06-21","objectID":"/posts/:2:1","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"error 在应用程序中使用 github.com/pkg/errors 处理应用错误，注意在公共库当中，一般不使用这个 error 应该是函数的最后一个返回值，当 error 不为 nil 时，函数的其他返回值是不可用的状态，不应该对其他返回值做任何期待 func f() (io.Reader, *S1, error) 在这里，不知道 io.Reader 中是否有数据，可能有，也有可能有一部分 错误处理的时候应该先判断错误， if err != nil 出现错误及时返回，使代码是一条流畅的直线，避免过多的嵌套 // good case func f() error { a, err := A() if err != nil { return err } // ... 其他逻辑 return nil } // bad case func f() error { a, err := A() if err == nil { // 其他逻辑 } return err } 在应用程序中出现错误时，使用 errors.New 或者 errors.Errorf 返回错误 func (u *usecese) usecase1() error { money := u.repo.getMoney(uid) if money \u003c 10 { errors.Errorf(\"用户余额不足, uid: %d, money: %d\", uid, money) } // 其他逻辑 return nil } 如果是调用应用程序的其他函数出现错误，请直接返回，如果需要携带信息，请使用 errors.WithMessage func (u *usecese) usecase2() error { name, err := u.repo.getUserName(uid) if err != nil { return errors.WithMessage(err, \"其他附加信息\") } // 其他逻辑 return nil } 如果是调用其他库（标准库、企业公共库、开源第三方库等）获取到错误时，请使用 errors.Wrap 添加堆栈信息 切记，不要每个地方都是用 errors.Wrap 只需要在错误第一次出现时进行 errors.Wrap 即可 根据场景进行判断是否需要将其他库的原始错误吞掉，例如可以把 repository 层的数据库相关错误吞掉，返回业务错误码，避免后续分割微服务或者更换 ORM 库时需要去修改上层代码 注意在基础库，被大量引入的第三方库编写时一般不使用 errors.Wrap 避免堆栈信息重复 func f() error { err := json.Unmashal(\u0026a, data) if err != nil { return errors.Wrap(err, \"其他附加信息\") } // 其他逻辑 return nil } 禁止每个出错的地方都打日志，只需要在进程的最开始的地方使用 %+v 进行统一打印，例如 http/rpc 服务的中间件 错误判断使用 errors.Is 进行比较 func f() error { err := A() if errors.Is(err, io.EOF){ return nil } // 其他逻辑 return nil } 错误类型判断，使用 errors.As 进行赋值 func f() error { err := A() var errA errorA if errors.As(err, \u0026errA){ // ... } // 其他逻辑 return nil } 如何判定错误的信息是否足够，想一想当你的代码出现问题需要排查的时候你的错误信息是否可以帮助你快速的定位问题，例如在请求中一般会输出参数信息，用于辅助判断错误 对于业务错误，推荐在一个统一的地方创建一个错误字典，错误字典里面应该包含错误的 code，并且在日志中作为独立字段打印，方便做业务告警的判断，错误必须有清晰的错误文档 不需要返回，被忽略的错误必须输出日志信息 同一个地方不停的报错，最好不要不停输出错误日志，这样可能会导致被大量的错误日志信息淹没，无法排查问题，比较好的做法是打印一次错误详情，然后打印出错误出现的次数 对同一个类型的错误，采用相同的模式，例如参数错误，不要有的返回 404 有的返回 200 处理错误的时候，需要处理已分配的资源，使用 defer 进行清理，例如文件句柄 ","date":"2023-06-21","objectID":"/posts/:2:2","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"何时使用panic，何时使用error 在 Go 中 panic 会导致程序直接退出，是一个致命的错误，如果使用 panic recover 进行处理的话，会存在很多问题 性能问题，频繁 panic recover 性能不好 容易导致程序异常退出，只要有一个地方没有处理到就会导致程序进程整个退出 不可控，一旦 panic 就将处理逻辑移交给了外部，我们并不能预设外部包一定会进行处理 什么时候使用 panic 呢？ 对于真正意外的情况，那些表示不可恢复的程序错误，例如索引越界、不可恢复的环境问题、栈溢出，才使用 panic 使用 error 处理有哪些好处？ 简单 考虑失败，而不是成功(Plan for failure, not success) 没有隐藏的控制流 完全交给你来控制 error Error are values ","date":"2023-06-21","objectID":"/posts/:2:3","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"返回错误时的抉择 这是一个不需要额外信息的简单错误吗？如果是，errors.New即可 客户需要检测并处理此错误吗？如果是，则应该使用自定义类型并实现该Error()方法，可添加更多信息 是否正在传播下游函数返回的错误而且需要添加上下文信息？如果是，则应该包装此错误 否则fmt.Errorf就可以 如果要将错误发送到另一个系统，就应该明确是错误消息及来源 ","date":"2023-06-21","objectID":"/posts/:2:4","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"三 Q \u0026 A ","date":"2023-06-21","objectID":"/posts/:3:0","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"1. 为什么标准库中 errors.New 会返回一个指针？ 翻看标准库的源代码可以发现， errors 库中的 errorString 结构体实现了 error 接口，为什么在 New 一个 error 的时候会返回一个结构体的指针呢？ // New returns an error that formats as the given text. // Each call to New returns a distinct error value even if the text is identical. func New(text string) error { return \u0026errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 先来看一个例子，同样创建了 errorString 的结构体，自定义的和标准库中的唯一不同就是，自建的这个返回的是值，而不是指针。 在 main 函数的对比中就可以发现，自定义的 errorString 在对比的时候只要对应的字符串相同就会返回 true，但是标准库的包不会。 这是因为，在对比两个 struct 是否相同的时候，会去对比，这两个 struct 里面的各个字段是否是相同的，如果相同就返回 true，但是对比指针的时候会去判断两个指针的地址是否一致。 ","date":"2023-06-21","objectID":"/posts/:3:1","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"2. 如果字符串相等就返回 true 会导致什么问题呢？ 如果有两个包，定义了两个错误，他们其实是两个相同的字符串，在其他库调用对比的时候，可能会由于不同的书写顺序，走进不同的分支导致一些奇奇怪怪的错误 type errorString struct { text string } func (e errorString) Error() string { return e.text } // New 创建一个自定义错误 func New(s string) error { return errorString{text: s} } var errorString1 = New(\"test a\") var err1 = errors.New(\"test b\") func main() { if errorString1 == New(\"test a\") { fmt.Println(\"err string a\") // 会输出 } if err1 == errors.New(\"test b\") { fmt.Println(\"err b\") // 不会输出 } } ","date":"2023-06-21","objectID":"/posts/:3:2","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"3. error type: 错误定义与判断 Sentinel Error 哨兵错误，就是定义一些包级别的错误变量，然后在调用的时候外部包可以直接对比变量进行判定，在标准库当中大量的使用了这种方式 例如下方 io 库中定义的错误 // EOF is the error returned by Read when no more input is available. // Functions should return EOF only to signal a graceful end of input. // If the EOF occurs unexpectedly in a structured data stream, // the appropriate error is either ErrUnexpectedEOF or some other error // giving more detail. var EOF = errors.New(\"EOF\") // ErrUnexpectedEOF means that EOF was encountered in the // middle of reading a fixed-size block or data structure. var ErrUnexpectedEOF = errors.New(\"unexpected EOF\") // ErrNoProgress is returned by some clients of an io.Reader when // many calls to Read have failed to return any data or error, // usually the sign of a broken io.Reader implementation. var ErrNoProgress = errors.New(\"multiple Read calls return no data or error\") 在外部判定的时候一般使用等值判定或者使用 errors.Is 进行判断 if err == io.EOF { //... } if errors.Is(err, io.EOF){ //... } 这种错误处理方式有一个问题是，将 error 当做包的 API 暴露给了第三方，这样会导致在做重构或者升级的时候很麻烦，并且这种方式包含的错误信息会十分的有限 error types 这个就类似前面定义的 errorString 一样实现了 error 的接口，然后在外部是否类型断言来判断是否是这种错误类型 type MyStruct struct { s string name string path string } // 使用的时候 func f() { switch err.(type) { case *MyStruct: // ... case others: // ... } } 这种方式相对于哨兵来说，可以包含更加丰富的信息，但是同样也将错误的类型暴露给了外部，例如标准库中的 os.PathError Opaque errors 不透明的错误处理，这种方式最大的特点就是只返回错误，暴露错误判定接口，不返回类型，这样可以减少 API 的暴露，后续的处理会比较灵活，这个一般用在公共库会比较好 type temporary interface { Temporary() bool } func IsTemporary(err error) bool { te, ok := err.(temporary) return ok \u0026\u0026 te.Temporary() } 这种方式可以断言错误实现了特定的行为，而不是断言错误是特定的类型或值 ","date":"2023-06-21","objectID":"/posts/:3:3","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"4. error handle: 错误处理优化 在 go 中常常会存在大量的 if err 代码，下面介绍两种常见的减少这种代码的方式 bufio.scan 对比下面两个函数的处理可以发现， count2 使用 sc.Scan 之后一个 if err 的判断都没有，极大的简化了代码，这是因为在 sc.Scan 做了很多处理，像很多类似的，需要循环读取的都可以考虑像这样包装之后进行处理，这样外部包调用的时候就会非常简洁 // 统计文件行数 func count(r io.Reader) (int, error) { var ( br = bufio.NewReader(r) lines int err error ) for { // 读取到换行符就说明是一行 _, err = br.ReadString('\\n') lines++ if err != nil { break } } // 当错误是 EOF 的时候说明文件读取完毕了 if err != io.EOF { return 0, err } return lines, err } func count2(r io.Reader) (int, error) { var ( sc = bufio.NewScanner(r) lines int ) for sc.Scan() { lines++ } return lines, sc.Err() } error writer 看一个来自 go blog 的例子：https://blog.golang.org/errors-are-values 一般代码 _, err = fd.Write(p0[a:b]) if err != nil { return err } _, err = fd.Write(p1[c:d]) if err != nil { return err } _, err = fd.Write(p2[e:f]) if err != nil { return err } // and so on errWriter type errWriter struct { w io.Writer err error } func (ew *errWriter) write(buf []byte) { if ew.err != nil { return } _, ew.err = ew.w.Write(buf) } // 使用时 ew := \u0026errWriter{w: fd} ew.write(p0[a:b]) ew.write(p1[c:d]) ew.write(p2[e:f]) // and so on if ew.err != nil { return ew.err } 如果去翻 标准库中 bufio.Writer 的源代码，你会发现也有这种用法，这种就是将重复的逻辑进行了封装，然后把 error 暂存，然后就只需要在最后判断一下 error 就行了 ","date":"2023-06-21","objectID":"/posts/:3:4","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"5. wrap error: 错误包装 errors.wrap 有何作用，为什么不用标准库的 fmt.Errorf(\"%w\") 先看一下标准库的源码，我们可以发现当 p.wrappedErr != nil 的时候（也就是有 %w）的时候，会使用一个 wrapError 将错误包装，看 wrapError 的源码可以发现，这个方法只是包装了一下原始错误，并且可以做到附加一些文本信息，但是没有堆栈信息 func Errorf(format string, a ...interface{}) error { p := newPrinter() p.wrapErrs = true p.doPrintf(format, a) s := string(p.buf) var err error if p.wrappedErr == nil { err = errors.New(s) } else { err = \u0026wrapError{s, p.wrappedErr} } p.free() return err } type wrapError struct { msg string err error } func (e *wrapError) Error() string { return e.msg } func (e *wrapError) Unwrap() error { return e.err } 在看一下 pkg/errors 的源码，我肯可以发现除了使用 withMessage 附加了错误信息之外还使用 withStack 附加了堆栈信息，这样在程序入口处打印日志信息的时候就可以将堆栈信息一并打出了 // Wrap returns an error annotating err with a stack trace // at the point Wrap is called, and the supplied message. // If err is nil, Wrap returns nil. func Wrap(err error, message string) error { if err == nil { return nil } err = \u0026withMessage{ cause: err, msg: message, } return \u0026withStack{ err, callers(), } } ","date":"2023-06-21","objectID":"/posts/:3:5","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"6. 为什么不允许处处使用 errors.Wrap 因为每一次 errors.Wrap的调用都会为错误添加堆栈信息，如果处处调用那会有大量的无用堆栈 先看一下只有一处 wrap func main() { fmt.Printf(\"err: %+v\", c()) } func a() error { return errors.Wrap(fmt.Errorf(\"xxx\"), \"test\") } func b() error { return a() } func c() error { return b() } 看结果可以发现已经可以打印出全部的堆栈信息了 err: xxx test main.a /home/ll/project/Go-000/Week02/blog/wrap.go:14 main.b /home/ll/project/Go-000/Week02/blog/wrap.go:18 main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 再看多处 wrap 的现象 func main() { fmt.Printf(\"err: %+v\", c()) } func a() error { return errors.Wrap(fmt.Errorf(\"xxx\"), \"a\") } func b() error { return errors.Wrap(a(), \"b\") } func c() error { return errors.Wrap(b(), \"c\") } 可以看到每一处 wrap 都添加了一次堆栈信息 err: xxx a main.a /home/ll/project/Go-000/Week02/blog/wrap.go:14 main.b /home/ll/project/Go-000/Week02/blog/wrap.go:18 main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 b main.b /home/ll/project/Go-000/Week02/blog/wrap.go:18 main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 c main.c /home/ll/project/Go-000/Week02/blog/wrap.go:22 main.main /home/ll/project/Go-000/Week02/blog/wrap.go:10 runtime.main /usr/local/go/src/runtime/proc.go:204 runtime.goexit /usr/local/go/src/runtime/asm_amd64.s:1374 ","date":"2023-06-21","objectID":"/posts/:3:6","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["Golang"],"content":"7. 标准库 errors.Is / As 怎么判断错误 errors.Is func Is(err, target error) bool { if target == nil { return err == target } // 通过反射判读 target 是否可以被比较 isComparable := reflectlite.TypeOf(target).Comparable() for { // 循环判断是否相等 if isComparable \u0026\u0026 err == target { return true } // 判断是否实现了 is 接口，如果有实现就直接判断 if x, ok := err.(interface{ Is(error) bool }); ok \u0026\u0026 x.Is(target) { return true } // 去判断是否实现了 unwrap 的接口，如果实现了就进行 unwrap if err = Unwrap(err); err == nil { return false } } } errors.As 和 is 的逻辑类似，就是不断的进行 unwrap 进行比较，只要有一个相同就返回，如果一直到底都不行就返回 false func As(err error, target interface{}) bool { if target == nil { panic(\"errors: target cannot be nil\") } val := reflectlite.ValueOf(target) typ := val.Type() if typ.Kind() != reflectlite.Ptr || val.IsNil() { panic(\"errors: target must be a non-nil pointer\") } if e := typ.Elem(); e.Kind() != reflectlite.Interface \u0026\u0026 !e.Implements(errorType) { panic(\"errors: *target must be interface or implement error\") } targetType := typ.Elem() for err != nil { if reflectlite.TypeOf(err).AssignableTo(targetType) { val.Elem().Set(reflectlite.ValueOf(err)) return true } if x, ok := err.(interface{ As(interface{}) bool }); ok \u0026\u0026 x.As(target) { return true } err = Unwrap(err) } return false } ","date":"2023-06-21","objectID":"/posts/:3:7","tags":["错误处理","Golang","最佳实践"],"title":"Go错误处理最佳实践","uri":"/posts/"},{"categories":["云原生"],"content":"云原生漫谈 云原生的5w1h，what，why，where，how，who when -\u003e anytime 云原生概念(定义、优势、总结); 云原生技术领域介绍：容器-\u003e容器编排-\u003e服务治理(简要介绍代表技术Docker、Kubernetes、Istio和Linkerd)、微服务架构 \u0026 Serverless架构、DevOps \u0026 可观测性; Kubernetes简介(如何满足12-Factor)、架构及开发方式; 应用的现代化改造思路; 云原生时代下的团队(对新出现一些岗位和名词的解释); CNCF(简介、对cncf landscape的介绍); 概念 What 定义 Martin Fowler - 课程获取 云原生描述了一种高效组织的模式，可以快速地、一致地、可靠地、规模化地交付软件 持续交付、DevOps 和微服务指明了为什么，怎么样，和什么是云原生 CNCF定义： 云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。 Pivotal 公司的 Matt Stine，2015，对于云原生的定义：12-Factor；面向微服务架构；自服务敏捷架构；基于API的协作；扛脆弱性 云原生12因素（12-Factor） 基准代码：一份基准代码，多份部署。基准代码和应用之间总是保持一一对应的关系。所有部署的基准代码相同，但是每份部署可以使用其不同的版本。 依赖：显式声明依赖关系。应用程序一定通过依赖清单，确切地声明所有依赖项。 配置：在环境中存储配置。将应用的配置存储于环境变量中。环境变量可以非常方便地在不同的部署间做修改，却不动一行代码。 后端服务：把后端服务当做附加资源。应用不会区别对待本地或第三方服务。对应用程序而言，两种都是附加资源。 构建、发布、运行：严格地区分构建，发布，运行这三个步骤。 进程：以一个或多个无状态进程运行应用。应用的进程必须无状态且无共享。 端口绑定：通过端口绑定提供服务。应用完全自我加载而不依赖任何网络服务器就可以创建一个面向网络的服务。 并发：通过进程模型进行扩展。开发人员可以运用这个模型去设计应用架构，将不同工作分配给不同的进程类型。 易处理：快速启动和优雅终止可最大化健壮性。应用的进程是可支配的，意思是说它们可以瞬间开启或停止。 开发环境与线上环境等价：尽可能保持开发、预发布、线上环境相同。应用想要做到持续部署就必须缩小本地与线上差异。 日志：把日志当做事件流。应用本身考虑存储自己的输出流。不应该试图去写或者管理日志文件。 管理进程：后台管理任务当做一次性进程运行。一次性管理进程应该和正常的常驻进程使用同样的环境。 总结 理念 -\u003e 特征 -\u003e 技术体系(包括云原生架构、云原生服务等https://www.oracle.com/hk/cloud/cloud-native/what-is-cloud-native/) 优势 why 发展历程 从docker，参考书 新时代互联网巨头成功的秘诀 - 又快又好 创新速度 随时随地可用的服务 从 0 到 1，快速拓展 以移动设备为中心的用户体验 - 移动为王 云原生应用程序或原生云应用程序 (NCA) 是为云计算架构设计的程序。他们有很多好处。 **独立性：**他们的架构使得构建彼此独立的云原生应用程序成为可能。这意味着您还可以单独管理和部署它们。 **弹性：**即使在基础设施中断的情况下，精心设计的云原生应用程序也能够生存并保持在线。 **基于标准：**为了互操作性和工作负载可移植性，云原生服务通常基于开源和基于标准的技术。这有助于减少供应商锁定并提高可移植性。 **业务敏捷性：**云原生应用程序支持跨网络的灵活部署选项，并且比传统应用程序更小，这使得它们更易于开发、部署和迭代。 **自动化：**云原生应用程序使用 DevOps 自动化功能，并支持持续交付和部署定期发布的软件更改。此外，开发人员可以使用蓝绿和金丝雀部署等方法来改进应用程序，而不会影响用户体验。 **无停机时间：**借助 Kubernetes 等容器编排器，您可以部署软件更新，停机时间基本为零。 最终要解决的问题 软件开发的本质困难 - 研究生课程资料 复杂性，不可见性，可变性，一致性 软件工程的一切 架构 协作模式 软件过程etc… 都是为了解决这些问题 云原生技术领域 where 容器 -\u003e 容器编排 -\u003e 服务治理 ","date":"2022-09-20","objectID":"/post/:0:0","tags":["云原生概念","云原生技术","云原生应用","CNCF"],"title":"云原生的5W1H","uri":"/post/"},{"categories":["云原生"],"content":"Docker ","date":"2022-09-20","objectID":"/post/:0:1","tags":["云原生概念","云原生技术","云原生应用","CNCF"],"title":"云原生的5W1H","uri":"/post/"},{"categories":["云原生"],"content":"Kubernetes ","date":"2022-09-20","objectID":"/post/:0:2","tags":["云原生概念","云原生技术","云原生应用","CNCF"],"title":"云原生的5W1H","uri":"/post/"},{"categories":["云原生"],"content":"Istio？linkerd？ 微服务架构 \u0026 Serverless架构 DevOps \u0026 可观测性 DevOps工具链 !https://cdn.nlark.com/yuque/0/2021/png/1386879/1621972375535-ea44572d-afd5-47f7-a816-1ef0d053bc23.png?x-oss-process=image%2Fresize%2Cw_1507%2Climit_0 !https://cdn.nlark.com/yuque/0/2022/webp/1386879/1663579034683-2a95b897-da39-458c-bb0b-e6ab3f5d0955.webp?x-oss-process=image%2Fresize%2Cw_843%2Climit_0 CI/CD Kubernetes 简介 如何满足12-Factor，为什么是云原生核心 架构 开发方式 什么是Kubernetes原生应用 sidecar模式 发布模式 应用的现代化改造 How 将单体应用改造成云原生应用 容器化 -\u003e 了解容器编排引擎工作原理 -\u003e 了解分布式系统的模式 -\u003e 应用服务网格 -\u003e 使用无服务器架构 -\u003e 代码优化，将短任务改造成函数 刀砍模式 一刀一刀砍去巨石应用。具体来说就是通过微服务架构来实现新的服务，然后逐步替换掉老应用中的部分组件功能。可以采用网关或者外观层来将用户请求导向正确的应用。随着时间的推移，越来越多的功能被转移到新架构下，知道整个巨石应用崩塌瓦解，完全转换为一个微服务架构下的应用。 防损层模式 与刀砍模式类似，区别在于新服务需要调用老服务。通过建立防损层可以使新服务访问老服务，反过来老服务也可以调用新服务。 云原生时代下的团队 who 岗位 开发？ 运维？ 运维开发？ SRE？ 云原生工程师？ Kubernetes开发工程师？ 容器工程师？ 基础架构研发工程师？ 云原生操作系统？ CNCF 云原生生态介绍 CNCF 成立于 2015 年，旨在应对大量采用云原生系统的组织和服务。CNCF 是由 Linux 基金会创建的项目，是一个开源软件基金会，旨在促进云原生技术的采用。CNCF 拥有超过 400 名成员，包括公共云提供商、企业软件公司和技术初创公司。微软、甲骨文、VMware、英特尔是 CNCF 的一些白金会员。 CNCF 的存在是为了确保云原生技术可访问、可用且可靠。它培育了一个致力于 Kubernetes、Prometheus 和 CoreDNS 等项目的社区，同时支持构建可持续环境的组织，这些环境在微服务架构中编排容器。 landscape介绍 https://landscape.cncf.io/ 组合一个典型的云原生架构 如何评估云原生能力 CMMI 云原生的未来 参考资料 \u0026 推荐阅读 https://www.infoq.cn/article/Fl9i3xgdklYR9xO5ryDc?source=app_share 云原生： 深入剖析Kubernetes 云原生.Boris Scholl 等.2020 Design Patterns for container-based distributed systems.Brendan Burns 容器设计模式 云原生应用设计模式https://xie.infoq.cn/article/3c64971c8aa06fec5e00b463b https://ost.51cto.com/posts/13985 DevOps： 凤凰项目 DevOps实践指南 微服务： 微服务设计模式 Martin Fowler Microservices https://martinfowler.com/articles/microservices.html 企业IT架构转型之道：阿里巴巴中台战略思想与架构实战 ","date":"2022-09-20","objectID":"/post/:0:3","tags":["云原生概念","云原生技术","云原生应用","CNCF"],"title":"云原生的5W1H","uri":"/post/"},{"categories":["软件工程"],"content":"——在CMMI中引入敏捷 ","date":"2021-04-12","objectID":"/post/:0:0","tags":["软件工程管理","软件过程改进"],"title":"简述软件过程改进","uri":"/post/"},{"categories":["软件工程"],"content":"1 CMMI概述 80年代早期，在SEI的资助下美国空军成立了一项研究来分析为什么许多软件合同都会超出工期和预算。由此得出的结论是：糟糕的过程。CMM\u0026CMMI也因此产生。CMMI的中文名称是能力成熟度模型，是一个过程改进方法和模型，它为组织提供了实现高效的软件交付过程所必需的基本元素，关注通过切实改进过程域的成熟度，实现过程改进的目标。它可以用来指导一个项目、一个部门甚至整个组织的过程改进。CMMI能帮助我们整合以往各自为政的组织功能，建立过程改进的目标与优先级，指导我们进行质量改进，还提供了评价现有过程的参照点，最关键的一点是，它提供了过程改进的线路图，目前最主要的用途是评价一个组织的组织级能力。 ","date":"2021-04-12","objectID":"/post/:1:0","tags":["软件工程管理","软件过程改进"],"title":"简述软件过程改进","uri":"/post/"},{"categories":["软件工程"],"content":"2 敏捷方法概述 敏捷是用来指导解决快速高质量交付高价值产品的思想与框架，是一种允许快速业务变更的开发实践。敏捷的核心是敏捷的4个核心价值观和12条原则，外围则是满足不同团队需求的各种敏捷实践，敏捷的不同之处在于其更关注团队协作、关注质量、关注可工作的软件。敏捷来源于实践而不是理论。在追求卓越的过程中，组织会尝试多种途经，采用不同的原则、方法及技术。一个对敏捷实践感兴趣的组织可能也会对PMI的OPM3、ISO或能力成熟度模型集成（CMMI）感兴趣，反之亦然，因为这些都是通向卓越的手段。敏捷代表着一种极简的实用主义。 敏捷的本质是，项目组全体人员以及所有员工和公司，同处于一个利益集体。表现出来的特征是所有人对项目的成功负责、需求驱动地工作、跨领域合作、持续交付，迭代开发，小步前进，持续改进。 敏捷过程的特点则是：项目目标明确的过程，只做对项目进展有帮助的事，不进行额外的工作，有效和高效是项目管理原则、强调让人工作愉快，充满热情。 ","date":"2021-04-12","objectID":"/post/:2:0","tags":["软件工程管理","软件过程改进"],"title":"简述软件过程改进","uri":"/post/"},{"categories":["软件工程"],"content":"3 CMMI 和敏捷 经常有一种说法是 CMMI 和敏捷是对立的，这是一种错误的理解，最根本的原因是 CMMI 不是开发过程，而大部分敏捷则是具体的开发过程，这两种之间并无冲突的基础，在 CMMI 的一些过程域中，可以使用敏捷方法进行实践，也可以不使用[3]，有些时候，敏捷方法是达成某个 CMMI 过程域目标的最佳选择。其次，CMMI 存在所谓的标准化，不管是评估方法还是实施办法都有标准化的趋势。而敏捷往往拒绝标准(追求灵活)。再次，作用，即让不熟悉的第三方认可上有差异。尽管 CMMI 目前的现状不乐观，但是，毕竟这种方式提供了一些有价值的线索来了解某个软件组织的能力和成熟度的可能。而这一点敏捷过程还无法提供。有一种说法，CMMI 是主要是组织级过程，而敏捷是项目小组的过程。应该说这种说法有一定的问题，敏捷也可以是组织过程， CMMI 也可以只是关注在小组级别（2 级）。 说完本质，具体地，可以从目标，过程，关注点，适用范围，核心理念等方面来分析和对比 CMMI。 从目标上说，CMMI和敏捷都是人们为了解决在软件生产过程中出现的质量低下、进度延迟、预算超支等问题，而产生的标准或过程改进的模型或方法实践。在这一点上是一致的，这也是为什么人们认为这两种方法是完成同一件事的不同方法因此会产生冲突的原因。但是，接下来，如果从其他角度看，这两种方法思考的角度，范围完全并不一致。 比如，从过程来看，过程的四要素分别是人、方法、技术和工具，在 CMMI 中，对于人的要求涉及GP2.3提供资源、GP2.4分配职责、GP2.5培训、OT组织培训，而敏捷中对人部分的关注在于如何提高人的工作积极性和效率，这在 CMMI 中也有体现，但 CMMI 还关注人的技能，技能培养和团队资源等，明显范围更大，考虑更深。对于方法，涉及所有PA 的SP，而敏捷则强调一组价值观。对于技术和工具，CMMI在GP2.3 提供资源，工程类PA ，OT 组织培训，OPD 组织过程定义，OPM 组织性能管理中谈及了技术在GP 2.3 提供资源谈及了工具，而敏捷对于技术和工具的选择仍基于其价值观，CMMI 则是通过各种目标综合考虑，这里又是CMMI 考虑的更为全面。 从它们的关注点看，敏捷是达成商业目标的极简方法，CMMI 是达成商业目标的方法体系，也是为商业目标服务，不能为商业目标服务也就会违背 CMMI本意，可以依据需求选择执行的部分，比如一个项目是质量优先还是工期优先，该过程和执行和过程还有执行的结果和效果可以被 CMMI 评估和追踪。CMMI和ISO关注为了实现组织软件生产目标，我们应该做什么？但却不关注如何做。而敏捷开发作为一个实践性方法，更关注怎么做。因此，在具体操作过程中，可以通过有效结合，能够使组织更快、更好地实现过程改进目标。为了能够有效结合各种CMMI和敏捷开发，组织必须明确它们的区别和联系，以及每种方法的主要关注点。CMMI和敏捷开发的主要冲突来自于双方产生的环境、目标客户和团队文化要素，例如CMMI早期客户,主要关注大型项目、复杂系统、使命关键(Mission Critical)系统，而敏捷开发主要关注小项目、简单应用和灵活多变的系统；CMMI的假想市场和用户主要面向成熟市场，面向那些关注流程创新的企业，而敏捷开发主要关注在新兴市场和多变的市场环境；文化方面，CMMI强调流程和管理，而敏捷更强调高度信任的氛围中，被激励起来的个人之间的协作创新。 从最一般的适用范围来说，CMMI最初是美国国防部为评价一个组织的开发能力而定义的模型，它是站在组织级的角度看待过程能力。它定义了高层管理者的治理职责，要求组织级要定义管理的方针、流程、裁剪指南、模版等，组织级要进行流程执行情况的检查，要给团队提供资源、工具、培训等支持，组织级要采集经验教训、典型案例、改进建议、度量数据等进行持续改进，要将组织的规范固化为大家的工作习惯。SCRUM，XP等敏捷方法大都是侧重于构建团队级的能力，给出了一个小团队的角色划分、管理实践与技术实践，如果需要进行大产品的开发，可以采用规模化敏捷的方法，如LeSS， SAFe等。当团队规模越大时，需要的管理活动就越多，SAFe之类的大规模敏捷框架受到的质疑就比较多。组织级敏捷文化的形成需要借助变革管理的理论、方法来辅助Scrum, XP, LeSS, SAFe等敏捷方法构建组织级的能力，在组织内如果不能形成敏捷文化，敏捷不能持久。 从核心理念来说，敏捷宣言，敏捷的12个原则以及各种敏捷方法自己的原则，构成了敏捷的价值观，这些是敏捷的思想理念，是敏捷的根本。CMMI推崇的价值观，理想以及自己的原则并没有明确的官方描述，CMMI的共性实践可以认为代表了它的一些核心理念，不是全部，它是通过实践来描述的，没有提炼、抽象出来。可以做如下概括：商业目标驱动改进，转型过程实现目标，定量数据量化性能，固化习惯成为文化，高层支持全员参与，循序渐进持续优化。 总结一下，CMMI 和敏捷要达成的目标其实是一致的，在适用范围上，它们皆可大可小适用于组织和团队，但是由于基本价值观的不同，思考问题的角度和方式也不同，CMMI 更像是一种管理方法，而敏捷更像是一种实践的指导思想。从实际使用的角度来说，目前敏捷方法在开发软件项目的时候使用的跟多，而 CMMI 则主要用来了解一个组织的能力和成熟度，不过并非是必要条件。在一些情形下也比敏捷方法更加适用。 ","date":"2021-04-12","objectID":"/post/:3:0","tags":["软件工程管理","软件过程改进"],"title":"简述软件过程改进","uri":"/post/"},{"categories":["软件工程"],"content":"4 CMMI 引入敏捷的得与失 从整体上说，CMMI和敏捷开发能够很好地相互补充、相互支持。首先在关注点上CMMI关注组织级或企业级改进，关注回答项目应该做什么，而不是具体怎么做的方法，而敏捷开发则更关注项目级改进，关注项目具体怎么做的方法和最佳实践，这使双方在定位方面形成很好的相互补充的态势，一方面CMMI为敏捷提供组织级扩展的能力和必须的组织治理框架，便于组织级对敏捷最佳实践的推广和重用；另一方面，敏捷为CMMI提供了项目级的具体实践方法，确保团队在CMMI框架下能够快速响应，不断创新，持续交付价值。两者的有效结合，能够有效实现个人绩效向团队绩效、向组织绩效的转变过程。同时，也可以通过敏捷实践，规避CMMI实施过程中重文档、重流程的不良倾向，使CMMI实施时更加关注组织的实际价值、关注客户、关注创新。 需求明确，技术明确的简单项目，用传统模式管理，套用CMMI模型，成熟、没大毛病，而且效率还会更高一些。部分复杂和复杂的可以使用敏捷，拥抱变更，需求边做边涌现，于是不断进行改进，会比使用传统项目管理更灵活一些，变更成本和风险都会降低。 谴责CMMI模型不好或者谴责敏捷方法不好，都是片面的，更大程度上是落地方法有问题，是去落地的人的问题。在一个组织内，谁最先发起要导入CMMI与敏捷的呼吁呢？如果是市场的呼吁，那可能侧重的是证书，是投标的需要。如果是开发的呼吁，那可能侧重的是减负，是提高效率的需求。如果是老板的呼吁，那可能侧重的是交付高质量的产品，快速响应市场的需求。对企业而言，对老板而言，要平衡短期利益与长期利益，活下去，活得好，活得久，需要平衡。CMMI与敏捷都不是万能的，都有其适用场景，不能盲目迷信，盲目崇拜，要秉持开放的心态，持续发展的心态，兼收并蓄，取长补短。总之，这两者的目标是一致的，因此要根据实际情况，选择更加适合的方法来达成这个目标，而不是为了方法本身纠结。 CMMI 中提供了一些良好的实践，这些实践中CMMI 过程域和敏捷方法相互帮助，共同实现了对方的目标/理念，这一过程中不但具有 CMMI 的优点也兼具了敏捷方法的优点，比如说：想达到 CMMI 2（已管理级）的 SCRUM（一种迭代式增量软件开发过程）团队在日常工作中需要实施下列过程域：“需求管理”（REQM）、“项目计划”（PP）、“项目监控”（PMC）、“过程和产品质量保证”（PPQA）、“配置管理”（CM）和“度量与分析”。SCRUM 团队在 SCRUM 规划会议期间执行项目计划，在每天的 SCRUM 中执行项目监控，但他们处理积压的订单时需要执行需求管理。很多时候，他们持续交付环境需要一个好的配置管理。此外，他们还需要实施一些 CMMI 3 的过程域，为他们进行审查性会议，使用类似 TFS 和 CollabNat 平台支持他们日常活动，以提供分析标准。然而，CMMI 3 的一个集成项目管理（IPM）却要求 SCRUM 团队改变管道生产方式，放弃纯 SCRUM，这是很难实现的。集成项目管理提供了强大的良好实践过程以帮助团队满足特定项目的几乎所有需求。想象一下，一个利益相关者谁还需要一系列基于模板而编写的特定文档。这类事情本应该由产品所有者来解决，现在 CMMI 却优雅地做到了这一点。 最后再总结一下，CMMI引入敏捷方法，二者共同以最高效和完美的方式达成了本来的共同目标，即解决在软件生产过程中出现的质量低下、进度延迟、预算超支等问题。同时，由于敏捷方法为 CMMI 某个过程域的最佳实践，使得这一过程兼具了 CMMI 可监控度量追踪等优点和敏捷方法成本最小化的同时质量最优化的优点。存在的问题就是，还是存在使用敏捷方法需要让 CMMI 进行妥协的情况。但是，鉴于二者都是为同样的商业目标服务的，这样的妥协显然是十分值得的。 ","date":"2021-04-12","objectID":"/post/:4:0","tags":["软件工程管理","软件过程改进"],"title":"简述软件过程改进","uri":"/post/"},{"categories":["软件工程"],"content":"5 Reference [1] Hillel Glazer, Jeff Dalton, etc. CMMI or Agile: Why Not Embrace Both!. SEI. 2008 [2] CMMI Institute. A Guide to Scrum and CMMI: Improving Agile Performance with CMMI. 2016 [3] CMMI 产品团队, CMMI开发模型，版本 1.3, 2010 ","date":"2021-04-12","objectID":"/post/:5:0","tags":["软件工程管理","软件过程改进"],"title":"简述软件过程改进","uri":"/post/"},{"categories":["读书笔记"],"content":"《软件管理沉思录》是一本介绍SEI项目管理、人际沟通和团队协作的要诀。不论读者是软件开发者抑或是管理者，都能够从这本书中挖掘到价值。 本书分为四个部分，分别介绍了项目管理，团队管理，与上级沟通和自我管理。 在关于项目管理的部分中，作者强调了软件质量的重要性。作者指出一条被广为认同的公理：一个软件系统是不可能没有缺陷的。一个小型的软件系统尚可能存在着不易察觉的缺陷，一个涉及到用户或者极为复杂的软件系统更是难以根除缺陷。所以提高软件质量，减少软件的不稳定性对于软件的开发维护人员是一个巨大的挑战。 针对这一问题，我们可以使用8个步骤规则，来控制软件质量：确立质量控制的策略、目标和计划；正确训练、指导和支持开发人员及其团队；确立和维护软件工程过程的统计控制；审查、检查并评估所有的产品制品；评估所有缺陷，加以更正并用以识别、纠正和预防其他类似问题；确立和维护配置管理和变更控制系统；持续改进开发过程。这八步措施被越来越多的证据证明是有效的，且能帮助节约时间和金钱。软件质量的控制从分析需求开始，只有得到了清晰的需求，才可能开发出高质量的程序。开发中的软件缺陷是影响软件质量的一个重要因素，它指的是程序中的错误，简单的错误可能导致毁灭性的缺陷。缺陷往往是潜藏在系统中的，当缺陷暴露出来，引发了问题，产生了影响就成了漏洞。 接下来讨论了高质量项目至关重要的一点——计划，其实制定合理有效的计划这一观念贯穿了本书始终，不论是开发人员个人在进行软件开发之前需要做详细的计划安排，团队合作之前也需要制定成员们都认可的计划，这是形成高效团队的条件之一。一份合格的产品计划应当包括三项内容：将要生产的产品规格和重要的性能指标；估算工作所需的时间；进度预测。对于重要的项目，管理者要做的第一件事就是组织一个计划和提案小组，并且制订出一个总体计划，计划的五条基本要求是：易于理解、清晰明白、详细具体、精确缜密、准确无误，如果你不能使计划准确无误，那就常做计划。 第二部分主要讲团队，团队是指有着共同不表的一群人。本书作者修改了戴尔的定义来描述TSP团队：一支团队至少要有两名成员；所有成员都是为了同一目标而工作；每位成员至少扮演一个特定的角色；完成任务要求团队成员之间相互依赖。在一支高效的团队中，团队成员联合后的集体才智使得团队获得更全面的知识。本书中列出了团队遇到的七个常见问题：无效的领导、缺乏妥协或合作、缺少参与、拖延和缺乏信心、低劣的质量、功能蔓延、无效的对等评估。因此最常见的导致项目团队合作失败的原因有：资源不足、领导问题、不可能的目标、士气问题。任何一个都会导致一支团队失效甚至失败，并且这些问题通常一起发生。一支高效的项目团队被称为凝胶型团队，当团队成员集中在一个清晰的目标上时，就会发现有中神奇的力量，每个成员的表现都似乎能超越自身的能力。这样的团队能为成员带来工作中的快乐，所有成员能对团队全身心投入。一个高效团队常常有四个条件：凝聚力、有挑战性的目标、目标追踪和反馈、共同的工作架构。一个团队是随着时间成长的，在团队形成凝聚力的过程中，各成员会逐渐接受一系列共同的团队目标并投入巨大的实现热情。在创建凝胶型团队的过程中，交流至关重要。对于团队来说，交流最重要的三要素是：透明、倾听和协商。随着团队成立，它就进入了一个自然的生命周期，逐步经历组建、动荡和规范等阶段。在这个过程中努力变成一支高效的团队。伯恩把群体分为三种类型：工作型群体专心于工作，过程型群体专注于内部的动力学，对抗型群体则与外部威胁作斗争。不同的团队可以采用不同的工作风格。康斯坦丁把团队行为界定了四种类型：开放型群体、随意型群体、封闭型群体和同步型群体。但是现实的团队风格往往是表现为混合的形式。自主指导型团队对于任何类型的工作都是有效的，但这种团队对于完成复杂、创新性的工作尤其重要。本书提出了5条自主指导型团队的典型特征：具有团队感和归属感；共同对团队目标做出承诺；对过程和计划的主人翁以适；具有制订计划的技巧和执行计划的纪律；追求卓越。 对于团队成员来说，一个优秀的成员应当会做任何需要做的事，并且应当作出负责人的承诺并努力实现。目标对于个人十分有用，它明确地提供了努力的目的，暗示了当前在过程中所处的位置。对于团队来说，需要一个所有成员都认可的共同目标，才能提高团队的凝聚力。项目团队提供的不仅仅是组织架构，还提供了一系列技巧和视角。团队只有恰当利用各个成员的知识和经验才能使每个成员都变成有力的资源。在团队交流中，不同的成员有不同的表现，组织者应当维持讨论的秩序和理性。要想让团队运行顺畅，每一位成员都应当奉献出他所知道的一切。在遇到麻烦的时候，团队的成员应当请求并接受帮助。本书中列举了团队创建的义务：接受并扮演一个团队中的角色、确定并努力实现团队目标、建立和维护团队。团队的创建和团队合作一样需要所有成员的主动参与。优秀的谈判者往往采用原则式谈判，可以避免立场的两极分化。本文在之前提到团队一定要做到共鸣型或主动型倾听。在原则式谈判中，基础是认识到立场只是满足利益的一种方式，应当将注意力集中在利益而不是立场上。经验表明，团队中如果有一个人不务正业的话，就会影响到其他所有人的表现，可以剔除不履行职责的团队成员来提升团队的整体表现。团队成员的一项重要责任是寻求帮助，很多软件工程师习惯各自解决难题，但其实及时寻求帮助能够很大程度上缩短解决问题需要的时间。同样团队成员除了自己的正式角色，还应当承担起团队公民的责任，帮助其他的团队成员解决问题。提供有效支持的关键是帮助团队伙伴相信他们自己的能力。 然后是关于领导力，领导力事关成败，团队的做事方式很大程度上取决于他们与领导者进行协调的方式。三条最重要的激励因素是恐惧、贪婪和承诺，对于开发人员等从事创造性工作的人而言，激励因素还涉及技术挑战。领导者可以利用这三个因素推动团队的工作，但是也应当适度，确保可以引发需要的反应。激励的程度取决于做出承诺的方式，承诺的三个要素是协商、约定和执行。可信的团队承诺有四条要求：自愿、可见、可信、得到承诺，这四个要求构成了作出承诺的基础。为了在长期富有挑战性的项目中信守承诺，需要在任务过程中以某种方式定期强化承诺。为了及时提供反馈，可以把总体承诺划分为若干标识进展的里程碑。领导力的挑战之一是帮助团队成员设置中间目标，短期的目标可以制造紧迫感。团队中往往会有不是非常积极参与的成员，为了让他们参与进来，可以采取的技巧有：提问、装聋作哑、频繁地检查约定、感受没有说出的疑虑或不同意见、不要让某个人完全控制讨论、管理专家、指导团队领导者、关注事实和数据、不允许有旁观者。当团队处于动荡阶段，辅导的关键是让团队成员发泄他们的怒气和愤懑，然后着手解决他们的焦虑。管理团队时个部门的管理者应当从一开始就参与其中，充分考虑他们的观点。另外，这样还可以使管理者从已提出的问题中发现一些重要的新议题。构建管理团队的最后一步使鼓励管理团队成员共同工作。当管理团队以一种公开、坦诚的方式在一起工作时，其结果一定时最佳的。理性管理的四个要素：确定目标、计划和审查、评估和追踪、预测和纠正。他们彼此相关，都是高效管理风格所必需的。 对于工程师如何与管理者相处，作者提到如果项目从一开始就遇到麻烦，工程师必须站稳立场，让管理者相信你知道项目会花费多长时间。当制定一份计划确定日期之后，就可以告诉管理者真正的交付期限，据理力争。我们的工作任务应当是让团队聚焦于优先级最高的事情。在面对管理者的压力时，我们应当制定一个可以让管理者相信整个团队正在努力实现的富有挑战性的计划。不过，制定一个合理详细的计划是掌控项目的第一步，接下来必须保持计划的更新。同时我们需要按照计划执行，让管理者了解情况。自主指导型团队面对管理层的控制时，应当制定详细的计划并与管理者商谈日程进度，而不仅仅是做那些要求做的事。默默为每一项变更制定调整计划可以有效应对管理者的控制。当一个项目注定失败时，如果不想放弃，我们应当试图解决问题。由于必须与管理者打交道，我们应当从他们的角度想想我们能做什么。在推行改进时我们需要管理者的支持才能让整个组织结构的人们改变工作方式。这时我们应当考虑三个问题：为什么想要改变、需要从哪些管理者那里取得支持、管理者为什么要支持？如果引起了高层管理者的关注，我们就需要给出战略性理由。这时我们要准备：阐明提议、理解当前的业务环境、找出关键点、作一次改进合理性检查、引入原型、前期引入成本、后期维护成本、过程改进的收益、有关收益的事实、计算节约的数额、衡量收益其他收益。突破管理者抵制的方式是证明当前面临的问题无法通过短期的权宜之计来解决，必须具备战略目光，可以采取的基本措施：让战略性改进活动具备战术吸引力，从小的、战术性努力开始，逐渐扩展成战略性改进方案。 在注意“管理”你的领导的同时，我们也需要学会管理自己，把握主动，这时需要分成两步：1. 真正掌控自己的工作；2. 说服管理者同意由你管理自己。本书中列举了改进工作的步骤：确定质量目标、衡量产品质量、理解过程、调整过程、应用调整后的结果、衡量结果、把结果与目标进行比较、循环并不断改进。我们也要学会利用支持人员，学会计划工作，并促使你的团队伙伴和项目负责人也开始作计划。按计划完成工作的一个隐含好处是执行计划事实上会改变你的行为。我们需要学会负责任、信守承诺、执着追求卓越。 最后，关于领导，作者讨论了作为领导，我们的行为方式会影响整个团队，因此我们需要为团队树立榜样。领导力低下的症状有：高层管理者在思考问题时以自我为中心，眼界短视狭隘；官僚惰性；管理者没有能力及时做出有效的决策；过犹不及。管理是利用资源达到某种结果，而领导则是激励人们实现某个目标。管理者和领导者之间最主要的区别是管理者命令","date":"2020-12-22","objectID":"/post/:0:0","tags":["软件工程管理"],"title":"《软件管理沉思录》 - 读书笔记","uri":"/post/"},{"categories":["读书笔记"],"content":"在对失败的软件开发项目的分析中，人们倾向于将与人相关的失败因素归结于政治而不深入研究，这是一种误区，而本书中Tom DeMarco和Timothy Lister两位大师用严谨的科学实验和辛辣尖锐的解剖一步步为我们揭开知识经济下管理中的这种误区，与《人月神话》中给出一些成功的实践和准确的论断不同，《人件》更想给读者以警醒，激发对人的因素的思考。 《人件》此书的核心观点是软件系统的主要问题不在于技术，而在于社会性因素。那么，究竟是哪些社会性因素呢？作者围绕如下几个问题，提出了需要注意的地方。 管理人力资源； 改善办公环境； 招聘留用人才； 提高团队效率； 塑造企业文化； 营造快乐氛围； 通过对以上问题的探讨，本书会让管理者形成一种心态，这种心态会帮助他更好地激发员工的工作效率而不是进行不必要的压榨。在这些问题中，我选择几个关键因素进行探讨。 单纯的技术问题绝不是导致项目失败的关键 “政治”是被访问者最常提及的失败原因，对于技术人员倘若面对政治范畴的问题，我们通常会逆来顺受，当与政治无关时，我们往往更加游刃有余。因此《人件》中认为的工作问题更多的属于社会学范畴，而非技术范畴。但是实际情况是，大多数管理者虽然承认他们对人的担心甚于对技术的担心，但是他们还是总以技术为主要的关注点，越俎代庖地去解决复杂而又有趣地难题上，却将最重要地与人相关地要素放到最低优先级。《人件》对此现象的解释就是该问题造成的原因就是管理者的提拔机制。 《人件》提出的几条管理脑力劳动者的建议或者警告： 错误在所难免 避免向工作者施压，反而采用一些手段让大家少工作一会儿，让大家做更有意义的事情 尊重每一位员工，“没有人是不可替换的”思想是不可靠的 稳定的生产思维对项目工作尤为有害，项目总是处于不断变化的状态，一个能让项目更加稳定的人抵得上两个做事的人 我们花时间去做事，但却从来不去考虑工作本身的问题 榨干员工的时间和精力是危险的 《人件》中提到的一个案例就是管理人员压榨员工，直接导致团队内两名成员离婚，一名成员的儿子染上毒瘾。管理者以牺牲员工的生活为代价来承担更大的工作强度和更长的工作时间，管理者鼓吹他们的员工加了多少班，并谋算着如何让大家加班更多的手段。这是完全不对，应该是引导员工意识到人生苦短，生活中还有很多事情比工作更重要。需要记得是：压力不会让工作得更好——只是工作得更快。 产品质量的影响因素——自信 新手管理者或许觉得工作可以不参杂个人情绪的，但是实际情况下，我们的工作给了我们表达情绪的很多机会。当我们面临一个背景毫无所知的项目，我们肯定十分胆怯，威胁到自信，并且我们倾向于将我们的自信与生产出的产品质量紧密相连。 再谈帕金森定律 当我们热爱我们的工作，我们绝不会让一项工作变得遥遥无期，因为这回推迟我们获得满足感的时间，在不需要降低标准、牺牲质量的时候，我们期望工作能快点完成。但是需要明确的是：帕金森定律是不能在工作中得到运用的。把团队中的成员当成帕金森性的员工是不可能奏效的，这只能消磨他们的意志，让他们失去前进的动力。《人件》中提出了帕金森定律的变异版本：一个组织的工作如果都忙忙碌碌，就会膨胀以至于占满整个工作日。 不要相信“苦杏素” 不少管理人员在“足够绝望”时会忽略对证据的审视，买到的技术缺乏任何客观证据的支撑。在实际项目中会存在这样类似的七宗罪： 有一个你不知道的新窍门可以让产能飙升 其他的管理者正在收获100%、200%乃至更多的增长！ 技术日新月异，你已经过时了！ 改变程序语言会给你带来巨大的提升 因为库存的缘故，你需要马上让产能翻倍 你自动化了其他所有东西；难道不是要你自动化掉你的软件开发人员吗？ 你的员工在巨大的压力下工作得更好 忘记掉这些准则，你和你的员工会工作得更好 似乎在朝九晚五得环境里啥都完成不了 软件行业里似乎形成一种风俗：加班就是命中注定。归根到底其实就是环境因素影响很 大。在《人件》中以下因素跟产出效率基本或根本没有关系：语言、经验年限、缺陷个数、薪酬。此外，从《人件》提供得数据来看，对工作环境设计上采用弃权政策是一个错误。那些安静、宽敞和注重隐私得环境不但能使你的团队更高效地完成工作，还能帮助你吸引和挽留住人才。 构建社区 成功构建社区的组织更能留在人。当员工有足够的社区意识时，他们就不想离开了。此时你对人力资本的投资由此也得到了回报，进而也愿意投资更多，再进而你的员工也会表现得更好，更喜欢呆在你的公司，这将会是一个增强得良性循环。 快乐地工作 作为一名管理者，你需要保证自己手下的人从工作中得到快乐。所谓的工作，就是要使员工的效率最大化，而这已经足以剥夺他们的快乐了。 纵观整本书，Tom DeMarco和Timothy Lister两位大师探索了技术项目中的人文问题，讨论了管理者在领导力上的病理征状，提出一些关于管理新旧成员水火不容的混合团队的建议方法。由于我的阅历尚浅，对有些章节读后并没有太多的感悟，有些章节有幡然醒悟的感觉，这类书还是需要在日后反复阅读。 此外，通过阅读《人月神话》和《人件》这两本书，我们大概能总结出软件工程管理的核心目标是：成本和工作量的估算、计划和进度跟踪调整，风险分析与控制等，在此基础上，我们要最大化地激发人的力量，即让人尽可能大地提高工作效率，尽可能多地保持良好的关系，尽可能地减少工作时间等。 ","date":"2020-11-20","objectID":"/post/:0:0","tags":["软件工程管理"],"title":"《人件》 - 读书笔记","uri":"/post/"},{"categories":["读书笔记"],"content":" 内容已过时，《黑客与画家》的核心是计算机，程序员与创业 一直以来，对“黑客”这个词总是充满了神秘的想象，本科阶段学习了《信息安全》这门课以后，对“黑客”的工作自以为算是有了一些初步的认识，怀着这样的心情，阅读了《黑客与画家》这本书，本以为会了解到更多的我所以为的“黑客”的工作，却没想到，这本书带给我的不仅仅是对已深深印在脑海中的概念的推倒重建，更多的是引发我对很多以前从没想过的问题的全新思考，这些思考带给我不一样的新的视角去看待其他事情，我想这就是阅读的意义所在吧。 首先，这本书绝不是你看到书名所能想象的那样，如果你对这块领域不那么熟悉的话。黑客，画家，看似两个毫无关联的职业，怎么能放在一起呢？然而，这正是该书的作者，他是黑客，也是画家，他是程序员，更是一名艺术家。书中，作者结合他的经历探讨了很多不同的问题，例如：怎样打破常规？怎样创业才会成功？如果你的想法是社会不能容忍的，该怎么办？为什么互联网软件是微软诞生后最大的机会？如何创造财富？怎样做出优秀的东西？一百年后，人类怎样编程？等等。总之，作者想要传达的是新的思想，来帮助读者理解我们所处的这个计算机时代，他的这些阐述，也的确带给我很多的启发。 初读本书，我就在脑海里对“黑客”这个概念作了重新定义，不像大多数人所认为的那样，“黑客”是利用自己的技术入侵他人计算机并带来一些危害的人，在计算机世界里，黑客指的是专家级的程序员，根据理查德。斯托尔曼的说法，黑客行为具备三个特点：好玩、高智商、探索精神。真正的黑客致力于改变世界，让世界运转得更好，而不是犯罪或危害他人。 基于这样的理解，作者在书的第一章讨论了这样一个问题：为什么书呆子不受欢迎？这里的书呆子，恰恰很可能就是一名未来的黑客，因为作者发现，“书呆子”与“高智商”有强烈的正相关关系，他们不会将注意力放在诸如穿衣打扮、开晚会上面，他们的脑子里想着别的事情，例如读书或观察世界上，他们从小就在琢磨如何变得更聪明，并打心底里追求这个，至于受不受欢迎，已经不在他们的考虑范围之内了，所以，在学校里书呆子也许会被大家歧视或欺负，但是离开学校以后，真实的世界却能友好的地对待他们，因为真实世界的庞大规模使得你做的每件事都能产生真正意义上的效果，发现正确的答案就开始变得重要了，而这恰恰是书呆子的优势所在。 黑客与画家的共同之处在于他们都是创作者，与作曲家、建筑师、作家一样，他们都在试图创作出优秀的作品，从另一个角度来说，他们都能称作为艺术家，创作过程中，他们可能会发现一些新技术，但本质上，他们并不是在做研究。黑客与画家有很多共同之处，其中我认为最重要的一点就是：你不能指望一开始就有完美的设计规格，要编写一个程序，你把问题想清楚的时间点，应该是在编写代码的同时，而不是之前。因为这终究是一项实践性的工作，需要不断的练习和探索，甚至很多的失败，才能找到一个相对正确的答案，而这个答案在不久的将来很有可能要再次修改甚至推倒。很多同学说自己编程能力不强，排除不感兴趣和懒惰的情况，总有人认为自己要把某门语言掌握到滚瓜烂熟才开始写代码，这是最错误的行为，你应该从尝试去解决一个小问题开始，在实际操作的过程中，不断补充新的知识，产生新的想法，就像书中说的，“编程语言是用来帮助思考程序的，而不是用来表达你已经想好的程序”。 程序员就像是手工艺人，他们创造人们需要的东西，也即财富，想要创造财富，就要做出优秀的软件，而实现最好的方法就是创业。作者结合自己创办viaweb的经历，探讨了一些创业的必备要素。其中最关键的就是：你必须了解用户的需求。就像桌面软件时代的过去，大多数的用户并不需要成为系统管理员，很多时候他们所需要的设备就只要有屏幕、浏览器、无线网卡就够了，互联网软件的诞生正好满足了这些需求，它们更加方便、易操作甚至更强大，同时数据会更安全，更重要的是，通过研究用户的行为，能及时的优化软件并马上得到反馈，带来更好用户体验的同时也带来了更多的用户数量，而这恰是决定一款软件成功与否的标志。创业的初始必然是艰辛的，同时压力也会很大，但小团队创业的优势是每个人的贡献是可测量的，在这种情况下，与其他愿意更努力工作的人一起组成一个团队，互相产生激励作用，从而共同谋取更高的回报，这远远好过加入大公司而将自己的工作与平庸之辈的工作平均化。这也是创业公司的意义所在。就如乔布斯曾经说过，创业的成败取决于最早加入公司的那十个人。 要做出优秀的软件，就要有好的设计，对于很多学科来说，优秀设计的原则是共通的。例如，好的设计是简单的设计，当你被迫把东西做得很简单是，你就被迫直接面对真正的问题，也即设计的核心目的，做到这个，你就能以简洁又直接的方式满足用户的需求。又如，好的设计是启发性的设计，在软件行业中这意味着，你应该为用户提供一些基本模块，使得他们可以随心所欲的自由组合，这往往更加引人入胜。 书中，作者还谈到了未来编程语言的发展方向，一种语言能否长期存在的最重要因素在于基本运算符，内核设计得越小、越干净，它的生命力就越顽强。对于黑客来说，他们需要简练的语言，这种语言具有最高层次的抽象和互动性，而且很容易装备，可以只用很少的代码就解决常见的问题，不管是什么程序，真正要写的代码几乎都与你自己的特点设置有关，其他具有普遍性的问题都有现成的函数库可以调用。然而，无论未来的编程语言发展如何，编程这项活动始终不会停止，它就像一种艺术创作，黑客就是艺术家，对于顶尖的黑客们来说，就像画家中流传的一句谚语，“画作永远没有完工的一天，你只是不再画下去而已”。 ","date":"2020-10-26","objectID":"/post/:0:0","tags":["创业","Hacker","个人成长"],"title":"《黑客与画家》 - 读书笔记","uri":"/post/"},{"categories":["软件工程"],"content":"软件工程的历史演变要从软件发展，软件过程的发展和软件工程管理这三个角度去说。一方面，随着软件的快速发展，出现了许许多多越来越难以解决的问题，为统一地回答和解决这些问题，催生出了软件工程。另一方面，从软件工程中衍生出了软件过程和软件工程管理的概念，它们都是为了解决软件系统开发中的本质困难而诞生的。前者目标是更好地解决问题，而后者的目标则是为了复制成功经验。无论为解决开发软件系统的困难而产生的学科会发展成什么样，它们的核心目标都是解决软件系统开发中的不可见性，复杂性，可变性和一致性这几个本质困难的。下面将就软件发展的历史阶段来说一说这些困难是怎样逐渐增大的以及与之对应的软件过程的演变。 软件发展的第一个阶段是软硬件一体化阶段，即软件开发要从硬件考虑，根据硬件情况去设计软件。产生这个阶段的最主要原因是硬件性能的限制。这一阶段主要使用的是硬件，用硬件做到一些之前只能全凭人脑才能做的事。软件几乎完全绑定与特定的硬件，无法迁移和复用，因此也就无法做更多的应用，对软件的想象力被局限在了硬件。对于软件开发团队来说，也局限在了小作坊和“个人英雄主义”的形式。当然在这一阶段，随着硬件的发展和伴随的软件复杂度的增高，人们逐渐发现了目前所采用的粗糙的软件开发方式“编码加改错(code and fix)”的问题，也出现了类似硬件开发过程的软件开发过程SAGE等。但失败的软件项目的还是在增多，因此才催生出“软件工程”的概念。 第二个阶段是软件成为了独立的产品。进入到这一阶段的最主要的原因是软件不再局限于硬件，高级语言的出现使得一个平台上的软件同样可以运行在其他平台，同时个人计算机的出现使得大量的公司开始开发软件为个人计算机用户服务。由于需求的空前增长和可迁移性，这一阶段的软件开始出现了爆发，这种爆发不止是软件产品数量上的，更是软件规模上的和占计算机系统产品比重上的。这一阶段的软件产品展现出了远胜之前的复杂性，可变性，在此基础上想保证一致性也更加的困难。与之对应的这一时期的软件过程也有了很大发展，其一是形式化方法，意图从数学上找到一个一般性的方法，一劳永逸地指导复杂软件系统的开发问题。其二是结构化程序设计的思想，通过对程序划分模块，能将复杂的问题转化为简单的问题去解决。还有就是经典的生命周期模型“瀑布模型的出现”，让软件开发过程第一次有了一个比较有效和完善的指导方案。但是这一时期诞生的方法还存在着许多问题，形式化方法能应用的领域太狭窄，使用瀑布模型开发软件系统效率太低，而且还缺乏对软件质量的评估和提升的方法。所幸在这一阶段又出现了面向对象开发技术，它极大地改变了软件过程，直面软件开发过程中不可见性、复杂性、一致性和可变性的问题，提供了套编程范式，并在此范式上产生了一系列的编程语言，框架，设计思想等等技术，它们同样具备更高的开发效率。同时，也出现了以 CMM 为代表的软件过程改进模型等。 第三个阶段的发展特征是网络化和服务化。这一阶段的到来除了软件进一步发展之外，主要是因为互联网和移动互联网的出现，极大地增加了用户规模和软件产品的使用方式，对软件产生了额外的要求，这就不可避免地又增加了软件复杂度。同时,由于竞争的需要,需求不确定性和系统的快速演化成为一个日益突出的问题。最后，软件分发和使用方式也出现了显著的变化，从拷贝复制逐渐过渡到基于网络的服务乃至云计算的形式，使得软件系统的版本更迭时间有了大为缩短的潜力。这些新情况的出现，使得软件开发的四大本质难题中，可变性和一致性对软件开发的影响更为突出，因而也催生了整个软件过程历史上最为纷繁的一个时代，大量的软件过程在这个阶段涌现出来。其中最具代表性的是一系列具有迭代式特征的开发方法，比如增量模型，螺旋模型和原型法等，这与之前的单一过程有很大区别。但是这些还不够，大型软件开发过程正逐渐地被视为一个交流和学习的过程，而迭代式的开发只是遵从这一规律，而并没有完全从这一过程本身出发去考虑，因此又出现“敏捷”开发方法，一系列以此为指导思想的方法诞生了，它们被统称为“敏捷方法”，比较著名的有SCRUM，XP和 Kanban 等。在敏捷方法之后，还有着开源软件方法，这是一种基于并行开发模式的软件开发的组织与管理方式。这种方法依赖于分散在全球的开发者和使用者的协作，而只有 Internet才能为这种大规模协助提供交流沟通的工具。廉价的Internet是开源软件得以发展的必要条件。 到了现在，随着互联网应用的日益普及，用户对软件系统和服务提出了更多的要求，“多快好省”已成为大多数互联网时代软件用户的基本期望。具体而言，功能要丰富、更新要及时、要稳定可靠，同时用户获取服务的成本不能过高。所有这一切，都使得人们对软件产品和服务的需求与软件产品和服务的开发能力之间越来越不匹配。DevOps 因此产生了，它足以胜任需求很难确定，需要快速响应变更，需要快速提供价值，需要高可靠性、安全性的当下互联网时代对软件的要求，同时又进一步解决了之前提到的软件开发的本质性难题。 从软件发展及对应的应对软件开发遇到的困难的学科——软件工程的发展，我们可以看到一些非常有意思的特点。 第一，软件工程中提出的方法总是落后于问题的出现，和自然科学可以用来预测一些事情的发生不同，软件工程总是总结成功和失败的经验并提出一套方法去避免你犯错而不是去预测问题的出现并提前提出解决方法，这是目前的特征。 第二，软件工程所关注的对象不仅局限于技术——即用于控制和管理复杂度的技术，还在于人，因为软件工程任务并不是由一个人完成的，人与人之间的交流也是复杂度的一部分。甚至是，它还占主导地位。因此，除了软件过程外，还有软件工程管理，包括软件项目管理和软件过程管理，它们将人视为重要因素，已经属于管理学的范畴了。在软件工程发展的过程中，管理所占的比重是逐渐加大的，可以预见在未来，管理和技术在软件工程中也一定会共同发展下去。 第三，关于软件的知识将会越来越容易让人理解和更为广泛地分发，高级程序设计语言、框架技术和设计模式甚至与开发范式不但可以提高开发效率，更有助于理解一个大型项目。同时，互联网和开源软件的存在也为软件知识的学习和分享提供了便利。这同样也是有助于我们理解和管理复杂度的。还有迭代式开发方式的经久不衰也能印证这个观点，因为迭代式的方式符合人的认知规律，相信在未来这也将一直是主流的方式。 总览软件工程历史的演变，无外乎在解决两方面的问题，一是软件开发本质上的困难，再就是时代的发展中对于软件系统更多的要求。一个好的软件过程或者是软件工程管理方法一定是同时在这两方面有较大进展的。我们无法一劳永逸地解决软件开发本质上的困难，但可以知道一部分软件未来发展的方向，这样其实就可以为软件工程学科发展提供目标了。 ","date":"2020-10-21","objectID":"/post/:0:0","tags":["软件工程发展"],"title":"简述软件工程的历史演变","uri":"/post/"},{"categories":["读书笔记"],"content":"很显然，作为一名技术人员，阅读一本不能提供任何技术的“管理学”书籍，首先需要的是耐心，需要的是那种想明白这样一本书到底是存在什么价值才会被奉为经典的好奇心。同时我也希望我能在阅读这样一部已经想读了好多年的经典书籍后能给自己留下一些有用的东西，因此我力图在这篇读书笔记中保留我学习到的知识、对本书的思考与评价和我自己的一些观点。 本书是作者开发 System/360 项目时的经验结晶，本书讨论了软件工程项目过程中较为完整的要素，并给出了一些赫赫有名的观点和结论。最令我印象深刻的有这么几个地方。 首先，它指出程序和编程系统和编程产品和系统级的编程产品这些概念之间是有本质上的不同的。通过这一个观点，首先说明的是文档，系统测试等并不实际起到软件产品的作用，却又是软件产品的重要组成部分的这些软件产物的重要性。失去了这些，那么一个产品将不能被一个团队共同开发，不能保证良好运行，不能继续进行维护和迭代。这完全符合本书所强调的软件任务的根本性问题即软件复杂度问题以及如何降低或者控制复杂度的问题（使用软件工程的除程序外的产物）。 其次，本书开创性地通过量化的形式，讨论了软件工程中工作量和参与人员的关系，同样符合软件复杂性的论述：人越多，添加的复杂性越高，工作进度并不能保证随着人数的增加而增加——即人月神话。在人月神话中，最令人印象深刻的莫过于作者指出添加了人意味着增加了沟通的难度，也就是增加了软件工程任务的复杂度，所以没有人月神话，并通过 Brooks 法则揭示了真实的情况。这是本书的核心观点之一。接着，既然说明了增加人员并不能有效地推进软件工程任务的推进，那么该如何做呢，接下来的 13 章作者给出了自己的观点和建议，以剖析创造性工作的本质为暗线，讲述自己在项目实践中的经验为明线，给出了一套解决方案，按照话题划分，我在这里大致总结如下，只挑关键的部分重点讲述： 介绍了一种外科手术团队般的开发团队组成和分工。 这里也有一些重要结论，如软件开发应该为“精英模式”，也就是永远让最有才华的人解决最难解决的问题，而不是让很多人共同解决问题，那样只会得到更差的结果，除非是进度的压迫迫使我们需要分解问题让更多的人更快地解决。此外，还对小团队高效但是进度慢，大团队低效的问题给出了解决办法。 讲述了如何保证设计系统时的概念完整性。 保证了这种完整性的产品有一个明显的例子，苹果公司(Apple Inc.)的产品，作为一个科技巨头，苹果公司拥有一个 IT/互联网公司拥有的一切重要的东西，处理器，编程语言，操作系统（桌面+移动），独到的工业设计，软件生态等等。但是苹果公司的产品相较于其强大的实力——少的惊人，却又有着极为出众的体验。这就是保证了设计时的概念完整性的结果，产品极为简洁、易用却又能解决所有该解决的问题。当然本书中是在陈述如何做到这件事。 给出了一个在二次设计系统时添加不必要的东西的警示。 描述了在第二次设计一个具相似功能的系统时（也可以说在迭代开发同一个系统时），应该具有什么样的约束和心态。 讲述了如何严格执行设计目标。 这部分是讲述如何进行手册的书写，安排会议，登记日志，安排测试小组等方式达到目标。 说明了如何促进团队交流。 如何估计编码工作量。 如何控制软件规模。 讲述了功能换空间的理论和如何做到时间空间折中还有改变数据表现形式的观点。我想说一点就是现在一些产品设计上的问题，即会有用空间换时间的操作。现代性能和存储空间已不是瓶颈，存储空间甚至被认为是廉价的这也是一些问题现在不会被考虑的原因。但是，从整体上想，如果想在的系统设计都不考虑这些问题，那未来的某一天，对于一个没怎么考虑过这些问题的超大型复杂系统，显然它是可以正常运行的，但是会变得超级臃肿不堪，数据过度冗余到了无法接受的地步，这样总归是要吃以空间换时间的恶果的。 介绍了重要的文档。 如何为变化（需求变更，人员变更等）做准备。 通用工具的使用。 如何保证系统的整体性。 如何进行进度控制。、 需要对系统进行什么样的说明。 在这些话题中，作者同样给出了很多结论和建议，它们共同组成了一个软件工程活动如何进行的指导方案，或者至少是一个 40 多年前的较为完美的方案。 本书的另外一个核心观点是没有银弹，这是一个预言，一个谦虚的预言，到现在也能成立。作者指出没有任何技术或者管理上的进展，能够独立地许诺在生产率、可靠性或简洁性上取得数量级地提高。这是建立在对软件工程活动本质上的认识上的，虽然作者没有直接地指出这一点，但我们很容易能得出这样的结论：软件工程的本质是一种纯粹的创造活动，我们没有办法大幅度提高人的创造力，也就没有办法大幅度提高生产力。如果对于本质的论断正确，那毫无疑问这个预言是能够成立的。当然，四十多年后的今天，软件的生产率确实提升了，这也是建立在无数抽象和好用的工具及理念的基础之上的。时至今日，仍然没有一个实质意义上的银弹出现。本书也讨论了一些根本解决问题的方法，最让人印象深刻的是“构建软件最可能的彻底解决方案是不开发任何软件”，这个观点完全可以套用到现代的云计算技术上，结合本书的上下文，可以解释云计算所拥有的巨大优势——几乎实现了量化购买“人月”，成本当然远远低于开发自己的全套系统。同时也能解释互联网公司为什么要追求“唯快不破”，其中一方面是因为一旦竞争对手的产品占据了市场，那么自己开发的系统实际上是徒增成本而且还得不到多少收益了。 结合软件工程管理的角度说，我们可以做一个简单的总结。我们要管理的终极目标，正如 SCIP 第一课中所讲述的观点——计算机科学家的任务就是学会如何管理复杂度所说，就是通过人，去设计一个复杂度很高的东西并很好地管理它的复杂度，只不过计算机科学家还要更加地关注硬件罢了。所以说，管理的主要要素，即为人员（团队），文档，成本，进度，工作空间。我们在软件工程管理这个话题下所讨论的一切都要围绕着如何组织这些，这些东西里面包含哪些内容能最大化地帮助我们完成目标进行，而重中之重，是为组织沟通。 本书最大的价值在于对企业项目管理人员的启示，也对创业者大有裨益。它开创性地，系统性地思考了计算机产品开发过程中会出现的问题。同时，还让我们对软件工程管理中的核心问题有一个认识和思考的过程，所以此书中的理论历经 40 多年经久不衰。本书中的很多经验已经被进一步发展形成一套新的管理方式与体系，同时还有一些以前存在的问题被完全解决。如第七章中有明显已不在当前时代的出现的印制工作手册，目前文档基本完全以电子形式。第十章提到的按版本印制的团队文档，现在已被共享文档和项目知识库取代。第十二章提到的程序库，现在已有成熟的分布式版本控制工具如 Git 等，也有在线代码库 GitHub 等，还有集成经理的角色，现在则被成熟的 Code Review 机制取代。第十三章中提到的非常具有前瞻性的结构化编程现在则发展成了开发框架，计算框架和脚手架项目甚至设计模式等形式。第十五章提到的代码格式化规范等等现在已经可以通过工具来实现。 可以看到，很多提到的技术都变成规范化的东西，本书所讲的内容没有被抛弃的，这让我知道了这些东西是因为什么需要而出现的。 由于缺乏具体的实践经验我只能讨论我从书中学习到的东西和我的看法而不是在书中所表达的观点引发的我对实际问题的思考和改进，这也是这一篇笔记的遗憾，希望在未来的某一天，我能带着这本书中的观点，重新审视我做过的事，完成从单纯的技术人员到管理人员的转变。 ","date":"2020-09-26","objectID":"/post/:0:0","tags":["软件工程管理"],"title":"《人月神话》 - 读书笔记","uri":"/post/"},{"categories":null,"content":"关于morsuning","date":"0001-01-01","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":" 我这辈子遇到的聪明人（来自各行各业的聪明人）没有不每天阅读的——没有，一个都没有。沃伦读书之多，我读书之多，可能会让你感到吃惊。我的孩子们都笑话我。他们觉得我是一本长了两条腿的书。” ——查理 · 芒格 一个不懂计算机、编程和软件工程的人 写 Blog 是为了分享成体系化的知识，真心希望你可以少走一些弯路 { \"Name\": \"morsuning(Ceion.M.X)\", \"Gender\": \"Male\", \"Address\": \"Chengdu, China\", \"Education\": \"Master, NJU\", \"Profession\": \"System; Go \u0026 Java \u0026 Rust \u0026 Python\", \"Email\": \"morsuning at gmail dot com\", \"Description\": \"Don't want to miss the wonderfulness of the world\", } ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"}]